{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "[2025-04-13 20:12:06,601] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/sw/nix/store/r3bwp9b2501bv77y6g1nwkb483p0y9z2-cuda-12.3.2/lib64/libcufile.so: undefined reference to `dlvsym'\n",
      "/mnt/sw/nix/store/r3bwp9b2501bv77y6g1nwkb483p0y9z2-cuda-12.3.2/lib64/libcufile.so: undefined reference to `dlopen'\n",
      "/mnt/sw/nix/store/r3bwp9b2501bv77y6g1nwkb483p0y9z2-cuda-12.3.2/lib64/libcufile.so: undefined reference to `dlclose'\n",
      "/mnt/sw/nix/store/r3bwp9b2501bv77y6g1nwkb483p0y9z2-cuda-12.3.2/lib64/libcufile.so: undefined reference to `dlerror'\n",
      "/mnt/sw/nix/store/r3bwp9b2501bv77y6g1nwkb483p0y9z2-cuda-12.3.2/lib64/libcufile.so: undefined reference to `dlsym'\n",
      "/mnt/sw/nix/store/r3bwp9b2501bv77y6g1nwkb483p0y9z2-cuda-12.3.2/lib64/libcufile.so: undefined reference to `shm_open'\n",
      "/mnt/sw/nix/store/r3bwp9b2501bv77y6g1nwkb483p0y9z2-cuda-12.3.2/lib64/libcufile.so: undefined reference to `shm_unlink'\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "import importlib\n",
    "import structures\n",
    "importlib.reload(structures)\n",
    "from structures import *\n",
    "import losses\n",
    "importlib.reload(losses)\n",
    "from losses import *\n",
    "import trainer\n",
    "importlib.reload(trainer)\n",
    "from trainer import *\n",
    "#dtype = torch.float32\n",
    "dtype = torch.double\n",
    "torch.set_default_dtype(dtype)\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "# Set the device to CUDA if available, otherwise CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "import random\n",
    "sys.path.append(\"/mnt/home/yjo10/ceph/myutils\")\n",
    "import plt_utils as pu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLD Preliminary version with positions, velocity, and acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from src.trainer import num_samples\n",
    "\n",
    "# Example unsupervised data: 100 samples with 10 features each\n",
    "data = np.load(\"../data/two_body_train_data.npy\")\n",
    "num_samples = data.shape[0]\n",
    "num_samples_start = int(data.shape[0]*0.9)\n",
    "#num_samples_start = 0\n",
    "num_samples_end   = data.shape[0]\n",
    "num_samples = num_samples_end - num_samples_start\n",
    "num_features = data.shape[1]\n",
    "\n",
    "# Create a tensor of features only\n",
    "data_org = torch.tensor(data[num_samples_start:num_samples_end,:], dtype=torch.double).to(device)\n",
    "data = data_org.clone()\n",
    "\n",
    "\n",
    "# Normalize the data\n",
    "data_min = data_org[:,:26].min(axis=0, keepdim=True).values\n",
    "data_max = data_org[:,:26].max(axis=0, keepdim=True).values\n",
    "data[:,:26] = (data_org[:,:26] - data_min) / (data_max - data_min)\n",
    "\n",
    "# Wrap the feature tensor in a TensorDataset\n",
    "# Each item from the dataset will be a tuple containing one tensor (X[i],)\n",
    "dataset = TensorDataset(data)\n",
    "\n",
    "# Define the proportion for the test set (e.g., 20%)\n",
    "test_ratio = 0.2\n",
    "num_test = int(num_samples * test_ratio)\n",
    "num_train = num_samples - num_test\n",
    "\n",
    "# Use random_split to split the dataset into train and test subsets\n",
    "train_dataset, test_dataset = random_split(dataset, [num_train, num_test])\n",
    "\n",
    "# Create DataLoaders for the training and testing datasets\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CustomizableLoss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(losses)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlosses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 7\u001b[0m criterion \u001b[38;5;241m=\u001b[39m \u001b[43mCustomizableLoss\u001b[49m(nParticle\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, nAttribute\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m13\u001b[39m, nBatch\u001b[38;5;241m=\u001b[39mbatch_size,alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, beta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10.0\u001b[39m, TargetEnergyError\u001b[38;5;241m=\u001b[39mTargetEnergyError,\n\u001b[1;32m      8\u001b[0m                             data_min\u001b[38;5;241m=\u001b[39mdata_min, data_max\u001b[38;5;241m=\u001b[39mdata_max,device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m      9\u001b[0m X \u001b[38;5;241m=\u001b[39m data[:\u001b[38;5;241m2\u001b[39m,:]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(data_org[:\u001b[38;5;241m2\u001b[39m,:])\u001b[38;5;66;03m#, data[:2,:])\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CustomizableLoss' is not defined"
     ]
    }
   ],
   "source": [
    "import structures\n",
    "importlib.reload(structures)\n",
    "from structures import *\n",
    "import losses\n",
    "importlib.reload(losses)\n",
    "from losses import *\n",
    "criterion = CustomizableLoss(nParticle=2, nAttribute=13, nBatch=batch_size,alpha=0.1, beta=0.1, gamma=10.0, TargetEnergyError=TargetEnergyError,\n",
    "                            data_min=data_min, data_max=data_max,device=device)\n",
    "X = data[:2,:]\n",
    "print(data_org[:2,:])#, data[:2,:])\n",
    "loss, loss_terms = criterion(output[:2,:], X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import structures\n",
    "importlib.reload(structures)\n",
    "from structures import *\n",
    "import losses\n",
    "importlib.reload(losses)\n",
    "from losses import *\n",
    "import trainer\n",
    "importlib.reload(trainer)\n",
    "from trainer import *\n",
    "\n",
    "\n",
    "input_size = 13     # Number of input features\n",
    "hidden_size = 500     # Number of hidden neurons\n",
    "output_size = 2     # Number of output \n",
    "TargetEnergyError = 1e-5\n",
    "\n",
    "# Instantiate the model\n",
    "try: \n",
    "    del model\n",
    "    print(\"model deleted\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "#model = SimpleNN(input_size, hidden_size, output_size).to(device)\n",
    "model = FullyConnectedNN(input_dim=input_size, output_dim=output_size, hidden_dims=[64, 64], activation='relu', dropout=0.0, output_positive=True).to(device)\n",
    "\n",
    "\n",
    "# Define the loss function (CrossEntropyLoss is common for classification tasks)\n",
    "criterion = CustomizableLoss(nParticle=2, nAttribute=13, nBatch=batch_size,alpha=0.1, beta=0.1, gamma=10.0, TargetEnergyError=TargetEnergyError,\n",
    "                            data_min=data_min, data_max=data_max,device=device)\n",
    "\n",
    "# Define the optimizer (Stochastic Gradient Descent in this example)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Paths to save best and last models\n",
    "base_path = \"/mnt/home/yjo10/projects/AITimeStepper/data/models/two_body/\"\n",
    "best_val_path = base_path + \"best_model_loss.pth\"\n",
    "best_timestep_path = base_path + \"best_model_timestep.pth\"\n",
    "#last_model_path = base_path + f\"last_model_{epoch}.pth\"\n",
    "best_val_loss = float(\"inf\")\n",
    "best_largest_timestep = 0\n",
    "\n",
    "example_input = torch.randn(1, input_size).to(device)\n",
    "\n",
    "# Training routine\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    train_loss = \\\n",
    "        train_one_epoch(model, optimizer, criterion, train_loader, input_size, device)\n",
    "    test_loss, energy_error, energy_error_fiducial, time_step, time_step_fiducial = \\\n",
    "        validate(model, criterion, test_loader, input_size, device)\n",
    "\n",
    "    if epoch > 5:\n",
    "        # Save the best model based on validation loss\n",
    "        if test_loss < best_val_loss:\n",
    "            best_val_loss = test_loss\n",
    "            torch.save(model.state_dict(), best_val_path)\n",
    "            traced_model = torch.jit.trace(model, example_input)\n",
    "            traced_model.save(base_path + f\"c++/best_model_loss.pt\")\n",
    "            print(f\"--> Best model saved at epoch {epoch} with val loss {best_val_loss:.4e}\")\n",
    "        \n",
    "        # Save the best model based on validation largest timestep\n",
    "        if time_step > best_largest_timestep:\n",
    "            best_largest_timestep = time_step\n",
    "            torch.save(model.state_dict(), best_timestep_path)\n",
    "            traced_model = torch.jit.trace(model, example_input)\n",
    "            traced_model.save(base_path + f\"c++/best_model_timestep.pt\")\n",
    "            print(f\"--> Best model saved at epoch {epoch} with largest timestep {best_largest_timestep:.4e}\")\n",
    "\n",
    "    # Save the last model after every epoch (or just once at the end)\n",
    "    torch.save(model.state_dict(), base_path + f\"model_{epoch}.pth\")\n",
    "    traced_model = torch.jit.trace(model, example_input)\n",
    "    traced_model.save(base_path + f\"c++/model_{epoch}.pt\")\n",
    "\n",
    "    print(f\"Epoch [{epoch}/{num_epochs}], Train Loss: {train_loss:.4e}, Test Loss: {test_loss:.4e}, Energy Loss: {energy_error:.4e}/{energy_error_fiducial:.4e}, Time step: {time_step:.4e}/{time_step_fiducial:.4e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEW version with magnitudes of velocity and acceleration, and mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([590, 48])\n"
     ]
    }
   ],
   "source": [
    "def normalizer(_data):\n",
    "    _max = torch.abs(_data.max())\n",
    "    data_max = torch.ones(_data.size(), device=device)*_max\n",
    "    _data = _data/data_max\n",
    "    return _data, _max\n",
    "    \n",
    "def denormalizer(_data, _max):\n",
    "    data_max = torch.ones(_data.size(), device=device)*_max\n",
    "    return _data*data_max\n",
    "\n",
    "# Example unsupervised data: 100 samples with 10 features each\n",
    "data = np.load(\"../data/two_body_train_data_new.npy\")\n",
    "num_samples = data.shape[0]\n",
    "num_samples_start = int(data.shape[0]*0.8)\n",
    "num_samples_start = 0\n",
    "num_samples_end   = data.shape[0]\n",
    "num_samples = num_samples_end - num_samples_start\n",
    "num_features = data.shape[1]\n",
    "\n",
    "# Placeholder for input (magnitudes of velocities and accelerations)\n",
    "data_org = torch.tensor(data[num_samples_start:num_samples_end,:], dtype=dtype).to(device)\n",
    "data = torch.empty((num_samples,6+num_features), dtype=dtype).to(device)\n",
    "data[:,6:] = data_org\n",
    "\n",
    "\n",
    "# Magnitudes vel, acc, mass\n",
    "temp, tmax = normalizer(data_org[:,4:7])\n",
    "vel = denormalizer(torch.norm(temp, p=2, dim=1),tmax)\n",
    "acc = torch.empty((num_samples,4), dtype=dtype).to(device)\n",
    "\n",
    "temp,tmax = normalizer(data_org[:,7:10])\n",
    "acc[:,0] = denormalizer(torch.norm(temp, p=2, dim=1),tmax)\n",
    "temp,tmax = normalizer(data_org[:,10:13])\n",
    "acc[:,1] = denormalizer(torch.norm(temp, p=2, dim=1),tmax)\n",
    "temp,tmax = normalizer(data_org[:,13:16])\n",
    "acc[:,2] = denormalizer(torch.norm(temp, p=2, dim=1),tmax)\n",
    "temp,tmax = normalizer(data_org[:,16:19])\n",
    "acc[:,3] = denormalizer(torch.norm(temp, p=2, dim=1),tmax)\n",
    "mass = data_org[:,0]\n",
    "\n",
    "data[:,0] = vel\n",
    "data[:,1:5] = acc\n",
    "data[:,5] = mass\n",
    "\n",
    "# Normalize the data\n",
    "eps = 1e-5\n",
    "data_min = data[:,:6].min(axis=0, keepdim=True).values\n",
    "data_max = data[:,:6].max(axis=0, keepdim=True).values\n",
    "data[:,:6] = (data[:,:6] - data_min) / (data_max - data_min)+eps\n",
    "\n",
    "\n",
    "# Wrap the feature tensor in a TensorDataset\n",
    "# Each item from the dataset will be a tuple containing one tensor (X[i],)\n",
    "dataset = TensorDataset(data)\n",
    "\n",
    "# Define the proportion for the test set (e.g., 20%)\n",
    "test_ratio = 0.2\n",
    "num_test = int(num_samples * test_ratio)\n",
    "num_train = num_samples - num_test\n",
    "\n",
    "# Use random_split to split the dataset into train and test subsets\n",
    "# Define generator with a fixed seed\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_dataset, test_dataset = random_split(dataset, [num_train, num_test], generator=generator)\n",
    "\n",
    "# Create DataLoaders for the training and testing datasets\n",
    "batch_size = 8\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.2343e-01, 4.0010e-02, 3.2632e-03, 3.9425e-04, 4.0169e-05, 1.0000e+00],\n",
       "        [2.2343e-01, 4.0010e-02, 3.2632e-03, 3.9425e-04, 4.0169e-05, 1.0000e+00],\n",
       "        [2.2344e-01, 4.0010e-02, 3.2632e-03, 6.5004e-05, 1.1570e-05, 1.0000e+00],\n",
       "        ...,\n",
       "        [3.1449e-01, 1.0010e-02, 2.9902e-04, 1.8662e-05, 1.0249e-05, 1.0000e-05],\n",
       "        [1.8249e-03, 2.1083e-05, 1.0070e-05, 1.0000e-05, 1.0000e-05, 1.0000e+00],\n",
       "        [2.0696e-01, 1.1211e-03, 1.7046e-05, 1.0042e-05, 1.0000e-05, 1.0000e-05]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:,:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.5110e+04,  1.2500e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -8.3790e+02,  0.0000e+00, -5.6160e+07,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  3.7640e+12,  0.0000e+00,  1.7660e+18,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.2130e+23,  0.0000e+00,  1.4650e-06,\n",
      "          3.5110e+04, -1.2500e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          8.3790e+02,  0.0000e+00,  5.6160e+07,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.7640e+12,  0.0000e+00, -1.7660e+18,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  3.2130e+23,  0.0000e+00,  1.4650e-06,\n",
      "          1.0747e-04, -2.4659e+10],\n",
      "        [ 3.5110e+04, -1.2500e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          8.3790e+02,  0.0000e+00,  5.6160e+07,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.7640e+12,  0.0000e+00, -1.7660e+18,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  3.2130e+23,  0.0000e+00,  1.4650e-06,\n",
      "          3.5110e+04,  1.2500e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -8.3790e+02,  0.0000e+00, -5.6160e+07,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  3.7640e+12,  0.0000e+00,  1.7660e+18,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.2130e+23,  0.0000e+00,  1.4650e-06,\n",
      "          1.0747e-04, -2.4659e+10]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import structures\n",
    "importlib.reload(structures)\n",
    "from structures import *\n",
    "import losses\n",
    "importlib.reload(losses)\n",
    "from losses import *\n",
    "TargetEnergyError = 1e-8\n",
    "criterion = CustomizableLoss3DM(nParticle=2, nAttribute=13, nBatch=batch_size,alpha=0.1, beta=0.1, gamma=10.0, TargetEnergyError=TargetEnergyError,\n",
    "                            data_min=data_min, data_max=data_max,device=device)\n",
    "X = data[:2,:]\n",
    "print(data_org[:2,:])#, data[:2,:])\n",
    "#loss, loss_terms = criterion(output[:2,:], X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-13 20:13:40,713] [INFO] [logging.py:128:log_dist] [Rank -1] DeepSpeed info: version=0.16.4, git-hash=unknown, git-branch=unknown\n",
      "[2025-04-13 20:13:40,714] [INFO] [comm.py:658:init_distributed] cdb=None\n",
      "[2025-04-13 20:13:40,714] [INFO] [comm.py:673:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-13 20:13:41,841] [INFO] [comm.py:728:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=10.250.149.94, master_port=29500\n",
      "[2025-04-13 20:13:41,842] [INFO] [comm.py:689:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2025-04-13 20:13:41,845] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "Ignoring value for oob_tcp_if_exclude on workergpu094 (10.250.112.0/20: Did not find interface matching this subnet).\n",
      "(You can safely ignore this message.)\n",
      "--------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-13 20:13:47,085] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /dev/shm/.cache-yjo10/torch_extensions/py310_cu123 as PyTorch extensions root...\n",
      "Creating extension directory /dev/shm/.cache-yjo10/torch_extensions/py310_cu123/fused_adam...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /dev/shm/.cache-yjo10/torch_extensions/py310_cu123/fused_adam/build.ninja...\n",
      "Building extension module fused_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    }
   ],
   "source": [
    "import structures\n",
    "importlib.reload(structures)\n",
    "from structures import *\n",
    "import losses\n",
    "importlib.reload(losses)\n",
    "from losses import *\n",
    "import trainer\n",
    "importlib.reload(trainer)\n",
    "from trainer import *\n",
    "\n",
    "input_mask = np.r_[0:3,5]\n",
    "print\n",
    "input_size = len(input_mask)\n",
    "#hidden_dims = [32,64,64,32]     # Number of hidden neurons\n",
    "#hidden_dims = [8,16,16,4]     # Number of hidden neurons\n",
    "hidden_dims = [12,12,6]     # Number of hidden neurons\n",
    "#hidden_dims = [16,128,32,8]     # Number of hidden neurons\n",
    "#hidden_dims = [8,8]     # Number of hidden neurons\n",
    "output_size = 2     # Number of output \n",
    "TargetEnergyError = 1e-3\n",
    "weights = {\"time_step\":10, \"energy_loss\":1}\n",
    "\n",
    "# Instantiate the model\n",
    "try: \n",
    "    del mode\n",
    "    l\n",
    "    print(\"model deleted\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "ds_config = {\n",
    "    \"train_batch_size\": batch_size,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"Adam\",\n",
    "        \"params\": {\"lr\": 1e-3, \"betas\": [0.9, 0.999], \"eps\": 1e-8}\n",
    "    },\n",
    "    \"fp32\": {\n",
    "        \"enabled\": True  # Enables mixed precision training\n",
    "    },\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 1  # Enable ZeRO Stage 1 for memory optimization\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "#model = SimpleNN(input_size, hidden_size, output_size).to(device)\n",
    "model = FullyConnectedNN(input_dim=input_size, output_dim=output_size, hidden_dims=hidden_dims, activation='relu', dropout=0.0, output_positive=False).to(device)\n",
    "\n",
    "\n",
    "model_engine, optimizer, _, _ = deepspeed.initialize(\n",
    "    model=model,\n",
    "    model_parameters=model.parameters(),\n",
    "    config=ds_config\n",
    ")\n",
    "\n",
    "# Define the loss function (CrossEntropyLoss is common for classification tasks)\n",
    "criterion = CustomizableLoss3DM(nParticle=2, nAttribute=20, nBatch=batch_size,alpha=weights['time_step'], beta=weights['energy_loss'], gamma=weights['energy_loss'], TargetEnergyError=TargetEnergyError,\n",
    "                            data_min=data_min, data_max=data_max,device=device)\n",
    "\n",
    "# Define the optimizer (Stochastic Gradient Descent in this example)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "#optimizer = optim.AdamW(model.parameters(), lr=0.00001)\n",
    "#optimizer = optim.AdamW(model.parameters(), lr=0.00001)\n",
    "\n",
    "\n",
    "\n",
    "# Paths to save best and last models\n",
    "base_path = \"/mnt/home/yjo10/projects/AITimeStepper/data/models/two_body/\"\n",
    "best_val_path = base_path + \"best_model_loss.pth\"\n",
    "best_timestep_path = base_path + \"best_model_timestep.pth\"\n",
    "#last_model_path = base_path + f\"last_model_{epoch}.pth\"\n",
    "best_val_loss = float(\"inf\")\n",
    "best_largest_timestep = 0\n",
    "with open(base_path+\"c++/normalization_factors.txt\", \"w\") as f:\n",
    "    f.write(f\"{data_min[0][0]} {data_min[0][1]} {data_min[0][2]} {data_min[0][3]} {data_min[0][4]} {data_min[0][5]}\\n\")    \n",
    "    f.write(f\"{data_max[0][0]} {data_max[0][1]} {data_max[0][2]} {data_max[0][3]} {data_max[0][4]} {data_max[0][5]}\\n\")    \n",
    "\n",
    "example_input = torch.randn(1, input_size).to(device)\n",
    "exp_time_step = 1\n",
    "exp_energy_loss = 1\n",
    "# Training routine\n",
    "num_epochs = 1000\n",
    "lists = {\"training_loss\":[], \"val_loss\":[], \"training_energy\":[], \"val_energy\":[], \"training_time_step\":[], \"val_time_step\":[]}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    #train_loss, train_energy = \\\n",
    "    #    train_one_epoch(model, optimizer, criterion, train_loader, input_mask, weights, device)\n",
    "    train_res = train_one_epoch_deepspeed(model_engine, optimizer, criterion, train_loader, input_mask, weights, device)\n",
    "        \n",
    "    #test_loss, energy_error, energy_error_std, energy_error_fiducial, energy_error_fiducial_std, energy_pred, energy_init, time_step, time_step_fiducial = \\\n",
    "    #    validate(model, criterion, test_loader, input_mask, weights, device)\n",
    "    val_res = validate_deepspeed(model_engine, criterion, test_loader, input_mask, weights, device)\n",
    "\n",
    "    lists[\"training_loss\"].append(train_res[\"train_loss\"])\n",
    "    lists[\"training_energy\"].append(train_res[\"energy_error\"])\n",
    "    lists[\"training_time_step\"].append(train_res[\"time_step\"])\n",
    "\n",
    "    lists[\"val_loss\"].append(val_res[\"val_loss\"])\n",
    "    lists[\"val_energy\"].append(val_res[\"energy_error\"])\n",
    "    lists[\"val_time_step\"].append(val_res[\"time_step\"])\n",
    "\n",
    "    if epoch > 5:\n",
    "        # Save the best model based on validation loss\n",
    "        if val_res['val_loss'] < best_val_loss:\n",
    "            best_val_loss = val_res['val_loss']\n",
    "            torch.save(model.state_dict(), best_val_path)\n",
    "            #traced_model = torch.jit.trace(model, example_input)\n",
    "            traced_model = torch.jit.script(model)\n",
    "            traced_model.save(base_path + f\"c++/best_model_loss.pt\")\n",
    "            print(f\"--> Best model saved at epoch {epoch} with val loss {best_val_loss:.4e}\")\n",
    "        \n",
    "        # Save the best model based on validation largest timestep\n",
    "        if val_res['time_step'] > best_largest_timestep:\n",
    "            best_largest_timestep = val_res['time_step']\n",
    "            torch.save(model.state_dict(), best_timestep_path)\n",
    "            #traced_model = torch.jit.trace(model, example_input)\n",
    "            traced_model = torch.jit.script(model)\n",
    "            traced_model.save(base_path + f\"c++/best_model_timestep.pt\")\n",
    "            print(f\"--> Best model saved at epoch {epoch} with largest timestep {best_largest_timestep:.4e}\")\n",
    "\n",
    "    # Save the last model after every epoch (or just once at the end)\n",
    "    torch.save(model.state_dict(), base_path + f\"model_{epoch}.pth\")\n",
    "    #traced_model = torch.jit.trace(model, example_input)\n",
    "    traced_model = torch.jit.script(model)\n",
    "    traced_model.save(base_path + f\"c++/model_{epoch}.pt\")\n",
    "\n",
    "\n",
    "\n",
    "    fig, axes = pu.generateAxesForMultiplePlots(shape=(1,3),figsize=(10,10),hspace=0.1,wspace=0.1,\n",
    "                                    gridspec=None)\n",
    "    for i, (key, value) in enumerate(lists.items()):\n",
    "        y = i//2\n",
    "        axes[y].plot(range(epoch+1), value, label=key)\n",
    "        axes[y].scatter(range(epoch+1), value)\n",
    "    axes[0].set_yscale(\"log\")\n",
    "    axes[2].set_yscale(\"log\")\n",
    "\n",
    "    axes[0].grid()\n",
    "    axes[1].grid()\n",
    "    axes[2].grid()\n",
    "\n",
    "\n",
    "    axes[2].axhline(y=val_res['time_step_fiducial'], c='r',alpha=0.5,zorder=-1,label=\"Timestep Fiducial\")\n",
    "    axes[1].axhline(y=np.log10(TargetEnergyError), c='r',alpha=0.5,zorder=-1,label=\"Target energy\")\n",
    "    #plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left', borderaxespad=0.)\n",
    "    axes[0].legend()\n",
    "    axes[1].legend()\n",
    "    axes[2].legend()\n",
    "    #plt.tight_layout()\n",
    "    axes[0].set_ylabel(\"Loss\")\n",
    "    axes[1].set_ylabel(\"log(Relative Error of Energy)\")\n",
    "    axes[2].set_ylabel(\"Timestep\")\n",
    "    axes[2].set_xlabel(\"epoch\")\n",
    "    plt.savefig(\"learning_curve.png\",dpi=100)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    fig, axes = pu.generateAxesForMultiplePlots(shape=(1,2),figsize=(10,15),hspace=0.1,wspace=0.1,\n",
    "                                    gridspec=None)\n",
    "    # Get one batch from the validation loader\n",
    "    dataiter = iter(train_loader)\n",
    "    inputs, = next(dataiter)\n",
    "\n",
    "    # Determine how many samples to take (if batch size < 50, take the whole batch)\n",
    "    num_samples = min(50, batch_size)\n",
    "\n",
    "    # Randomly select indices from the batch\n",
    "    indices = random.sample(range(batch_size), num_samples)\n",
    "    sampled_inputs = inputs[:,input_mask][indices]\n",
    "    sampled_targets = inputs[indices,25]\n",
    "\n",
    "    # Compute model predictions with no gradient computation\n",
    "    with torch.no_grad():\n",
    "        sampled_predictions = model(sampled_inputs)\n",
    "\n",
    "    # Convert tensors to numpy arrays for plotting\n",
    "    sampled_predictions = sampled_predictions[:,0].cpu().numpy().flatten()\n",
    "    sampled_targets = sampled_targets.cpu().numpy().flatten()\n",
    "\n",
    "    # Create sample indices for the x-axis (1st sample, 2nd sample, etc.)\n",
    "    sample_indices = list(range(1, num_samples + 1))\n",
    "\n",
    "    # Plot predictions and ground truth vs sample number\n",
    "    # plt.figure(figsize=(8, 6))\n",
    "    # Add vertical lines for each data point\n",
    "    for x in sample_indices:\n",
    "        axes[0].axvline(x=x, color='grey', linestyle='-', alpha=0.2,zorder=0)\n",
    "    axes[0].scatter(sample_indices, sampled_targets, marker='o', label='Ground Truth', fc=\"none\", ec=\"k\",zorder=10)\n",
    "    axes[0].scatter(sample_indices, np.power(10,sampled_predictions), marker='s', label='Predictions', fc=\"none\",ec=\"r\" ,zorder=10)\n",
    "    axes[0].set_yscale(\"log\")\n",
    "    axes[0].set_xlabel('Sample Number')\n",
    "    axes[0].set_ylabel('Value')\n",
    "\n",
    "    # Get one batch from the validation loader\n",
    "    dataiter = iter(test_loader)\n",
    "    inputs, = next(dataiter)\n",
    "\n",
    "    # Determine how many samples to take (if batch size < 50, take the whole batch)\n",
    "    num_samples = min(50, batch_size)\n",
    "\n",
    "    # Randomly select indices from the batch\n",
    "    indices = random.sample(range(batch_size), num_samples)\n",
    "    sampled_inputs = inputs[:,input_mask][indices]\n",
    "    sampled_targets = inputs[indices,25]\n",
    "\n",
    "    # Compute model predictions with no gradient computation\n",
    "    with torch.no_grad():\n",
    "        sampled_predictions = model(sampled_inputs)\n",
    "\n",
    "    # Convert tensors to numpy arrays for plotting\n",
    "    sampled_predictions = sampled_predictions[:,0].cpu().numpy().flatten()\n",
    "    sampled_targets = sampled_targets.cpu().numpy().flatten()\n",
    "\n",
    "    # Create sample indices for the x-axis (1st sample, 2nd sample, etc.)\n",
    "    sample_indices = list(range(1, num_samples + 1))\n",
    "\n",
    "    # Plot predictions and ground truth vs sample number\n",
    "    # plt.figure(figsize=(8, 6))\n",
    "    # Add vertical lines for each data point\n",
    "    for x in sample_indices:\n",
    "        axes[1].axvline(x=x, color='grey', linestyle='-', alpha=0.2,zorder=0)\n",
    "    axes[1].scatter(sample_indices, sampled_targets, marker='o', label='Ground Truth', fc=\"none\", ec=\"k\",zorder=10)\n",
    "    axes[1].scatter(sample_indices, np.power(10,sampled_predictions), marker='s', label='Predictions', fc=\"none\",ec=\"r\" ,zorder=10)\n",
    "    axes[1].set_yscale(\"log\")\n",
    "    axes[1].set_xlabel('Sample Number')\n",
    "    axes[1].set_ylabel('Value')\n",
    "\n",
    "    axes[0].set_title(f'Epoch [{epoch}/{num_epochs}] Predictions and Ground Truth vs. Sample Number')\n",
    "    #plt.legend()\n",
    "    axes[0].grid()\n",
    "    axes[1].grid()\n",
    "    plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left', borderaxespad=0.)\n",
    "    plt.savefig(\"samples.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    if time_step < time_step_fiducial:\n",
    "        weights['time_step'] += 0.1*exp_time_step\n",
    "        exp_time_step += 1\n",
    "    else:\n",
    "        weights['time_step'] += 0\n",
    "        exp_time_step = 1\n",
    "\n",
    "    if energy_error > energy_error_fiducial:\n",
    "        weights['energy_loss'] += 0.1*exp_energy_loss\n",
    "        exp_energy_loss += 1\n",
    "    else:\n",
    "        weights['energy_loss'] += 0\n",
    "        exp_energy_loss = 1\n",
    "        \"\"\"\n",
    "\n",
    "    #print(f\"Epoch [{epoch}/{num_epochs}], Train Loss: {train_loss:.4e}, Test Loss: {test_loss:.4e}, Energy Loss: {energy_error:.4e}/{energy_error_fiducial:.4e}, std: {energy_error_std:.4e}/{energy_error_fiducial_std:.4e}, Time step: {time_step:.4e}/{time_step_fiducial:.4e}\")\n",
    "    #print(f\"Epoch [{epoch}/{num_epochs}], Train Loss: {train_res['train_loss']:.4e}, Val Loss: {val_res['val_loss']:.4e}, Energy Loss: {np.log10(train_res['energy_error']):.4e}/{np.log10(train_res['energy_error_fiducial']):.4e}, {np.log10(val_res['energy_error']):.4e}/{np.log10(val_res['energy_error_fiducial']):.4e}, Time step: {train_res['time_step']:.4e}/{train_res['time_step_fiducial']:.4e}, {val_res['time_step']:.4e}/{val_res['time_step_fiducial']:.4e}, {val_res['time_step_std']:.4e}/{val_res['time_step_fiducial_std']:.4e}\")\n",
    "    print(f\"Epoch [{epoch}/{num_epochs}], Timestep error: {train_res['time_step_relative_error']:.4e}/{val_res['time_step_relative_error']:.4e}, Energy Loss: {np.log10(train_res['energy_error']):.4e}/{np.log10(train_res['energy_error_fiducial']):.4e}, {np.log10(val_res['energy_error']):.4e}/{np.log10(val_res['energy_error_fiducial']):.4e}, Time step: {train_res['time_step']:.4e}/{train_res['time_step_fiducial']:.4e}, {val_res['time_step']:.4e}/{val_res['time_step_fiducial']:.4e}, {val_res['time_step_std']:.4e}/{val_res['time_step_fiducial_std']:.4e}\")\n",
    "    #print(f\"Epoch [{epoch}/{num_epochs}], Train Loss: {train_res['train_loss']:.4e}, Val Loss: {val_res['val_loss']:.4e}, Energy Loss: {np.log10(train_res['energy_error']):.4e}/{np.log10(train_res['energy_error_fiducial']):.4e}, {np.log10(val_res['energy_error']):.4e}/{np.log10(val_res['energy_error_fiducial']):.4e}, energy_pred: {energy_pred:.4e}/{energy_init:.4e}, Time step: {time_step:.4e}/{time_step_fiducial:.4e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retraining with different learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-11 15:02:30,809] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed info: version=0.16.4, git-hash=unknown, git-branch=unknown\n",
      "[2025-04-11 15:02:30,810] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 1\n",
      "[2025-04-11 15:02:30,813] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2025-04-11 15:02:30,814] [INFO] [logging.py:128:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adam as basic optimizer\n",
      "[2025-04-11 15:02:30,814] [INFO] [logging.py:128:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2025-04-11 15:02:30,814] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam\n",
      "[2025-04-11 15:02:30,815] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>\n",
      "[2025-04-11 15:02:30,815] [INFO] [logging.py:128:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 1 optimizer\n",
      "[2025-04-11 15:02:30,815] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 500000000\n",
      "[2025-04-11 15:02:30,816] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 500000000\n",
      "[2025-04-11 15:02:30,817] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2025-04-11 15:02:30,817] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-11 15:02:31,347] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states\n",
      "[2025-04-11 15:02:31,351] [INFO] [utils.py:782:see_memory_usage] MA 3.75 GB         Max_MA 7.47 GB         CA 7.48 GB         Max_CA 7 GB \n",
      "[2025-04-11 15:02:31,352] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 58.87 GB, percent = 5.8%\n",
      "[2025-04-11 15:02:31,686] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states\n",
      "[2025-04-11 15:02:31,687] [INFO] [utils.py:782:see_memory_usage] MA 3.75 GB         Max_MA 3.75 GB         CA 7.48 GB         Max_CA 7 GB \n",
      "[2025-04-11 15:02:31,688] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 58.88 GB, percent = 5.8%\n",
      "[2025-04-11 15:02:31,688] [INFO] [stage_1_and_2.py:550:__init__] optimizer state initialized\n",
      "[2025-04-11 15:02:32,021] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2025-04-11 15:02:32,023] [INFO] [utils.py:782:see_memory_usage] MA 3.75 GB         Max_MA 3.75 GB         CA 7.48 GB         Max_CA 7 GB \n",
      "[2025-04-11 15:02:32,023] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 58.88 GB, percent = 5.8%\n",
      "[2025-04-11 15:02:32,032] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer\n",
      "[2025-04-11 15:02:32,032] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = None\n",
      "[2025-04-11 15:02:32,033] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2025-04-11 15:02:32,033] [INFO] [logging.py:128:log_dist] [Rank 0] step=0, skipped=0, lr=[1e-05], mom=[[0.9, 0.999]]\n",
      "[2025-04-11 15:02:32,033] [INFO] [config.py:1001:print] DeepSpeedEngine configuration:\n",
      "[2025-04-11 15:02:32,034] [INFO] [config.py:1005:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2025-04-11 15:02:32,034] [INFO] [config.py:1005:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'intra_op_parallelism': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}\n",
      "[2025-04-11 15:02:32,034] [INFO] [config.py:1005:print]   amp_enabled .................. False\n",
      "[2025-04-11 15:02:32,034] [INFO] [config.py:1005:print]   amp_params ................... False\n",
      "[2025-04-11 15:02:32,035] [INFO] [config.py:1005:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2025-04-11 15:02:32,035] [INFO] [config.py:1005:print]   bfloat16_enabled ............. False\n",
      "[2025-04-11 15:02:32,036] [INFO] [config.py:1005:print]   bfloat16_immediate_grad_update  False\n",
      "[2025-04-11 15:02:32,036] [INFO] [config.py:1005:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2025-04-11 15:02:32,036] [INFO] [config.py:1005:print]   checkpoint_tag_validation_enabled  True\n",
      "[2025-04-11 15:02:32,036] [INFO] [config.py:1005:print]   checkpoint_tag_validation_fail  False\n",
      "[2025-04-11 15:02:32,038] [INFO] [config.py:1005:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1552bf460400>\n",
      "[2025-04-11 15:02:32,038] [INFO] [config.py:1005:print]   communication_data_type ...... None\n",
      "[2025-04-11 15:02:32,038] [INFO] [config.py:1005:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2025-04-11 15:02:32,038] [INFO] [config.py:1005:print]   curriculum_enabled_legacy .... False\n",
      "[2025-04-11 15:02:32,039] [INFO] [config.py:1005:print]   curriculum_params_legacy ..... False\n",
      "[2025-04-11 15:02:32,039] [INFO] [config.py:1005:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2025-04-11 15:02:32,040] [INFO] [config.py:1005:print]   data_efficiency_enabled ...... False\n",
      "[2025-04-11 15:02:32,040] [INFO] [config.py:1005:print]   dataloader_drop_last ......... False\n",
      "[2025-04-11 15:02:32,040] [INFO] [config.py:1005:print]   disable_allgather ............ False\n",
      "[2025-04-11 15:02:32,041] [INFO] [config.py:1005:print]   dump_state ................... False\n",
      "[2025-04-11 15:02:32,041] [INFO] [config.py:1005:print]   dynamic_loss_scale_args ...... None\n",
      "[2025-04-11 15:02:32,041] [INFO] [config.py:1005:print]   eigenvalue_enabled ........... False\n",
      "[2025-04-11 15:02:32,041] [INFO] [config.py:1005:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2025-04-11 15:02:32,042] [INFO] [config.py:1005:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2025-04-11 15:02:32,042] [INFO] [config.py:1005:print]   eigenvalue_layer_num ......... 0\n",
      "[2025-04-11 15:02:32,042] [INFO] [config.py:1005:print]   eigenvalue_max_iter .......... 100\n",
      "[2025-04-11 15:02:32,042] [INFO] [config.py:1005:print]   eigenvalue_stability ......... 1e-06\n",
      "[2025-04-11 15:02:32,043] [INFO] [config.py:1005:print]   eigenvalue_tol ............... 0.01\n",
      "[2025-04-11 15:02:32,044] [INFO] [config.py:1005:print]   eigenvalue_verbose ........... False\n",
      "[2025-04-11 15:02:32,044] [INFO] [config.py:1005:print]   elasticity_enabled ........... False\n",
      "[2025-04-11 15:02:32,045] [INFO] [config.py:1005:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2025-04-11 15:02:32,045] [INFO] [config.py:1005:print]   fp16_auto_cast ............... None\n",
      "[2025-04-11 15:02:32,045] [INFO] [config.py:1005:print]   fp16_enabled ................. False\n",
      "[2025-04-11 15:02:32,046] [INFO] [config.py:1005:print]   fp16_master_weights_and_gradients  False\n",
      "[2025-04-11 15:02:32,046] [INFO] [config.py:1005:print]   global_rank .................. 0\n",
      "[2025-04-11 15:02:32,046] [INFO] [config.py:1005:print]   grad_accum_dtype ............. None\n",
      "[2025-04-11 15:02:32,046] [INFO] [config.py:1005:print]   gradient_accumulation_steps .. 1\n",
      "[2025-04-11 15:02:32,047] [INFO] [config.py:1005:print]   gradient_clipping ............ 0.0\n",
      "[2025-04-11 15:02:32,047] [INFO] [config.py:1005:print]   gradient_predivide_factor .... 1.0\n",
      "[2025-04-11 15:02:32,048] [INFO] [config.py:1005:print]   graph_harvesting ............. False\n",
      "[2025-04-11 15:02:32,048] [INFO] [config.py:1005:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2025-04-11 15:02:32,048] [INFO] [config.py:1005:print]   initial_dynamic_scale ........ 65536\n",
      "[2025-04-11 15:02:32,049] [INFO] [config.py:1005:print]   load_universal_checkpoint .... False\n",
      "[2025-04-11 15:02:32,049] [INFO] [config.py:1005:print]   loss_scale ................... 0\n",
      "[2025-04-11 15:02:32,050] [INFO] [config.py:1005:print]   memory_breakdown ............. False\n",
      "[2025-04-11 15:02:32,050] [INFO] [config.py:1005:print]   mics_hierarchial_params_gather  False\n",
      "[2025-04-11 15:02:32,050] [INFO] [config.py:1005:print]   mics_shard_size .............. -1\n",
      "[2025-04-11 15:02:32,050] [INFO] [config.py:1005:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')\n",
      "[2025-04-11 15:02:32,051] [INFO] [config.py:1005:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2025-04-11 15:02:32,051] [INFO] [config.py:1005:print]   optimizer_legacy_fusion ...... False\n",
      "[2025-04-11 15:02:32,051] [INFO] [config.py:1005:print]   optimizer_name ............... adam\n",
      "[2025-04-11 15:02:32,052] [INFO] [config.py:1005:print]   optimizer_params ............. {'lr': 1e-05, 'betas': [0.9, 0.999], 'eps': 1e-08}\n",
      "[2025-04-11 15:02:32,052] [INFO] [config.py:1005:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2025-04-11 15:02:32,052] [INFO] [config.py:1005:print]   pld_enabled .................. False\n",
      "[2025-04-11 15:02:32,052] [INFO] [config.py:1005:print]   pld_params ................... False\n",
      "[2025-04-11 15:02:32,053] [INFO] [config.py:1005:print]   prescale_gradients ........... False\n",
      "[2025-04-11 15:02:32,053] [INFO] [config.py:1005:print]   scheduler_name ............... None\n",
      "[2025-04-11 15:02:32,053] [INFO] [config.py:1005:print]   scheduler_params ............. None\n",
      "[2025-04-11 15:02:32,054] [INFO] [config.py:1005:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2025-04-11 15:02:32,055] [INFO] [config.py:1005:print]   sparse_attention ............. None\n",
      "[2025-04-11 15:02:32,055] [INFO] [config.py:1005:print]   sparse_gradients_enabled ..... False\n",
      "[2025-04-11 15:02:32,055] [INFO] [config.py:1005:print]   steps_per_print .............. None\n",
      "[2025-04-11 15:02:32,056] [INFO] [config.py:1005:print]   tensor_parallel_config ....... dtype=torch.float16 autotp_size=0 tensor_parallel=TPConfig(tp_size=1, tp_grain_size=1, mpu=None, tp_group=None) injection_policy_tuple=None keep_module_on_host=False replace_with_kernel_inject=False\n",
      "[2025-04-11 15:02:32,056] [INFO] [config.py:1005:print]   timers_config ................ enabled=True synchronized=True\n",
      "[2025-04-11 15:02:32,056] [INFO] [config.py:1005:print]   train_batch_size ............. 64\n",
      "[2025-04-11 15:02:32,057] [INFO] [config.py:1005:print]   train_micro_batch_size_per_gpu  64\n",
      "[2025-04-11 15:02:32,057] [INFO] [config.py:1005:print]   use_data_before_expert_parallel_  False\n",
      "[2025-04-11 15:02:32,057] [INFO] [config.py:1005:print]   use_node_local_storage ....... False\n",
      "[2025-04-11 15:02:32,058] [INFO] [config.py:1005:print]   wall_clock_breakdown ......... False\n",
      "[2025-04-11 15:02:32,058] [INFO] [config.py:1005:print]   weight_quantization_config ... None\n",
      "[2025-04-11 15:02:32,059] [INFO] [config.py:1005:print]   world_size ................... 1\n",
      "[2025-04-11 15:02:32,059] [INFO] [config.py:1005:print]   zero_allow_untested_optimizer  False\n",
      "[2025-04-11 15:02:32,059] [INFO] [config.py:1005:print]   zero_config .................. stage=1 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False zeropp_loco_param=None mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True log_trace_cache_warnings=False\n",
      "[2025-04-11 15:02:32,060] [INFO] [config.py:1005:print]   zero_enabled ................. True\n",
      "[2025-04-11 15:02:32,060] [INFO] [config.py:1005:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2025-04-11 15:02:32,060] [INFO] [config.py:1005:print]   zero_optimization_stage ...... 1\n",
      "[2025-04-11 15:02:32,060] [INFO] [config.py:991:print_user_config]   json = {\n",
      "    \"train_batch_size\": 64, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"optimizer\": {\n",
      "        \"type\": \"Adam\", \n",
      "        \"params\": {\n",
      "            \"lr\": 1e-05, \n",
      "            \"betas\": [0.9, 0.999], \n",
      "            \"eps\": 1e-08\n",
      "        }\n",
      "    }, \n",
      "    \"fp32\": {\n",
      "        \"enabled\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 1\n",
      "    }\n",
      "}\n",
      "energy_error= tensor([2.9187e-02, 6.4229e-03, 1.1561e-02, 2.4053e-05, 4.8653e-06, 1.0755e-05,\n",
      "        4.4837e-07, 1.4614e-06, 6.3770e-05, 2.7613e-06, 5.2462e-04, 5.3520e-05,\n",
      "        2.0999e-06, 1.4940e-07, 2.8360e-04, 1.1009e-04, 4.8254e-03, 6.9439e-02,\n",
      "        3.1772e-02, 1.1599e+03, 2.6079e-04, 7.4074e-09, 6.8381e-02, 1.5439e-04,\n",
      "        3.4708e-06, 1.1229e-02, 2.1961e-02, 2.8931e-06, 3.4023e-04, 1.1535e-03,\n",
      "        5.4988e-02, 1.2251e-04, 3.2051e-04, 3.5957e-01, 2.8358e-02, 1.3572e-05,\n",
      "        6.2704e-04, 3.8108e-04, 3.5779e-06, 1.5745e-05, 7.1904e-06, 1.9113e-06,\n",
      "        2.2501e-04, 4.1352e-01, 7.2976e-01, 4.3401e-07, 1.7566e-02, 3.3153e-06,\n",
      "        1.9725e-02, 2.6875e-07, 2.2287e-04, 3.2946e-06, 8.6354e-03, 1.2804e-03,\n",
      "        3.1085e-06, 3.6601e-07, 9.6606e-04, 9.0814e-03, 1.1618e+03, 2.6662e-04,\n",
      "        8.8820e-08, 1.0727e-02, 3.6246e-08, 6.9036e-01], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([1.1382e+01, 3.4591e+00, 5.9909e+00, 1.3894e+01, 2.8362e+01, 2.0543e+01,\n",
      "        5.9442e+01, 4.2620e+01, 7.5761e+00, 3.4716e+01, 4.1614e-01, 8.5714e+00,\n",
      "        3.8018e+01, 7.7596e+01, 1.5881e+00, 4.8684e+00, 2.4772e+00, 1.7981e+01,\n",
      "        1.1962e+01, 1.9499e+02, 1.8065e+00, 1.3955e+02, 1.7851e+01, 3.4905e+00,\n",
      "        3.2074e+01, 5.8492e+00, 9.5436e+00, 3.4169e+01, 1.1624e+00, 2.0398e-02,\n",
      "        1.6057e+01, 4.4083e+00, 1.2947e+00, 3.4632e+01, 1.1188e+01, 1.8488e+01,\n",
      "        2.1785e-01, 9.3073e-01, 3.1730e+01, 1.7233e+01, 2.4354e+01, 3.9187e+01,\n",
      "        2.2249e+00, 3.6297e+01, 4.3464e+01, 5.9945e+01, 8.2138e+00, 3.2595e+01,\n",
      "        8.8918e+00, 6.7597e+01, 2.2534e+00, 3.2666e+01, 4.6478e+00, 6.1111e-02,\n",
      "        3.3335e+01, 6.2613e+01, 1.1926e-03, 4.8674e+00, 1.9503e+02, 1.7475e+00,\n",
      "        8.7028e+01, 5.6301e+00, 1.0455e+02, 4.2735e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(29.1889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([1.8559e-02, 3.4354e-06, 1.9539e-06, 6.3039e-03, 5.2248e-04, 1.5969e-05,\n",
      "        9.3117e-04, 1.8691e-01, 1.4784e-04, 3.6442e-02, 8.5334e-06, 1.1390e-02,\n",
      "        1.0445e-04, 3.9341e-01, 5.0925e-03, 2.2744e-06, 1.7484e-06, 2.0618e-07,\n",
      "        4.1928e-05, 7.2467e-07, 1.2683e-07, 5.5977e-03, 5.5961e-05, 3.1634e-01,\n",
      "        1.0393e-06, 2.6083e-04, 4.0731e-06, 3.2469e-05, 1.5155e-03, 4.2219e-05,\n",
      "        5.8957e-04, 2.2699e-06, 6.6221e-04, 2.9969e-05, 8.7923e-03, 9.2590e-06,\n",
      "        4.6495e-05, 5.5872e-07, 1.3760e-06, 2.3038e-06, 3.5456e-06, 1.2154e-04,\n",
      "        2.6113e-05, 7.3011e-02, 9.8600e-03, 4.7927e-01, 1.5321e-05, 1.0661e-04,\n",
      "        2.6482e-04, 6.1230e-04, 5.2546e-03, 5.3079e-05, 2.1505e-02, 4.7732e-05,\n",
      "        2.1622e-10, 3.9807e-01, 6.1257e-04, 7.7564e-05, 7.8038e-02, 1.3453e-04,\n",
      "        6.4599e-03, 1.2728e-03, 1.1004e-05, 7.6889e-06], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([8.5320e+00, 3.2190e+01, 3.8912e+01, 3.3899e+00, 4.2142e-01, 1.7116e+01,\n",
      "        5.0859e-03, 2.7359e+01, 3.6544e+00, 1.2929e+01, 2.2693e+01, 5.9183e+00,\n",
      "        5.1031e+00, 3.5699e+01, 2.6496e+00, 3.7040e+01, 4.0310e+01, 7.2025e+01,\n",
      "        1.0060e+01, 5.2270e+01, 8.0509e+01, 2.9665e+00, 8.3122e+00, 3.3141e+01,\n",
      "        4.7186e+01, 1.8060e+00, 3.0287e+01, 1.1747e+01, 1.7284e-01, 1.0016e+01,\n",
      "        2.7917e-01, 3.7064e+01, 1.6989e-01, 1.2303e+01, 4.7257e+00, 2.1923e+01,\n",
      "        9.4151e+00, 5.6098e+01, 4.3410e+01, 3.6884e+01, 3.1833e+01, 4.4415e+00,\n",
      "        1.3288e+01, 1.8409e+01, 5.2372e+00, 3.8097e+01, 1.7460e+01, 5.0113e+00,\n",
      "        1.7655e+00, 2.4062e-01, 2.7526e+00, 8.6200e+00, 9.4144e+00, 9.2547e+00,\n",
      "        2.3553e+02, 3.5840e+01, 2.4018e-01, 6.5365e+00, 1.8985e+01, 4.0238e+00,\n",
      "        3.4805e+00, 5.8172e-02, 2.0336e+01, 2.3697e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(21.7382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([6.3922e-06, 8.0266e-06, 1.3474e-04, 1.5091e-03, 2.6475e-03, 1.1801e-05,\n",
      "        1.2054e-03, 3.5026e-02, 8.0254e-08, 6.9237e-06, 5.6475e-06, 1.8645e-04,\n",
      "        2.7055e-09, 7.4781e-01, 1.0962e-04, 1.6301e-06, 1.4597e-01, 1.4683e-04,\n",
      "        2.8422e-06, 1.1302e+03, 2.3304e-06, 8.4905e-03, 1.7992e-09, 1.8211e-06,\n",
      "        1.2231e-06, 2.3555e-02, 1.8286e-07, 1.0184e-02, 6.0271e-03, 1.2605e-03,\n",
      "        2.0655e-06, 3.4125e-06, 1.8446e-01, 7.0544e-06, 1.6734e-02, 1.0575e-05,\n",
      "        4.6038e-05, 1.4820e-02, 4.1387e-03, 2.6052e-05, 3.9677e-07, 9.3890e-05,\n",
      "        4.8617e-06, 1.0035e-03, 2.9441e-02, 4.9633e-04, 7.2845e-05, 4.6647e-05,\n",
      "        3.6447e-02, 9.5202e-06, 1.2589e-02, 2.4967e-06, 3.3981e-03, 3.6565e-07,\n",
      "        9.4641e-03, 2.8620e-02, 1.7881e-01, 2.7505e-07, 1.9865e-03, 7.7697e-03,\n",
      "        1.0326e-03, 7.6964e-03, 1.0632e-04, 2.1726e-05], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([2.5530e+01, 2.3281e+01, 4.0176e+00, 1.6936e-01, 9.4790e-01, 1.9710e+01,\n",
      "        3.4892e-02, 1.2646e+01, 8.8931e+01, 2.4729e+01, 2.6797e+01, 2.8211e+00,\n",
      "        1.6436e+02, 4.3787e+01, 4.8875e+00, 4.1205e+01, 2.4834e+01, 3.6807e+00,\n",
      "        3.4377e+01, 1.9427e+02, 3.6744e+01, 4.5751e+00, 1.7498e+02, 3.9795e+01,\n",
      "        4.4975e+01, 9.9813e+00, 7.4077e+01, 5.3864e+00, 3.2266e+00, 5.3608e-02,\n",
      "        3.8222e+01, 3.2266e+01, 2.7221e+01, 2.4543e+01, 7.9380e+00, 2.0695e+01,\n",
      "        9.4758e+00, 7.2682e+00, 2.0175e+00, 1.3305e+01, 6.1343e+01, 5.5962e+00,\n",
      "        2.8370e+01, 1.1965e-05, 1.1440e+01, 4.9071e-01, 6.8613e+00, 9.3952e+00,\n",
      "        1.2930e+01, 2.1663e+01, 6.4153e+00, 3.5913e+01, 1.4963e+00, 6.2629e+01,\n",
      "        5.0513e+00, 1.1250e+01, 2.6898e+01, 6.7216e+01, 4.7109e-01, 4.2035e+00,\n",
      "        1.0317e-03, 4.1647e+00, 5.0234e+00, 1.4663e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(26.8944, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([1.5324e-07, 4.4715e-07, 1.4611e-01, 3.4794e-03, 2.2440e-06, 9.6103e-03,\n",
      "        1.4281e-02, 2.2640e-06, 1.1738e-04, 5.8271e-07, 1.7622e-04, 5.6150e-03,\n",
      "        4.2643e-05, 2.3554e+00, 3.1358e-04, 1.1852e-03, 4.2750e-06, 1.4024e-01,\n",
      "        1.1010e-05, 6.9977e-04, 4.8358e-07, 1.9136e-05, 5.2117e-04, 3.0641e-05,\n",
      "        7.5005e-04, 1.7166e-02, 2.1455e-02, 2.3124e-04, 7.1125e-07, 6.9751e-02,\n",
      "        5.9895e-04, 1.6112e-01, 4.3930e-03, 2.8839e-04, 8.3992e-06, 1.1152e-02,\n",
      "        4.3255e-01, 1.8654e-07, 3.1079e-07, 1.9094e-05, 1.4074e-02, 3.9392e-04,\n",
      "        4.5978e-04, 3.4560e-04, 2.3686e-01, 8.6821e-07, 3.3026e-02, 2.5045e-03,\n",
      "        2.8276e-06, 3.9528e-02, 9.9162e-05, 2.5571e-03, 1.0311e-02, 3.4123e-06,\n",
      "        7.9793e-07, 8.4098e-06, 4.1117e-05, 5.1014e-05, 3.9241e-06, 8.8589e-06,\n",
      "        7.3275e-03, 3.7888e-02, 1.1016e-05, 5.2125e-04], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([7.7150e+01, 5.9484e+01, 2.4844e+01, 1.5547e+00, 3.7204e+01, 5.1204e+00,\n",
      "        7.0699e+00, 3.7096e+01, 4.5898e+00, 5.5470e+01, 3.0137e+00, 2.9772e+00,\n",
      "        9.9534e+00, 6.0287e+01, 1.3449e+00, 2.8862e-02, 2.9757e+01, 2.4437e+01,\n",
      "        2.0331e+01, 1.2745e-01, 5.8283e+01, 1.5652e+01, 4.2467e-01, 1.2148e+01,\n",
      "        8.2726e-02, 8.0821e+00, 9.4000e+00, 2.1442e+00, 5.2540e+01, 1.8019e+01,\n",
      "        2.6273e-01, 2.5828e+01, 2.1904e+00, 1.5462e+00, 2.2845e+01, 5.8160e+00,\n",
      "        3.6841e+01, 7.3734e+01, 6.5228e+01, 1.5669e+01, 6.9924e+00, 8.6791e-01,\n",
      "        6.0374e-01, 1.1288e+00, 2.9893e+01, 4.9690e+01, 1.2231e+01, 8.4291e-01,\n",
      "        3.4437e+01, 1.3520e+01, 5.3407e+00, 8.8146e-01, 5.4440e+00, 3.2267e+01,\n",
      "        5.0887e+01, 2.2833e+01, 1.0185e+01, 8.8545e+00, 3.0699e+01, 2.2338e+01,\n",
      "        3.9666e+00, 1.3211e+01, 2.0326e+01, 4.2449e-01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(19.7881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([4.3873e-06, 3.0062e-05, 1.0653e-06, 2.3430e-03, 7.6461e-10, 3.2313e-03,\n",
      "        9.7141e-07, 2.2635e-06, 7.5736e-07, 2.6796e-05, 2.4494e-05, 3.0617e-06,\n",
      "        9.2186e-03, 8.1477e-03, 5.6273e-06, 6.9149e-07, 7.0997e-06, 2.1141e-07,\n",
      "        7.2066e-07, 4.8538e-06, 7.1337e-03, 4.2473e-03, 9.7458e-07, 4.9088e-06,\n",
      "        4.6058e-03, 1.2704e-03, 5.5413e-02, 3.0496e-02, 7.2317e-05, 3.6753e-07,\n",
      "        1.3003e-05, 1.5354e-03, 5.3551e-05, 2.1934e-04, 1.3397e-06, 2.9858e-04,\n",
      "        1.3041e-02, 1.1100e-07, 3.1908e-06, 9.0649e-04, 9.4314e-07, 7.4199e-05,\n",
      "        3.7623e-05, 5.7883e-06, 2.6872e-06, 1.4645e-02, 3.2817e-06, 7.7721e-04,\n",
      "        5.2831e-04, 2.9197e-02, 1.9518e-03, 1.4083e-06, 1.3382e-02, 2.1229e-03,\n",
      "        7.2842e-05, 1.7067e-02, 3.1196e-02, 2.3558e-03, 3.3918e-03, 6.6505e-03,\n",
      "        2.6155e-05, 5.6102e-03, 2.2448e-02, 4.1123e-01], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([2.9474e+01, 1.2281e+01, 4.6847e+01, 7.2496e-01, 1.9836e+02, 1.3757e+00,\n",
      "        4.8119e+01, 3.7099e+01, 5.1634e+01, 1.3101e+01, 1.3759e+01, 3.3510e+01,\n",
      "        4.9339e+00, 4.4005e+00, 2.6834e+01, 5.2950e+01, 2.4480e+01, 7.1601e+01,\n",
      "        5.2350e+01, 2.8387e+01, 3.8606e+00, 2.0917e+00, 4.8073e+01, 2.8267e+01,\n",
      "        2.3327e+00, 5.7294e-02, 1.6119e+01, 1.1680e+01, 6.8995e+00, 6.2548e+01,\n",
      "        1.8858e+01, 1.8389e-01, 8.5681e+00, 2.3017e+00, 4.3762e+01, 1.4610e+00,\n",
      "        6.5951e+00, 8.2918e+01, 3.3033e+01, 9.6394e-03, 4.8529e+01, 6.7652e+00,\n",
      "        1.0759e+01, 2.6542e+01, 3.5037e+01, 7.2043e+00, 3.2711e+01, 6.3524e-02,\n",
      "        4.0713e-01, 1.1384e+01, 4.4724e-01, 4.3104e+01, 6.7284e+00, 5.6665e-01,\n",
      "        6.8616e+00, 8.0495e+00, 1.1836e+01, 7.3423e-01, 1.4918e+00, 3.5899e+00,\n",
      "        1.3277e+01, 2.9742e+00, 9.6795e+00, 3.6230e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(22.7627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([5.2945e-06, 1.5286e-04, 1.3761e-02, 9.7079e-07, 1.9411e-06, 3.5892e-06,\n",
      "        3.8160e-06, 8.1103e-03, 3.3814e-02, 1.9974e-02, 4.8568e-06, 1.6359e-07,\n",
      "        3.5389e-08, 3.3642e-02, 1.3460e-06, 1.1002e-03, 6.9905e-03, 8.4910e-07,\n",
      "        3.6397e-03, 1.5825e-05, 4.5887e-04, 8.9151e-08, 3.4494e-06, 8.9692e-03,\n",
      "        7.2836e-08, 6.6698e-07, 3.6849e-07, 7.4100e-06, 1.0954e-04, 3.8475e-04,\n",
      "        9.7734e-07, 4.2524e-01, 9.8257e-03, 1.6395e-04, 1.7040e-04, 7.3744e-06,\n",
      "        1.9218e-04, 1.5076e-02, 4.8240e-06, 1.3886e+01, 1.3020e-02, 8.0523e-03,\n",
      "        2.4239e-03, 1.8397e-02, 9.5748e+00, 2.2789e-06, 1.7109e-07, 5.1120e-07,\n",
      "        3.2183e-05, 3.5163e-01, 1.1483e-02, 1.1226e-02, 6.9695e-07, 7.8936e-07,\n",
      "        3.9508e-06, 6.6641e-03, 1.1255e+03, 5.5629e-06, 5.5317e-03, 4.0951e-01,\n",
      "        3.1630e-04, 3.8639e-06, 2.8168e-06, 4.0397e-07], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([2.7469e+01, 3.5277e+00, 6.8739e+00, 4.8128e+01, 3.8994e+01, 3.1695e+01,\n",
      "        3.1009e+01, 4.3812e+00, 1.2397e+01, 8.9665e+00, 2.8381e+01, 7.6006e+01,\n",
      "        1.0504e+02, 1.2361e+01, 4.3700e+01, 9.1232e-03, 3.7813e+00, 5.0004e+01,\n",
      "        1.6690e+00, 1.7191e+01, 6.0682e-01, 8.6959e+01, 3.2144e+01, 4.8127e+00,\n",
      "        9.0770e+01, 5.3476e+01, 6.2507e+01, 2.4058e+01, 4.8904e+00, 9.1233e-01,\n",
      "        4.8034e+01, 3.6635e+01, 5.2212e+00, 3.2695e+00, 3.1315e+00, 2.4106e+01,\n",
      "        2.7202e+00, 7.3610e+00, 2.8453e+01, 9.0985e+01, 6.5869e+00, 4.3512e+00,\n",
      "        7.8390e-01, 8.4807e+00, 8.4032e+01, 3.7016e+01, 7.5226e+01, 5.7437e+01,\n",
      "        1.1808e+01, 3.4370e+01, 5.9578e+00, 5.8480e+00, 5.2835e+01, 5.1041e+01,\n",
      "        3.0623e+01, 3.5976e+00, 1.9415e+02, 2.6953e+01, 2.9258e+00, 3.6180e+01,\n",
      "        1.3250e+00, 3.0870e+01, 3.4482e+01, 6.1061e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(31.5715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([4.1341e-03, 2.7242e-05, 1.8374e-02, 2.9871e-01, 6.6513e-04, 6.8777e-06,\n",
      "        1.6164e-06, 2.8956e-06, 6.8033e-05, 4.1200e-04, 2.7584e-06, 5.8921e-04,\n",
      "        7.7454e-06, 2.0516e-06, 4.2819e-07, 5.0898e-07, 2.3010e-02, 1.3905e-03,\n",
      "        2.9489e-06, 4.0734e-02, 1.1144e-05, 7.4192e-05, 1.5684e-05, 5.1341e-02,\n",
      "        3.3169e-05, 3.8432e-08, 8.3700e-03, 3.0290e-01, 3.3147e-07, 1.2328e-01,\n",
      "        5.1347e-03, 4.1818e-02, 2.1804e-02, 4.4292e-01, 5.4137e-07, 6.6579e-07,\n",
      "        1.0967e-02, 6.5227e-02, 5.5376e-02, 2.1720e-05, 1.1900e-01, 3.8148e-05,\n",
      "        1.1393e-07, 1.9914e-05, 1.3588e-03, 4.4529e-03, 9.0262e-07, 1.7694e-04,\n",
      "        8.9634e-02, 2.9569e-05, 7.3381e-01, 1.0006e-03, 1.5621e-06, 1.5850e-05,\n",
      "        1.0765e-06, 1.2283e-02, 3.3029e-06, 1.6592e-01, 1.5694e-02, 5.7608e-05,\n",
      "        8.6300e-06, 9.6002e-03, 7.6720e-06, 7.4639e-04], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([2.0143e+00, 1.2982e+01, 8.4735e+00, 3.2484e+01, 1.6628e-01, 2.4795e+01,\n",
      "        4.1314e+01, 3.4159e+01, 7.2241e+00, 7.8627e-01, 3.4729e+01, 2.7981e-01,\n",
      "        2.3626e+01, 3.8305e+01, 6.0155e+01, 5.7504e+01, 9.8341e+00, 1.0866e-01,\n",
      "        3.3946e+01, 1.3742e+01, 2.0222e+01, 6.7657e+00, 1.7265e+01, 1.5512e+01,\n",
      "        1.1602e+01, 1.0336e+02, 4.5141e+00, 3.2643e+01, 6.4192e+01, 2.3179e+01,\n",
      "        2.6765e+00, 1.3938e+01, 9.4992e+00, 3.7129e+01, 5.6572e+01, 5.3502e+01,\n",
      "        5.7356e+00, 1.7455e+01, 1.6113e+01, 1.4665e+01, 2.2840e+01, 1.0669e+01,\n",
      "        8.2445e+01, 1.5338e+01, 9.4025e-02, 2.2307e+00, 4.9143e+01, 2.9997e+00,\n",
      "        2.0212e+01, 1.2398e+01, 4.3537e+01, 3.6831e-07, 4.1754e+01, 1.7178e+01,\n",
      "        4.6705e+01, 6.2911e+00, 3.2638e+01, 2.6128e+01, 7.5807e+00, 8.1458e+00,\n",
      "        2.2586e+01, 5.1157e+00, 2.3719e+01, 8.5557e-02], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(22.8593, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([1.3536e-05, 2.6224e-05, 5.0576e-06, 1.4157e+00, 1.0194e-06, 3.7926e-02,\n",
      "        2.1529e-04, 4.2812e-07, 1.2998e-05, 1.6259e-05, 3.7832e-03, 6.3255e-06,\n",
      "        7.2820e-08, 8.9045e-03, 2.3291e-06, 1.5920e-06, 9.9896e-04, 3.6678e-04,\n",
      "        1.7252e-01, 6.3016e-03, 4.2488e-07, 8.4268e-03, 6.1288e-03, 1.8167e-02,\n",
      "        2.9133e-08, 2.1889e-03, 3.1978e-03, 5.0979e-05, 2.5569e-05, 3.0044e-01,\n",
      "        3.7326e-02, 1.1877e-02, 1.0134e+00, 3.1452e-03, 2.0260e-05, 9.8088e-06,\n",
      "        1.0829e-03, 1.1100e-02, 5.3863e-02, 2.8484e-05, 5.7791e-06, 6.0028e-05,\n",
      "        2.4362e-03, 5.2459e-05, 7.9492e-07, 2.4865e-07, 1.7149e-02, 3.4815e-06,\n",
      "        1.4303e-03, 3.4787e-02, 4.4361e+00, 7.5175e-08, 5.2992e-05, 2.7421e-05,\n",
      "        6.8911e-05, 9.2733e-06, 8.0823e-07, 2.5176e-06, 1.9050e-02, 6.9817e-07,\n",
      "        9.8933e-05, 6.4607e-01, 5.6114e-06, 6.8198e-05], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([1.8510e+01, 1.3257e+01, 2.7951e+01, 5.2641e+01, 4.7452e+01, 1.3218e+01,\n",
      "        2.3586e+00, 6.0157e+01, 1.8861e+01, 1.6967e+01, 1.7704e+00, 2.5636e+01,\n",
      "        9.0774e+01, 4.7810e+00, 3.6751e+01, 4.1509e+01, 1.0808e-06, 1.0060e+00,\n",
      "        2.6528e+01, 3.3885e+00, 6.0275e+01, 4.5429e+00, 3.2870e+00, 8.4076e+00,\n",
      "        1.0907e+02, 6.1372e-01, 1.3513e+00, 8.8586e+00, 1.3442e+01, 3.2550e+01,\n",
      "        1.3102e+01, 6.1237e+00, 4.7902e+01, 1.3130e+00, 1.5203e+01, 2.1386e+01,\n",
      "        6.3376e-03, 5.7935e+00, 1.5892e+01, 1.2662e+01, 2.6559e+01, 7.9127e+00,\n",
      "        7.9291e-01, 8.6891e+00, 5.0941e+01, 6.8881e+01, 8.0765e+00, 3.2039e+01,\n",
      "        1.2810e-01, 1.2597e+01, 7.0518e+01, 9.0168e+01, 8.6296e+00, 1.2934e+01,\n",
      "        7.1553e+00, 2.1908e+01, 5.0704e+01, 3.5814e+01, 8.6852e+00, 5.2810e+01,\n",
      "        5.3514e+00, 4.1873e+01, 2.6863e+01, 7.2111e+00], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(24.1022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([3.2071e-05, 2.2265e-02, 2.5427e-01, 2.7339e-05, 3.5256e-02, 3.8900e-03,\n",
      "        6.3360e-05, 1.8930e-06, 1.2750e-02, 4.6644e-06, 2.7441e-06, 1.2084e-02,\n",
      "        1.4741e-02, 1.5910e-06, 3.2029e-08, 5.3281e-03, 2.3012e-02, 4.5159e-07,\n",
      "        4.9368e-07, 2.4171e-02, 5.2915e-05, 4.6043e-06, 5.9886e-08, 1.8468e-02,\n",
      "        1.8645e-06, 3.9226e-04, 1.2690e-06, 9.4158e-03, 1.5768e-01, 7.1877e-04,\n",
      "        2.8133e-04, 2.4801e-03, 2.7410e-05, 8.0283e-03, 2.2308e-08, 1.8934e-01,\n",
      "        1.2097e-03, 1.3389e-02, 4.0137e-03, 8.2841e-06, 1.4233e-03, 1.1229e+03,\n",
      "        3.3695e-06, 1.4276e-04, 1.1499e-06, 5.3247e+00, 1.6583e-02, 8.6854e-03,\n",
      "        3.1772e-08, 1.9397e-06, 5.9186e-03, 3.1333e-05, 3.2784e-06, 1.0944e-08,\n",
      "        1.2957e-03, 4.7788e-02, 1.2601e-02, 7.0306e-05, 3.1772e-08, 2.3400e-03,\n",
      "        1.0691e-02, 4.5674e-04, 1.0386e-07, 1.0315e-06], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([1.1832e+01, 9.6288e+00, 3.0674e+01, 1.2956e+01, 1.2692e+01, 1.8453e+00,\n",
      "        7.6116e+00, 3.9308e+01, 6.4799e+00, 2.8813e+01, 3.4790e+01, 6.2096e+00,\n",
      "        7.2394e+00, 4.1518e+01, 1.0710e+02, 2.7989e+00, 9.8345e+00, 5.9332e+01,\n",
      "        5.7967e+01, 1.0145e+01, 8.6381e+00, 2.8953e+01, 9.4538e+01, 8.5034e+00,\n",
      "        3.9498e+01, 8.7576e-01, 4.4482e+01, 5.0283e+00, 2.5610e+01, 1.0904e-01,\n",
      "        1.6084e+00, 8.2497e-01, 1.2937e+01, 4.3388e+00, 1.1472e+02, 2.7495e+01,\n",
      "        3.6247e-02, 6.7313e+00, 1.9313e+00, 2.2977e+01, 1.2460e-01, 1.9408e+02,\n",
      "        3.2410e+01, 3.7892e+00, 4.5807e+01, 7.3618e+01, 7.8869e+00, 4.6727e+00,\n",
      "        1.0727e+02, 3.9003e+01, 3.1616e+00, 1.1993e+01, 3.2723e+01, 1.3048e+02,\n",
      "        6.7101e-02, 1.4952e+01, 6.4201e+00, 7.0485e+00, 1.0727e+02, 7.2272e-01,\n",
      "        5.6140e+00, 6.1408e-01, 8.4134e+01, 4.7290e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(29.8399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([3.5826e-03, 1.3056e-05, 1.0013e-03, 6.8221e-06, 9.2152e-08, 2.2130e-01,\n",
      "        6.3259e-03, 4.5771e-05, 1.1651e-04, 1.2100e-02, 6.9468e-04, 5.4011e-06,\n",
      "        4.3148e-01, 9.7154e-05, 1.0067e-06, 2.2536e-07, 8.8369e-06, 2.5578e-06,\n",
      "        1.5676e-02, 1.1049e-02, 7.3010e-02, 1.1233e-03, 1.1285e-06, 3.5339e-08,\n",
      "        1.3037e-05, 1.8504e-07, 5.1036e-07, 1.5749e-06, 6.9137e-02, 1.3626e-04,\n",
      "        2.5029e-07, 1.2908e-06, 4.3882e-03, 6.8556e-07, 2.3336e-02, 5.4267e-03,\n",
      "        4.7818e-04, 5.3753e-06, 4.2215e-05, 6.8107e-03, 1.1974e-03, 3.0956e-06,\n",
      "        1.7440e-06, 2.8421e-04, 1.0704e-04, 5.1989e-05, 1.1438e-04, 3.7492e-06,\n",
      "        3.5435e-06, 1.2751e-03, 6.6056e-06, 1.3279e-06, 8.4704e-04, 1.2718e-06,\n",
      "        2.0337e-02, 2.0638e-02, 3.2730e-06, 2.2526e-06, 5.1181e-04, 5.4939e-05,\n",
      "        2.2484e-04, 5.9904e-05, 5.1307e-02, 5.3559e-06], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([1.6284e+00, 1.8823e+01, 1.7442e-06, 2.4876e+01, 8.6343e+01, 2.9155e+01,\n",
      "        3.4028e+00, 9.5117e+00, 4.6215e+00, 6.2161e+00, 1.3272e-01, 2.7260e+01,\n",
      "        3.6811e+01, 5.4357e+00, 4.7625e+01, 7.0523e+01, 2.2362e+01, 3.5624e+01,\n",
      "        7.5741e+00, 5.7714e+00, 1.8409e+01, 1.3526e-02, 4.6062e+01, 1.0507e+02,\n",
      "        1.8835e+01, 7.3873e+01, 5.7462e+01, 4.1648e+01, 1.7944e+01, 3.9728e+00,\n",
      "        6.8772e+01, 4.4256e+01, 2.1872e+00, 5.3075e+01, 9.9225e+00, 2.8606e+00,\n",
      "        5.4429e-01, 2.7310e+01, 1.0017e+01, 3.6806e+00, 3.2442e-02, 3.3383e+01,\n",
      "        4.0343e+01, 1.5826e+00, 4.9933e+00, 8.7423e+00, 4.7013e+00, 3.1206e+01,\n",
      "        3.1839e+01, 5.9064e-02, 2.5199e+01, 4.3879e+01, 2.7560e-02, 4.4453e+01,\n",
      "        9.0749e+00, 9.1634e+00, 3.2742e+01, 3.7157e+01, 4.4862e-01, 8.4189e+00,\n",
      "        2.2271e+00, 7.9243e+00, 1.5507e+01, 2.7348e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(22.9698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([3.6484e-07, 7.9987e-03, 9.5971e-03, 4.3805e-06, 1.6050e-03, 3.1793e-03,\n",
      "        4.7356e-06, 4.0808e-01, 5.6394e-06, 2.3433e-02, 1.3331e-01, 1.2873e-05,\n",
      "        1.4223e-02, 1.3952e-02, 2.2515e-05, 6.7929e-06, 3.4699e-06, 6.5739e-05,\n",
      "        4.1209e-04, 4.5140e-04, 2.3503e-02, 6.2285e-03, 1.0520e-05, 9.5732e-03,\n",
      "        5.9604e-04, 8.8271e+00, 5.6143e-05, 1.1195e+03, 3.9091e-04, 7.5855e-04,\n",
      "        6.0391e-05, 1.3447e-07, 4.3157e-07, 1.0907e-04, 2.1738e-03, 3.4888e-02,\n",
      "        1.5267e-06, 6.3349e-06, 1.4370e-04, 6.2285e-03, 2.2388e-06, 2.5652e-07,\n",
      "        3.1001e-07, 2.5567e-06, 1.7651e-07, 1.0076e-04, 1.1306e-06, 5.8331e-03,\n",
      "        3.0708e-07, 6.1221e-02, 1.1046e-06, 1.0284e-04, 1.4552e-06, 8.5862e-05,\n",
      "        2.2020e-04, 5.7341e-06, 1.0409e-04, 6.7956e-03, 1.8099e-04, 1.7544e-04,\n",
      "        1.2775e-03, 5.9999e-07, 2.7382e-06, 6.9080e-06], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([6.2664e+01, 4.3234e+00, 5.1142e+00, 2.9491e+01, 2.2383e-01, 1.3378e+00,\n",
      "        2.8651e+01, 3.6138e+01, 2.6812e+01, 9.9486e+00, 2.3938e+01, 1.8946e+01,\n",
      "        7.0483e+00, 6.9466e+00, 1.4391e+01, 2.4919e+01, 3.2077e+01, 7.4096e+00,\n",
      "        7.8588e-01, 6.3267e-01, 9.9676e+00, 3.3457e+00, 2.0743e+01, 5.1029e+00,\n",
      "        2.6774e-01, 8.2548e+01, 8.2936e+00, 1.9400e+02, 8.8224e-01, 7.6369e-02,\n",
      "        7.8787e+00, 7.9463e+01, 6.0033e+01, 4.9096e+00, 6.0292e-01, 1.2618e+01,\n",
      "        4.2051e+01, 2.5621e+01, 3.7638e+00, 3.3457e+00, 3.7232e+01, 6.8365e+01,\n",
      "        6.5269e+01, 3.5629e+01, 7.4687e+01, 5.2670e+00, 4.6037e+01, 3.1101e+00,\n",
      "        6.5422e+01, 1.6929e+01, 4.6352e+01, 5.1739e+00, 4.2675e+01, 6.0271e+00,\n",
      "        2.2898e+00, 2.6639e+01, 5.1189e+00, 3.6721e+00, 2.9217e+00, 3.0292e+00,\n",
      "        5.9984e-02, 5.5036e+01, 3.4815e+01, 2.4751e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(24.7471, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([3.1224e-05, 6.5858e-03, 3.8378e-06, 2.2108e-02, 2.5552e-03, 2.6805e-06,\n",
      "        2.6193e-04, 1.4337e-01, 4.0612e-05, 2.3251e-03, 4.7179e-05, 8.5755e-05,\n",
      "        5.9406e-07, 6.5929e-03, 1.0067e-02, 5.5248e-05, 3.5770e-02, 3.0755e-02,\n",
      "        4.7003e-05, 1.8848e-03, 3.3602e-03, 1.6142e-04, 6.5295e-04, 6.9006e-05,\n",
      "        1.5540e-06, 4.2965e-01, 7.2859e-06, 9.8619e-04, 4.6848e-07, 1.9029e-05,\n",
      "        1.3611e-03, 9.9386e-07, 2.2094e-10, 4.9272e-06, 2.9287e-06, 7.3342e-06,\n",
      "        2.2668e-06, 2.1808e-02, 1.2214e-06, 8.0899e-09, 1.5455e-03, 1.4201e-02,\n",
      "        3.2280e-06, 6.3710e-07, 4.0904e-05, 2.2381e-03, 1.3430e-06, 4.5049e-07,\n",
      "        7.5433e-10, 9.2049e-08, 8.4619e-06, 2.8691e-02, 1.5230e-03, 9.5908e-05,\n",
      "        3.2344e-08, 1.6883e-06, 3.4791e-06, 6.0855e-03, 3.1012e-07, 2.0872e-06,\n",
      "        6.6353e-03, 1.2485e-06, 3.0783e-03, 8.0714e-03], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([1.2017e+01, 3.5529e+00, 3.0945e+01, 9.5848e+00, 8.8009e-01, 3.5067e+01,\n",
      "        1.7948e+00, 2.4655e+01, 1.0264e+01, 7.1190e-01, 9.3257e+00, 6.0332e+00,\n",
      "        5.5183e+01, 3.5570e+00, 5.3328e+00, 8.3863e+00, 1.2796e+01, 1.1738e+01,\n",
      "        9.3486e+00, 4.0175e-01, 1.4689e+00, 3.3261e+00, 1.8169e-01, 7.1479e+00,\n",
      "        4.1821e+01, 3.6760e+01, 2.4224e+01, 1.9325e-04, 5.8768e+01, 1.5696e+01,\n",
      "        9.5043e-02, 4.7802e+01, 2.3487e+02, 2.8228e+01, 3.4026e+01, 2.4159e+01,\n",
      "        3.7081e+01, 9.5003e+00, 4.4994e+01, 1.3747e+02, 1.8953e-01, 7.0399e+00,\n",
      "        3.2900e+01, 5.4149e+01, 1.0218e+01, 6.4906e-01, 4.3730e+01, 5.9370e+01,\n",
      "        1.9874e+02, 8.6363e+01, 2.2774e+01, 1.1267e+01, 1.7698e-01, 5.4961e+00,\n",
      "        1.0690e+02, 4.0756e+01, 3.2047e+01, 3.2613e+00, 6.5263e+01, 3.8093e+01,\n",
      "        3.5812e+00, 4.4700e+01, 1.2642e+00, 4.3611e+00], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(29.8824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([2.7767e-05, 4.9071e-04, 9.2436e-07, 2.5191e-06, 1.0029e-05, 3.8215e-05,\n",
      "        7.1860e-07, 2.5797e-07, 7.5121e-03, 3.1923e-05, 1.7122e-06, 9.6875e-07,\n",
      "        2.3784e-01, 9.0325e-07, 7.7123e+00, 1.5224e-05, 1.8084e-04, 1.7787e-04,\n",
      "        1.1247e-03, 1.6137e-06, 2.9086e-07, 1.1317e-09, 7.0684e-07, 2.9669e-04,\n",
      "        1.0635e-03, 2.0203e-07, 2.5501e-07, 3.6667e-06, 4.3671e-03, 1.4702e-02,\n",
      "        4.6093e-08, 2.8656e-03, 6.0149e-05, 4.9009e+00, 9.0097e-03, 3.8666e-01,\n",
      "        8.9140e-05, 5.6601e-04, 1.4118e-04, 7.3203e-06, 2.5040e-07, 3.4320e-04,\n",
      "        1.0306e-01, 8.3173e-07, 4.9971e-06, 1.3617e-02, 2.6596e-02, 1.3073e-05,\n",
      "        4.0887e-06, 6.5159e-05, 1.6870e-04, 1.5766e+01, 1.0165e-06, 6.6471e-04,\n",
      "        1.0871e-03, 1.1375e+03, 9.1921e-05, 3.6758e-07, 2.6567e-05, 3.0536e-06,\n",
      "        2.6005e+00, 2.8399e-06, 1.8649e-06, 5.8717e-04], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([1.2844e+01, 5.0680e-01, 4.8810e+01, 3.5807e+01, 2.1181e+01, 1.0657e+01,\n",
      "        5.2392e+01, 6.8272e+01, 4.0663e+00, 1.1864e+01, 4.0576e+01, 4.8157e+01,\n",
      "        2.9939e+01, 4.9133e+01, 8.0113e+01, 1.7514e+01, 2.9246e+00, 2.9815e+00,\n",
      "        1.3820e-02, 4.1335e+01, 6.6303e+01, 1.8747e+02, 5.2631e+01, 1.4764e+00,\n",
      "        3.7915e-03, 7.2371e+01, 6.8462e+01, 3.1455e+01, 2.1730e+00, 7.2253e+00,\n",
      "        9.9697e+01, 1.1083e+00, 7.9013e+00, 7.2202e+01, 4.8326e+00, 3.5492e+01,\n",
      "        5.8445e+00, 3.2393e-01, 3.8325e+00, 2.4178e+01, 6.8765e+01, 1.1437e+00,\n",
      "        2.1486e+01, 5.0296e+01, 2.8078e+01, 6.8189e+00, 1.0763e+01, 1.8811e+01,\n",
      "        3.0245e+01, 7.4580e+00, 3.1672e+00, 9.3424e+01, 4.7491e+01, 1.6679e-01,\n",
      "        6.9775e-03, 1.9444e+02, 5.6969e+00, 6.2546e+01, 1.3163e+01, 3.3541e+01,\n",
      "        6.1834e+01, 3.4387e+01, 3.9496e+01, 2.8349e-01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(33.7121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([6.9282e-04, 3.3627e-06, 9.1863e-07, 1.1154e+03, 5.2813e-05, 1.1239e-06,\n",
      "        7.6634e-01, 4.0366e-01, 1.3731e-01, 5.1547e-03, 5.5222e-03, 4.1856e-01,\n",
      "        1.9364e-06, 6.6896e-05, 8.6325e-03, 2.6496e-04, 4.9001e-05, 2.4963e-03,\n",
      "        8.3224e-03, 9.0689e-04, 4.4017e-03, 1.7307e-06, 3.0591e-05, 1.2655e-02,\n",
      "        1.9616e-07, 1.6037e-07, 2.8657e-02, 7.6473e-08, 9.5899e-06, 6.9025e-03,\n",
      "        1.8152e-06, 1.9115e-06, 1.7764e-03, 1.6502e-05, 5.1590e-05, 1.4577e-05,\n",
      "        6.9557e-04, 1.2954e-03, 6.4732e-08, 7.6037e-01, 2.1040e-01, 6.1571e-05,\n",
      "        4.6675e-07, 1.0495e-02, 3.9035e-03, 3.3244e-04, 1.5303e-02, 8.9381e-03,\n",
      "        3.4163e-03, 4.4274e-05, 6.1304e-01, 9.7258e-03, 4.3754e-08, 3.7415e-04,\n",
      "        1.0826e-02, 3.9153e+00, 3.3551e-03, 6.8583e-05, 4.9938e-05, 3.6645e-03,\n",
      "        2.5120e-05, 2.7463e-03, 6.3712e-03, 2.7090e-07], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([1.3467e-01, 3.2433e+01, 4.8897e+01, 1.9390e+02, 8.6494e+00, 4.6117e+01,\n",
      "        4.4111e+01, 3.6007e+01, 2.4228e+01, 2.6893e+00, 2.9199e+00, 3.6443e+01,\n",
      "        3.9024e+01, 7.3149e+00, 4.6463e+00, 1.7640e+00, 9.0957e+00, 8.3684e-01,\n",
      "        4.4900e+00, 9.5515e-03, 2.1963e+00, 4.0440e+01, 1.2160e+01, 6.4417e+00,\n",
      "        7.2873e+01, 7.6353e+01, 1.1259e+01, 8.9843e+01, 2.1595e+01, 3.7322e+00,\n",
      "        3.9836e+01, 3.9186e+01, 3.3018e-01, 1.6845e+01, 8.7878e+00, 1.7879e+01,\n",
      "        1.3179e-01, 6.6977e-02, 9.3031e+01, 4.4007e+01, 2.8612e+01, 7.7705e+00,\n",
      "        5.8824e+01, 5.5268e+00, 1.8547e+00, 1.2129e+00, 7.4421e+00, 4.7975e+00,\n",
      "        1.5093e+00, 9.7179e+00, 4.1196e+01, 5.1746e+00, 1.0074e+02, 9.6647e-01,\n",
      "        5.6737e+00, 6.8437e+01, 1.4652e+00, 7.1808e+00, 8.9819e+00, 1.6866e+00,\n",
      "        1.3572e+01, 1.0206e+00, 3.4291e+00, 6.7466e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(24.9213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([6.8442e-06, 2.1198e-05, 6.5254e-02, 1.7998e-05, 8.8735e-03, 1.7712e-02,\n",
      "        2.1778e-04, 1.5280e-07, 3.1897e-08, 5.9729e-05, 5.1434e-08, 3.6305e-05,\n",
      "        3.8134e-06, 7.6698e-03, 2.4377e-05, 8.3658e-03, 6.8096e-04, 2.4701e-01,\n",
      "        2.4127e-03, 8.7207e-01, 1.2706e-03, 3.5033e-09, 1.3078e-03, 4.8980e-03,\n",
      "        2.3547e-02, 6.8928e-02, 5.4343e-03, 1.8139e-07, 3.8564e-02, 1.2075e-06,\n",
      "        9.6162e-04, 1.7620e-02, 7.2808e-04, 2.3943e-05, 2.8151e-02, 3.3560e-03,\n",
      "        4.4314e-05, 6.2630e-07, 3.9097e-03, 8.3145e-01, 6.6286e-03, 3.6823e-05,\n",
      "        3.0007e-06, 3.3836e-04, 3.8691e-02, 9.8843e-07, 1.2706e-03, 4.3450e-03,\n",
      "        1.0681e-07, 7.5123e-03, 1.1667e-02, 1.2905e-03, 1.8222e-05, 1.0244e-04,\n",
      "        1.1750e-05, 1.6643e-04, 7.3034e-05, 7.3657e-07, 4.7445e-01, 5.4673e-04,\n",
      "        2.5002e-06, 7.0792e-06, 1.8155e-01, 1.3391e-05], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([2.4844e+01, 1.4852e+01, 1.7458e+01, 1.6140e+01, 4.7658e+00, 8.2613e+00,\n",
      "        2.3234e+00, 7.7201e+01, 1.0718e+02, 7.9408e+00, 9.7520e+01, 1.0995e+01,\n",
      "        3.1016e+01, 4.1505e+00, 1.3795e+01, 4.5120e+00, 1.4765e-01, 3.0354e+01,\n",
      "        7.7575e-01, 4.5845e+01, 5.7355e-02, 1.5780e+02, 7.2012e-02, 2.5244e+00,\n",
      "        9.9793e+00, 1.7919e+01, 2.8654e+00, 7.4216e+01, 1.3339e+01, 4.5148e+01,\n",
      "        1.5314e-03, 8.2314e+00, 1.0071e-01, 1.3928e+01, 1.1140e+01, 1.4659e+00,\n",
      "        9.7123e+00, 5.4401e+01, 1.8590e+00, 4.5201e+01, 3.5773e+00, 1.0901e+01,\n",
      "        3.3743e+01, 1.1743e+00, 1.3364e+01, 4.7878e+01, 5.7355e-02, 2.1581e+00,\n",
      "        8.3621e+01, 4.0664e+00, 6.0356e+00, 6.5033e-02, 1.6041e+01, 5.1915e+00,\n",
      "        1.9748e+01, 3.2155e+00, 6.8478e+00, 5.2035e+01, 3.7972e+01, 3.6458e-01,\n",
      "        3.5897e+01, 2.4508e+01, 2.7056e+01, 1.8603e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(22.5650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([1.1611e-02, 5.2466e-07, 2.4549e-02, 1.7362e-06, 3.6951e-02, 1.2247e-03,\n",
      "        2.5194e-03, 3.9224e-03, 1.4342e-04, 4.6998e-06, 2.1839e-02, 4.7545e-04,\n",
      "        4.3948e-01, 1.6868e-02, 1.5150e-04, 6.5530e-03, 1.9846e-02, 3.1202e-03,\n",
      "        5.1090e-06, 3.7577e-03, 1.6450e-05, 1.0033e-05, 7.3665e-07, 2.9503e-02,\n",
      "        4.9267e-06, 6.8027e-08, 7.4471e-06, 2.0587e-05, 9.6739e-05, 2.7338e-05,\n",
      "        6.7938e-02, 1.1257e-07, 6.8351e-05, 9.0749e-04, 7.5378e-05, 7.4908e-03,\n",
      "        1.0256e-05, 4.0912e-03, 1.5145e-01, 6.2735e-06, 3.1000e-08, 1.0267e-02,\n",
      "        1.5570e-03, 6.2801e-06, 7.5595e-05, 1.1228e-01, 1.1071e-07, 1.1147e-01,\n",
      "        1.2179e-04, 2.0193e-03, 6.6618e-02, 1.1585e-06, 6.0374e-03, 1.7595e-06,\n",
      "        9.1072e-03, 2.4391e-03, 1.0020e-03, 1.8377e-02, 1.2772e+00, 2.8328e-05,\n",
      "        4.7285e-03, 3.9436e-03, 1.1287e+03, 3.6513e-06], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([6.0119e+00, 5.7044e+01, 1.0244e+01, 4.0400e+01, 1.3029e+01, 4.1077e-02,\n",
      "        8.5383e-01, 1.8679e+00, 3.7712e+00, 2.8732e+01, 9.5091e+00, 5.5277e-01,\n",
      "        3.7035e+01, 7.9828e+00, 3.5614e+00, 3.5341e+00, 8.9282e+00, 1.2948e+00,\n",
      "        2.7844e+01, 1.7524e+00, 1.6871e+01, 2.1178e+01, 5.2033e+01, 1.1455e+01,\n",
      "        2.8229e+01, 9.2076e+01, 2.4009e+01, 1.5078e+01, 5.4557e+00, 1.2956e+01,\n",
      "        1.7797e+01, 8.2663e+01, 7.1990e+00, 9.4227e-03, 6.6835e+00, 4.0549e+00,\n",
      "        2.0975e+01, 1.9849e+00, 2.5203e+01, 2.5719e+01, 1.0778e+02, 5.4238e+00,\n",
      "        1.9606e-01, 2.5709e+01, 6.6686e+00, 2.2288e+01, 8.2967e+01, 2.2220e+01,\n",
      "        4.4329e+00, 4.9386e-01, 1.7631e+01, 4.5707e+01, 3.2327e+00, 4.0230e+01,\n",
      "        4.8799e+00, 7.9503e-01, 3.8235e-06, 8.4745e+00, 5.1157e+01, 1.2701e+01,\n",
      "        2.4137e+00, 1.8826e+00, 1.9423e+02, 3.1502e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(22.3223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([7.6424e-06, 4.3258e-03, 3.0208e-05, 6.2291e-02, 3.7598e-03, 5.0679e-03,\n",
      "        1.4877e-07, 3.9278e-02, 8.4660e-04, 5.1353e-04, 4.8961e-06, 1.0299e-01,\n",
      "        4.0194e-01, 1.1211e+03, 2.9902e-06, 3.8568e-06, 4.4754e-04, 4.4376e-05,\n",
      "        2.8691e-07, 7.4068e-02, 2.3946e-06, 3.5790e-03, 8.0615e-09, 2.1893e-02,\n",
      "        1.5265e-06, 3.0387e-06, 4.3823e-08, 3.8325e-04, 2.5332e-04, 1.5097e-04,\n",
      "        7.1004e-02, 1.1624e-03, 1.0858e-02, 8.5362e-03, 1.5746e-03, 1.1633e-05,\n",
      "        7.2808e-02, 2.5044e-04, 1.5592e-03, 4.0096e-07, 8.3940e-05, 2.5463e-06,\n",
      "        4.8519e-04, 4.5414e-06, 1.4360e-04, 1.5563e-07, 8.7252e-05, 1.6233e-02,\n",
      "        1.2045e-05, 8.4514e-06, 9.5613e-07, 9.1419e-07, 1.0538e-04, 1.0061e-06,\n",
      "        2.2223e-02, 9.9675e-06, 1.9088e-03, 2.9692e-06, 8.1498e-07, 1.0859e-03,\n",
      "        9.1617e-07, 3.9552e-01, 7.2568e-03, 6.5527e-01], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([2.3756e+01, 2.1451e+00, 1.2247e+01, 1.7072e+01, 1.7539e+00, 2.6339e+00,\n",
      "        7.7671e+01, 1.3474e+01, 2.7733e-02, 4.4415e-01, 2.8295e+01, 2.1480e+01,\n",
      "        3.5956e+01, 1.9404e+02, 3.3784e+01, 3.0890e+01, 6.4639e-01, 9.7035e+00,\n",
      "        6.6526e+01, 1.8533e+01, 3.6416e+01, 1.6259e+00, 1.3756e+02, 9.5245e+00,\n",
      "        4.2052e+01, 3.3598e+01, 1.0071e+02, 9.1983e-01, 1.8854e+00, 3.5745e+00,\n",
      "        1.8171e+01, 2.2640e-02, 5.6878e+00, 4.5981e+00, 2.0612e-01, 1.9837e+01,\n",
      "        1.8385e+01, 1.9169e+00, 1.9731e-01, 6.1178e+01, 6.1388e+00, 3.5678e+01,\n",
      "        5.2305e-01, 2.9101e+01, 3.7664e+00, 7.6878e+01, 5.9485e+00, 7.7675e+00,\n",
      "        1.9529e+01, 2.2786e+01, 4.8339e+01, 4.8965e+01, 5.0633e+00, 4.7632e+01,\n",
      "        9.6170e+00, 2.1238e+01, 4.1794e-01, 3.3866e+01, 5.0586e+01, 6.7909e-03,\n",
      "        4.8934e+01, 3.5763e+01, 3.9281e+00, 4.2056e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(26.4635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([4.4649e-02, 6.6635e-01, 3.0403e-06, 7.5579e-07, 1.3373e-04, 2.9307e-06,\n",
      "        4.2493e-05, 6.4907e-06, 1.0863e-02, 9.3928e-02, 3.0717e-07, 7.7004e-05,\n",
      "        4.1823e-01, 2.1237e-05, 6.2989e-01, 4.0875e-04, 7.3577e-05, 9.9019e-04,\n",
      "        6.3930e-03, 8.7262e-03, 5.8902e-02, 8.5150e-07, 5.8146e-03, 5.2237e-04,\n",
      "        5.1922e-04, 3.0585e-05, 9.8696e-07, 9.7958e-09, 2.0815e-02, 1.3646e-03,\n",
      "        6.3398e-05, 2.3415e-01, 6.3101e-06, 2.4739e-06, 7.6237e-10, 4.2075e-05,\n",
      "        1.1248e+03, 1.1952e-03, 4.6299e-05, 1.9919e-02, 3.2390e-02, 7.7305e-03,\n",
      "        5.1449e-06, 1.4085e-03, 1.2026e-04, 1.5595e-06, 3.1074e-06, 1.0839e-05,\n",
      "        2.3557e-02, 2.8079e-06, 2.1019e-02, 8.3551e-03, 3.5109e-07, 3.3259e-04,\n",
      "        9.1816e-05, 2.0556e-01, 5.9498e-06, 2.9320e-07, 1.9846e-01, 9.5799e-03,\n",
      "        1.5569e-07, 1.0738e-05, 2.2049e-02, 4.7403e-06], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([1.4431e+01, 4.2274e+01, 3.3591e+01, 5.1664e+01, 4.0477e+00, 3.4018e+01,\n",
      "        9.9756e+00, 2.5375e+01, 5.6901e+00, 2.0635e+01, 6.5417e+01, 6.5736e+00,\n",
      "        3.6434e+01, 1.4838e+01, 4.1545e+01, 8.0040e-01, 6.8091e+00, 9.7229e-05,\n",
      "        3.4418e+00, 4.6930e+00, 1.6613e+01, 4.9964e+01, 3.0989e+00, 4.2169e-01,\n",
      "        4.2958e-01, 1.2161e+01, 4.7899e+01, 1.3302e+02, 9.2153e+00, 9.6649e-02,\n",
      "        7.6083e+00, 2.9767e+01, 2.5660e+01, 3.6023e+01, 1.9844e+02, 1.0038e+01,\n",
      "        1.9413e+02, 3.1782e-02, 9.4411e+00, 8.9500e+00, 1.2096e+01, 4.1827e+00,\n",
      "        2.7770e+01, 1.1734e-01, 4.4864e+00, 4.1776e+01, 3.3339e+01, 2.0472e+01,\n",
      "        9.9821e+00, 3.4520e+01, 9.2746e+00, 4.5066e+00, 6.3274e+01, 1.2119e+00,\n",
      "        5.7024e+00, 2.8363e+01, 2.6259e+01, 6.6173e+01, 2.7990e+01, 5.1061e+00,\n",
      "        7.6872e+01, 2.0557e+01, 9.5684e+00, 2.8640e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(27.7735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([1.1662e-02, 1.7867e-02, 1.0256e-02, 4.4221e-03, 1.4008e-04, 4.1205e-06,\n",
      "        3.6040e-07, 8.0665e-09, 2.1282e-01, 1.5593e-02, 6.0251e-03, 6.5075e-08,\n",
      "        2.4034e-05, 2.6923e-06, 4.4182e-02, 1.9533e-03, 1.5826e-05, 5.5878e-01,\n",
      "        4.4638e-07, 4.5725e-04, 7.5542e-07, 6.0649e-05, 6.8188e-05, 7.2691e-02,\n",
      "        1.2643e-02, 5.7789e-04, 2.0916e-04, 3.5194e-02, 2.5181e-06, 2.8329e-05,\n",
      "        1.7858e-03, 7.7349e-03, 4.7742e-04, 9.8221e-05, 1.5148e-01, 4.1688e-06,\n",
      "        6.9818e-05, 6.5048e-05, 7.0590e-01, 4.2817e-06, 4.1327e-03, 3.2039e-05,\n",
      "        1.4947e-06, 4.1203e-01, 1.1778e-08, 2.2296e-02, 1.3778e-07, 1.9171e-02,\n",
      "        2.6047e-01, 4.7460e-05, 1.5493e-05, 5.1124e-04, 2.9652e-06, 5.5408e-07,\n",
      "        7.3264e-06, 7.2253e+00, 4.0985e-04, 1.0967e-05, 2.4873e-06, 2.5861e-04,\n",
      "        1.1827e-03, 2.2534e-01, 4.4544e-04, 8.9589e-04], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([6.0338e+00, 8.3114e+00, 5.4189e+00, 2.2100e+00, 3.8634e+00, 3.0160e+01,\n",
      "        6.2858e+01, 1.3754e+02, 2.8734e+01, 7.5450e+00, 3.2254e+00, 9.2929e+01,\n",
      "        1.3900e+01, 3.5015e+01, 1.4351e+01, 4.4823e-01, 1.7190e+01, 4.0015e+01,\n",
      "        5.9511e+01, 6.1234e-01, 5.1671e+01, 7.8548e+00, 7.2118e+00, 1.8372e+01,\n",
      "        6.4371e+00, 3.0071e-01, 2.4482e+00, 1.2680e+01, 3.5811e+01, 1.2701e+01,\n",
      "        3.3625e-01, 4.1850e+00, 5.4667e-01, 5.3849e+00, 2.5205e+01, 3.0032e+01,\n",
      "        7.0855e+00, 7.4673e+00, 4.3027e+01, 2.9740e+01, 2.0134e+00, 1.1839e+01,\n",
      "        4.2326e+01, 3.6254e+01, 1.2881e+02, 9.6374e+00, 7.9030e+01, 8.7227e+00,\n",
      "        3.0941e+01, 9.2896e+00, 1.7367e+01, 4.5014e-01, 3.3882e+01, 5.6223e+01,\n",
      "        2.4170e+01, 7.8949e+01, 7.9560e-01, 2.0366e+01, 3.5959e+01, 1.8291e+00,\n",
      "        2.8156e-02, 2.9351e+01, 6.5397e-01, 1.2087e-02], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(24.0197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([1.6587e-08, 1.7025e-05, 3.8922e-02, 1.1657e-03, 4.5147e-07, 1.0129e-05,\n",
      "        8.4912e-07, 3.5851e-06, 1.6533e-07, 3.9558e-05, 1.7332e-06, 2.5722e-07,\n",
      "        1.8776e-01, 9.3987e-02, 7.4204e-03, 5.1065e-07, 7.9477e-07, 5.4727e-03,\n",
      "        1.4585e-05, 8.2809e-05, 1.6144e-06, 1.4644e-01, 7.5458e-05, 1.1172e-02,\n",
      "        1.4300e-02, 1.3628e-02, 2.0896e-06, 1.0485e-01, 5.4757e-07, 1.1658e-02,\n",
      "        4.2737e-07, 2.7586e-05, 5.7725e-03, 2.9345e-04, 9.7608e-06, 1.4860e-01,\n",
      "        3.7889e-03, 4.2192e-01, 2.1913e-06, 9.4540e-04, 2.0925e-06, 5.9835e-07,\n",
      "        1.0836e-05, 1.8920e-06, 8.0262e-08, 1.1798e-05, 6.0539e-07, 1.2959e-02,\n",
      "        6.9063e-07, 5.7635e-04, 1.3933e-05, 3.7301e-01, 2.2985e-06, 9.4540e-04,\n",
      "        2.0270e-06, 4.1389e-07, 3.2295e-03, 3.0445e-05, 8.5240e-07, 5.6979e-06,\n",
      "        4.6669e-07, 1.6927e-07, 4.1379e-01, 5.2396e-03], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([1.2115e+02, 1.6590e+01, 1.3407e+01, 2.3511e-02, 5.9336e+01, 2.1090e+01,\n",
      "        5.0003e+01, 3.1708e+01, 7.5822e+01, 1.0433e+01, 4.0421e+01, 6.8320e+01,\n",
      "        2.7407e+01, 2.0640e+01, 4.0170e+00, 5.7454e+01, 5.0943e+01, 2.8892e+00,\n",
      "        1.7874e+01, 6.2062e+00, 4.1329e+01, 2.4866e+01, 6.6780e+00, 5.8246e+00,\n",
      "        7.0769e+00, 6.8231e+00, 3.8078e+01, 2.1646e+01, 5.6400e+01, 6.0319e+00,\n",
      "        6.0185e+01, 1.2891e+01, 3.0734e+00, 1.5032e+00, 2.1431e+01, 2.5013e+01,\n",
      "        1.7744e+00, 3.6540e+01, 3.7495e+01, 3.1530e-03, 3.8061e+01, 5.5076e+01,\n",
      "        2.0475e+01, 3.9314e+01, 8.8929e+01, 1.9712e+01, 5.4903e+01, 6.5627e+00,\n",
      "        5.2968e+01, 3.0364e-01, 1.8262e+01, 3.5065e+01, 3.6912e+01, 3.1530e-03,\n",
      "        3.8455e+01, 6.0683e+01, 1.3744e+00, 1.2193e+01, 4.9949e+01, 2.6705e+01,\n",
      "        5.8827e+01, 7.5412e+01, 3.6305e+01, 2.7432e+00], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(30.3061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([2.2460e-03, 6.8796e-05, 3.0435e-03, 5.6694e-01, 1.0121e-02, 7.1754e-07,\n",
      "        6.9189e-05, 2.7605e-03, 2.5116e-04, 9.6681e-09, 9.6319e-09, 1.1755e-01,\n",
      "        9.7098e-05, 3.4959e-01, 5.8199e-04, 4.1284e-02, 1.9512e-06, 4.6598e-05,\n",
      "        2.6337e-03, 7.4611e-01, 1.0740e-05, 7.1325e-09, 5.5760e-07, 3.0421e-05,\n",
      "        2.9712e-06, 1.7600e-06, 3.1560e-02, 1.3623e-02, 2.2408e-06, 7.0493e-06,\n",
      "        4.8246e-07, 7.1754e-07, 5.8186e-07, 1.1938e-03, 1.2264e-05, 3.1313e-03,\n",
      "        1.2215e-06, 6.0544e-05, 7.6298e-06, 3.4199e-06, 5.9860e-04, 7.3162e-04,\n",
      "        1.2501e-03, 1.8317e-02, 3.4199e-06, 1.5444e+00, 1.7402e-03, 3.8026e-04,\n",
      "        1.9138e-06, 4.8597e-03, 2.3617e-05, 2.0108e-03, 1.6582e-04, 1.1601e-06,\n",
      "        3.3424e-02, 1.5592e-05, 1.7747e-06, 1.4940e-03, 4.3502e-05, 5.5074e-05,\n",
      "        6.8859e-04, 4.1361e-05, 8.6375e-03, 2.7211e-05], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([6.5470e-01, 7.1643e+00, 1.2388e+00, 4.0199e+01, 5.3575e+00, 5.2413e+01,\n",
      "        7.1338e+00, 1.0310e+00, 1.9090e+00, 1.3333e+02, 1.3341e+02, 2.2723e+01,\n",
      "        5.4384e+00, 3.4302e+01, 2.9301e-01, 1.3842e+01, 3.8929e+01, 9.4016e+00,\n",
      "        9.3778e-01, 4.3757e+01, 2.0556e+01, 1.4044e+02, 5.6128e+01, 1.2198e+01,\n",
      "        3.3858e+01, 4.0226e+01, 1.1916e+01, 6.8211e+00, 3.7221e+01, 2.4550e+01,\n",
      "        5.8318e+01, 5.2413e+01, 5.5492e+01, 3.1383e-02, 1.9369e+01, 1.3029e+00,\n",
      "        4.4993e+01, 7.8646e+00, 2.3772e+01, 3.2241e+01, 2.6334e-01, 9.7651e-02,\n",
      "        4.9841e-02, 8.4554e+00, 3.2241e+01, 5.3911e+01, 3.0691e-01, 9.3488e-01,\n",
      "        3.9171e+01, 2.4995e+00, 1.4031e+01, 4.8797e-01, 3.2286e+00, 4.5687e+01,\n",
      "        1.2315e+01, 1.7314e+01, 4.0121e+01, 1.6118e-01, 9.8279e+00, 8.4046e+00,\n",
      "        1.3921e-01, 1.0147e+01, 4.6488e+00, 1.2990e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(24.2283, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([1.9631e-07, 2.2173e-03, 2.1353e-07, 1.8986e-02, 2.3638e-02, 1.1483e-04,\n",
      "        1.0506e-03, 8.7600e-04, 2.3403e-03, 7.7379e-06, 2.5813e-06, 8.7223e-02,\n",
      "        1.0029e-05, 1.8318e-06, 6.1695e-06, 2.3403e-03, 8.5033e-04, 8.5671e-03,\n",
      "        1.0845e-06, 4.1243e-04, 1.6297e-04, 4.0715e-01, 4.8814e+00, 5.4871e-05,\n",
      "        5.7417e-03, 2.5547e-06, 1.5019e-03, 6.5313e-03, 4.7228e-03, 3.6720e-07,\n",
      "        6.4528e-07, 6.8473e-03, 2.9925e-06, 1.2599e-06, 4.3994e-01, 2.5701e-04,\n",
      "        1.1330e+03, 1.4036e-05, 9.7888e-02, 2.4507e-05, 7.5235e-08, 9.1895e-07,\n",
      "        9.9019e-04, 2.5547e-06, 5.3149e-03, 8.1025e-09, 1.6591e-08, 6.8473e-03,\n",
      "        1.1231e+00, 2.1763e-01, 8.6772e-03, 1.3231e-04, 1.1364e+03, 2.1590e-03,\n",
      "        1.3749e-03, 1.6635e-05, 8.0263e-03, 1.1354e-09, 9.8018e-05, 7.2536e-05,\n",
      "        2.1257e-05, 4.7915e-03, 5.1580e-02, 2.2954e-02], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([7.2860e+01, 6.3407e-01, 7.1432e+01, 8.6655e+00, 1.0004e+01, 4.6842e+00,\n",
      "        2.4388e-03, 1.7526e-02, 7.2295e-01, 2.3635e+01, 3.5515e+01, 1.9967e+01,\n",
      "        2.1181e+01, 3.9721e+01, 2.5889e+01, 7.2295e-01, 2.6285e-02, 4.6136e+00,\n",
      "        4.6603e+01, 7.8443e-01, 3.2913e+00, 3.6110e+01, 7.2134e+01, 8.4261e+00,\n",
      "        3.0546e+00, 3.5639e+01, 1.6542e-01, 3.5217e+00, 2.4099e+00, 6.2562e+01,\n",
      "        5.3961e+01, 3.7012e+00, 3.3775e+01, 4.4579e+01, 3.7047e+01, 1.8459e+00,\n",
      "        1.9433e+02, 1.8200e+01, 2.1011e+01, 1.3755e+01, 9.0153e+01, 4.8892e+01,\n",
      "        9.7224e-05, 3.5639e+01, 2.7906e+00, 1.3744e+02, 1.2115e+02, 3.7012e+00,\n",
      "        4.9335e+01, 2.8974e+01, 4.6686e+00, 4.0911e+00, 1.9442e+02, 5.9234e-01,\n",
      "        1.0138e-01, 1.6779e+01, 4.3377e+00, 1.8738e+02, 5.3945e+00, 6.8836e+00,\n",
      "        1.4831e+01, 2.4550e+00, 1.5548e+01, 9.8188e+00], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(31.6026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([6.5059e-02, 2.9927e-06, 2.4705e-07, 2.6064e-02, 6.8844e-06, 1.6232e-04,\n",
      "        7.2848e-02, 2.5153e-03, 3.8260e-03, 8.9728e-07, 8.4482e-03, 2.0894e-02,\n",
      "        1.2265e-05, 3.6064e-07, 2.2629e-05, 1.7583e-06, 5.4489e+01, 6.1244e-06,\n",
      "        3.5531e-06, 1.3346e-02, 3.4293e-06, 3.7474e-05, 2.1471e-06, 1.9454e-03,\n",
      "        8.6230e-06, 2.7400e-04, 5.0554e-03, 5.3333e-05, 3.2051e-09, 5.1814e-05,\n",
      "        1.6534e-05, 1.9148e-06, 1.4218e-02, 5.9624e-06, 1.0644e-06, 4.1104e-04,\n",
      "        1.1880e-01, 3.4616e-03, 1.1688e-02, 1.9740e-07, 2.4867e-07, 6.9131e-05,\n",
      "        1.8924e-05, 1.2771e-06, 5.4870e-02, 1.3990e-01, 5.3421e-07, 5.8437e-05,\n",
      "        3.9991e-02, 1.4597e-05, 2.2553e-07, 1.9465e-02, 4.7923e-04, 1.1903e-02,\n",
      "        1.1358e-04, 3.7266e-01, 4.3576e-06, 5.9069e-04, 7.4050e-08, 4.2533e-01,\n",
      "        3.7980e-03, 4.6176e-08, 1.0869e-05, 4.1751e-02], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([ 17.4331,  33.7745,  68.9881,  10.6313,  24.7854,   3.3059,  18.3901,\n",
      "          0.8508,   1.8005,  49.2262,   4.5537,   9.2384,  19.3689,  62.8475,\n",
      "         14.3530,  40.2392, 118.9355,  25.9639,  31.8088,   6.7144,  32.2102,\n",
      "         10.7854,  37.7441,   0.4429,  22.5941,   1.6761,   2.6259,   8.5919,\n",
      "        160.0422,   8.7622,  16.8292,  39.1646,   7.0465,  26.2378,  46.8582,\n",
      "          0.7904,  22.8238,   1.5419,   6.0446,  72.7661,  68.8799,   7.1383,\n",
      "         15.7397,  44.3975,  16.0398,  24.4127,  56.7720,   8.0645,  13.6061,\n",
      "         17.8668,  70.5104,   8.8128,   0.5411,   6.1345,   4.7317,  35.0542,\n",
      "         29.5483,   0.2772,  90.4546,  36.6371,   1.7808,  99.6613,  20.4468,\n",
      "         13.9257], device='cuda:0', grad_fn=<PowBackward0>)\n",
      "tensor(27.8160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([1.6519e-06, 2.1507e-02, 1.0606e-04, 6.2809e-04, 1.4794e-04, 4.8338e-04,\n",
      "        4.1043e-05, 9.7174e-08, 3.1251e-04, 7.9013e-05, 2.3500e-01, 5.3971e-02,\n",
      "        6.9369e-02, 2.8456e-02, 5.6101e-03, 1.3416e-04, 5.2560e-07, 3.7752e-07,\n",
      "        6.5102e-05, 2.2487e-03, 4.9568e-06, 1.1362e-04, 1.0112e-05, 2.9549e-05,\n",
      "        2.5803e-04, 4.4410e-04, 2.2188e-03, 9.7397e-03, 4.1749e-05, 1.3416e-04,\n",
      "        5.9373e-08, 8.6522e-05, 6.4012e-03, 2.5427e-03, 7.8276e-09, 2.0318e-03,\n",
      "        4.0950e-05, 1.2109e-03, 5.8081e-07, 1.5621e+00, 1.9198e-06, 5.4891e-07,\n",
      "        7.3661e-02, 5.6469e-06, 4.1464e-05, 8.8106e-07, 7.7109e-03, 5.8461e-05,\n",
      "        7.9602e-06, 3.1485e-06, 5.1401e-06, 3.2566e+00, 1.1236e+03, 7.4718e-07,\n",
      "        1.0584e-04, 7.7044e-05, 2.2705e-06, 1.4223e-02, 9.5586e-04, 2.3998e-01,\n",
      "        1.3847e-05, 1.2225e-03, 4.6616e-05, 4.6616e-05], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([4.1035e+01, 9.4148e+00, 5.0343e+00, 2.1629e-01, 3.6516e+00, 5.2846e-01,\n",
      "        1.0196e+01, 8.5359e+01, 1.3529e+00, 6.4422e+00, 2.9807e+01, 1.5908e+01,\n",
      "        1.7973e+01, 1.1212e+01, 2.9742e+00, 4.0350e+00, 5.7017e+01, 6.2124e+01,\n",
      "        7.4627e+00, 6.5670e-01, 2.8164e+01, 4.7304e+00, 2.1105e+01, 1.2402e+01,\n",
      "        1.8352e+00, 6.5886e-01, 6.3517e-01, 5.1811e+00, 1.0088e+01, 4.0350e+00,\n",
      "        9.4705e+01, 5.9896e+00, 3.4465e+00, 8.7089e-01, 1.3825e+02, 5.0258e-01,\n",
      "        1.0211e+01, 3.6630e-02, 5.5519e+01, 5.4078e+01, 3.9132e+01, 5.6364e+01,\n",
      "        1.8486e+01, 2.6798e+01, 1.0131e+01, 4.9483e+01, 4.1723e+00, 8.0622e+00,\n",
      "        2.3361e+01, 3.3187e+01, 2.7780e+01, 6.5423e+01, 1.9410e+02, 5.1829e+01,\n",
      "        5.0438e+00, 6.5709e+00, 3.7061e+01, 7.0484e+00, 2.0380e-03, 3.0036e+01,\n",
      "        1.8316e+01, 4.0371e-02, 9.3992e+00, 9.3992e+00], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(24.3135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([8.4122e-06, 3.6046e-08, 5.2559e-07, 3.9076e-03, 1.3391e-06, 7.9669e-02,\n",
      "        1.7199e-04, 4.4595e-05, 3.4093e-03, 6.0511e-07, 5.1921e+00, 1.0465e-04,\n",
      "        5.4403e-03, 1.9412e-01, 3.1738e-03, 1.7218e-02, 1.9021e-02, 7.2035e-05,\n",
      "        4.4364e-01, 1.1075e-02, 7.0533e-02, 5.5091e-05, 8.1551e-06, 2.5700e-03,\n",
      "        4.5883e-03, 1.1543e-03, 8.0809e-07, 1.8036e-05, 7.5893e-07, 1.9061e-06,\n",
      "        6.4439e-05, 2.1380e-03, 1.0706e-01, 1.4794e-06, 1.0632e-04, 1.5050e-04,\n",
      "        5.3834e-06, 3.2337e-02, 3.6103e-06, 1.2518e-02, 3.3724e-03, 1.3055e-05,\n",
      "        6.5847e-04, 3.3757e-02, 2.3440e-03, 6.0233e-07, 6.2762e-07, 1.0924e-05,\n",
      "        3.0383e-05, 2.0183e-06, 1.3988e-06, 1.3268e-09, 2.5851e-07, 5.0233e-05,\n",
      "        3.8060e-08, 3.2091e-09, 1.3559e-03, 6.8743e-02, 1.1024e-05, 2.1496e-04,\n",
      "        2.6993e-04, 4.3801e-01, 1.1231e+03, 7.2166e-02], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([2.2830e+01, 1.0467e+02, 5.7018e+01, 1.8576e+00, 4.3769e+01, 1.9166e+01,\n",
      "        3.0987e+00, 9.6729e+00, 1.5043e+00, 5.4910e+01, 7.3186e+01, 5.0946e+00,\n",
      "        2.8691e+00, 2.7757e+01, 1.3339e+00, 8.0994e+00, 8.6763e+00, 6.9201e+00,\n",
      "        3.7149e+01, 5.7826e+00, 1.8114e+01, 8.4029e+00, 2.3128e+01, 8.9099e-01,\n",
      "        2.3210e+00, 2.0598e-02, 5.0706e+01, 1.6123e+01, 5.1604e+01, 3.9221e+01,\n",
      "        7.5188e+00, 5.7740e-01, 2.1841e+01, 4.2459e+01, 5.0234e+00, 3.5864e+00,\n",
      "        2.7295e+01, 1.2084e+01, 3.1629e+01, 6.3867e+00, 1.4777e+00, 1.8824e+01,\n",
      "        1.7459e-01, 1.2385e+01, 7.2568e-01, 5.4978e+01, 5.4370e+01, 2.0402e+01,\n",
      "        1.2207e+01, 3.8508e+01, 4.3193e+01, 1.8313e+02, 6.8237e+01, 8.9466e+00,\n",
      "        1.0356e+02, 1.6001e+02, 9.2697e-02, 1.7896e+01, 2.0320e+01, 2.3632e+00,\n",
      "        1.7150e+00, 3.6994e+01, 1.9409e+02, 1.8310e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(30.2688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([9.8088e-07, 3.5443e-06, 6.1609e-03, 1.0939e-06, 4.5382e-04, 1.1888e-04,\n",
      "        1.0067e-03, 4.4389e-01, 1.9608e+00, 3.3479e-06, 1.0061e-03, 1.0577e-02,\n",
      "        4.0385e-07, 2.0639e-04, 4.6897e-06, 2.1678e+00, 7.1327e-03, 8.5618e-07,\n",
      "        4.9727e-02, 2.5560e-07, 1.5497e-05, 1.5624e-02, 8.6295e-03, 5.5423e-03,\n",
      "        4.4423e-05, 4.2249e-05, 1.0566e-06, 1.3023e-03, 3.5689e-06, 1.1424e+03,\n",
      "        2.3266e-03, 1.0482e-02, 1.9614e-03, 6.5324e-05, 6.4415e-03, 2.1272e-07,\n",
      "        1.1264e-06, 3.0223e-05, 7.3050e-06, 2.4108e-05, 1.8990e-03, 2.4343e-02,\n",
      "        1.1079e-06, 1.6519e-03, 1.8059e+00, 1.5179e-07, 4.5343e-05, 7.6312e-04,\n",
      "        6.6575e-06, 9.4075e-06, 3.8065e-08, 4.0810e-05, 1.0393e-07, 3.8835e-05,\n",
      "        6.5246e-03, 3.3035e-03, 1.4206e-05, 5.8941e-03, 5.9912e-07, 3.3741e-03,\n",
      "        1.1312e-06, 1.0475e-07, 4.3899e-06, 1.0747e-04], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([4.7984e+01, 3.1837e+01, 3.3059e+00, 4.6486e+01, 6.2417e-01, 4.5352e+00,\n",
      "        4.4906e-05, 3.7156e+01, 5.7473e+01, 3.2483e+01, 3.6573e-05, 5.5634e+00,\n",
      "        6.1066e+01, 2.4900e+00, 2.8755e+01, 5.9005e+01, 3.8600e+00, 4.9886e+01,\n",
      "        1.5261e+01, 6.8424e+01, 1.7365e+01, 7.5559e+00, 4.6448e+00, 2.9323e+00,\n",
      "        9.6970e+00, 1.0012e+01, 4.6959e+01, 6.9784e-02, 3.1759e+01, 1.9456e+02,\n",
      "        7.1304e-01, 5.5210e+00, 4.5380e-01, 7.4442e+00, 3.4699e+00, 7.1496e+01,\n",
      "        4.6086e+01, 1.2244e+01, 2.4198e+01, 1.3877e+01, 4.1129e-01, 1.0190e+01,\n",
      "        4.6312e+01, 2.5192e-01, 5.6232e+01, 7.7317e+01, 9.5698e+00, 7.3081e-02,\n",
      "        2.5120e+01, 2.1774e+01, 1.0356e+02, 1.0233e+01, 8.4122e+01, 1.0552e+01,\n",
      "        3.5178e+00, 1.4280e+00, 1.8097e+01, 3.1469e+00, 5.5057e+01, 1.4790e+00,\n",
      "        4.6029e+01, 8.3978e+01, 2.9468e+01, 4.9755e+00], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(27.6586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([1.4960e-03, 7.5627e-07, 3.6389e-05, 3.9477e-02, 4.9485e-03, 6.5055e-02,\n",
      "        1.5845e-05, 2.5710e-04, 4.3451e-07, 3.0202e-06, 3.8395e-06, 2.5203e-01,\n",
      "        3.3468e-04, 4.2301e-03, 1.0526e-03, 5.3980e-04, 5.3840e-06, 1.0131e-05,\n",
      "        1.3792e+00, 3.4788e-02, 3.1146e-08, 1.3761e+00, 5.0065e-04, 2.2563e-06,\n",
      "        1.4963e-06, 7.6102e-04, 4.0897e-03, 1.1423e-03, 4.5504e-06, 1.1445e-04,\n",
      "        1.4608e-02, 2.1392e-03, 5.8078e-04, 2.8857e-06, 2.0458e-04, 5.8978e-03,\n",
      "        3.4623e-05, 1.2173e-03, 2.4323e-04, 3.6734e-03, 2.2649e-02, 1.2272e-02,\n",
      "        6.9122e-07, 2.6714e-04, 5.3873e-06], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([1.6224e-01, 5.1655e+01, 1.0979e+01, 1.3511e+01, 2.5571e+00, 1.7433e+01,\n",
      "        1.7180e+01, 1.8450e+00, 5.9928e+01, 3.3668e+01, 3.0940e+01, 3.0576e+01,\n",
      "        1.1981e+00, 2.0800e+00, 2.6310e-03, 3.8015e-01, 2.7294e+01, 2.1088e+01,\n",
      "        5.2263e+01, 1.2597e+01, 1.0768e+02, 5.2229e+01, 4.7866e-01, 3.7137e+01,\n",
      "        4.2312e+01, 7.4584e-02, 1.9838e+00, 1.7707e-02, 2.9080e+01, 4.6987e+00,\n",
      "        7.1909e+00, 5.7829e-01, 2.9526e-01, 3.4199e+01, 2.5179e+00, 3.1491e+00,\n",
      "        1.1311e+01, 3.8651e-02, 1.9987e+00, 1.6929e+00, 9.7350e+00, 6.2867e+00,\n",
      "        5.2955e+01, 1.7424e+00, 2.7287e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(18.3112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([2.4969e-06, 6.2043e-02, 5.1268e-07, 7.1489e-02, 2.0648e-04, 1.1670e-07,\n",
      "        2.1969e-05, 2.5669e-06, 2.8605e-02, 7.1062e-06, 8.7742e-01, 8.6338e-03,\n",
      "        1.0505e-05, 1.5562e-03, 6.4081e-08, 4.9628e-04, 1.7464e-03, 1.5775e-06,\n",
      "        1.0540e-05, 2.5837e-04, 3.2098e-06, 6.8874e+00, 1.2850e-03, 1.9125e-05,\n",
      "        2.5401e-05, 3.8636e-06, 4.0167e-07, 3.9151e-04, 6.2126e-04, 6.2750e-06,\n",
      "        4.2512e-07, 1.1274e+03, 2.1914e-07, 4.2784e-03, 9.3252e-07, 1.2243e-03,\n",
      "        2.2871e-05, 3.2582e-06, 3.1992e-09, 1.7631e-04, 1.1724e-04, 1.9460e-06,\n",
      "        1.3002e-05, 6.6487e-03, 1.2157e-02, 1.8952e-02, 1.6294e-06, 2.1569e-05,\n",
      "        6.5622e-06, 4.8251e-05, 1.8671e-06, 2.8089e-02, 4.6086e-06, 5.2899e-06,\n",
      "        1.2670e-02, 2.0387e-03, 1.4955e-02, 4.5349e-01, 3.4433e-08, 3.6634e-06,\n",
      "        3.1419e-05, 1.4955e-02, 4.5939e-06, 2.4732e-06], device='cuda:0')\n",
      "tensor([3.5912e+01, 1.7039e+01, 5.7394e+01, 1.8229e+01, 2.4887e+00, 8.2010e+01,\n",
      "        1.4578e+01, 3.5582e+01, 1.1246e+01, 2.4471e+01, 4.5928e+01, 4.6470e+00,\n",
      "        2.0756e+01, 1.9557e-01, 9.3226e+01, 4.9086e-01, 3.1089e-01, 4.1627e+01,\n",
      "        2.0726e+01, 1.8316e+00, 3.2965e+01, 7.8100e+01, 6.2897e-02, 1.5656e+01,\n",
      "        1.3491e+01, 3.0871e+01, 6.1150e+01, 8.7935e-01, 2.2658e-01, 2.5717e+01,\n",
      "        6.0266e+01, 1.9420e+02, 7.0994e+01, 2.1129e+00, 4.8687e+01, 4.0954e-02,\n",
      "        1.4272e+01, 3.2794e+01, 1.6009e+02, 3.0121e+00, 4.5948e+00, 3.8963e+01,\n",
      "        1.8859e+01, 3.5888e+00, 6.2395e+00, 8.6550e+00, 4.1210e+01, 1.4719e+01,\n",
      "        2.5265e+01, 9.1890e+00, 3.9481e+01, 1.1125e+01, 2.8942e+01, 2.7478e+01,\n",
      "        6.4477e+00, 5.0738e-01, 7.3174e+00, 3.7417e+01, 1.0561e+02, 3.1465e+01,\n",
      "        1.1974e+01, 7.3174e+00, 2.8977e+01, 3.6027e+01], device='cuda:0')\n",
      "tensor(30.0881, device='cuda:0')\n",
      "energy_error= tensor([1.8259e-03, 5.4839e-07, 7.6422e-05, 1.1483e-04, 4.0993e-05, 5.0439e-05,\n",
      "        5.6667e-04, 2.0110e+00, 6.2307e-06, 9.6535e-04, 3.7432e-07, 4.8287e-07,\n",
      "        1.8873e-05, 7.1729e-06, 3.1645e-02, 3.9605e-05, 8.0176e-08, 2.9118e-06,\n",
      "        1.3189e-06, 1.3658e-02, 2.1131e-07, 9.9580e-04, 5.1350e-04, 5.1866e-03,\n",
      "        1.0871e-05, 2.0813e-02, 1.6376e-05, 5.8181e-05, 7.3572e-03, 9.5837e-04,\n",
      "        6.6692e-07, 7.6141e-07, 4.1119e-04, 1.0725e+00, 1.0582e-02, 5.0084e-04,\n",
      "        9.7102e-07, 2.8786e-04, 5.6123e-07, 5.2849e-05, 6.4556e-04, 1.2002e-03,\n",
      "        7.3114e-04, 6.9966e-04, 1.3431e-04, 5.0548e-01, 8.4440e-06, 1.4957e+00,\n",
      "        5.2463e-05, 1.6122e-04, 3.7426e-02, 6.6048e-03, 7.7068e-02, 1.2055e-03,\n",
      "        2.2479e-06, 7.8570e-03, 7.2738e-05, 1.0278e-02, 3.5413e-06, 3.1424e-05,\n",
      "        1.3680e-02, 5.6760e-03, 6.6406e-03, 1.9144e-04], device='cuda:0')\n",
      "tensor([3.6247e-01, 5.6378e+01, 6.6125e+00, 4.6843e+00, 1.0204e+01, 8.9222e+00,\n",
      "        3.2261e-01, 5.7857e+01, 2.5789e+01, 1.2435e-03, 6.2258e+01, 5.8305e+01,\n",
      "        1.5761e+01, 2.4378e+01, 1.1934e+01, 1.0425e+01, 8.8949e+01, 3.4094e+01,\n",
      "        4.3970e+01, 6.8346e+00, 7.1609e+01, 1.7709e-05, 4.4424e-01, 2.7096e+00,\n",
      "        2.0446e+01, 9.2147e+00, 1.6908e+01, 8.0894e+00, 3.9827e+00, 1.8081e-03,\n",
      "        5.3478e+01, 5.1557e+01, 7.8979e-01, 4.8689e+01, 5.5655e+00, 4.7814e-01,\n",
      "        4.8124e+01, 1.5508e+00, 5.6031e+01, 8.6455e+00, 1.9152e-01, 3.3300e-02,\n",
      "        9.8066e-02, 1.2757e-01, 4.0305e+00, 3.8757e+01, 2.2794e+01, 5.3441e+01,\n",
      "        8.6886e+00, 3.3307e+00, 1.3122e+01, 3.5638e+00, 1.8876e+01, 3.4922e-02,\n",
      "        3.7182e+01, 4.2494e+00, 6.8691e+00, 5.4291e+00, 3.1846e+01, 1.1973e+01,\n",
      "        6.8430e+00, 3.0145e+00, 3.5842e+00, 2.7330e+00], device='cuda:0')\n",
      "tensor(19.0183, device='cuda:0')\n",
      "energy_error= tensor([4.6809e-03, 3.9818e-03, 1.1797e-03, 3.8256e+00, 4.0832e-05, 3.2033e-03,\n",
      "        4.0065e-04, 4.7562e-04, 3.8036e-03, 1.5346e-05, 7.7223e-03, 4.2315e-03,\n",
      "        1.2701e-02, 6.5375e-02, 5.0584e-06, 1.9825e-01, 2.5996e-07, 1.3276e-09,\n",
      "        1.0661e-06, 3.7825e-06, 4.6627e-05, 9.1401e-07, 1.3743e-02, 2.0445e-03,\n",
      "        4.8323e-01, 7.6671e-03, 3.9221e-06, 1.4451e-01, 9.0089e-03, 7.7349e-05,\n",
      "        5.1104e-07, 2.5188e-04, 3.7259e-03, 8.9480e-03, 6.6569e-07, 2.2095e-06,\n",
      "        3.2271e-05, 4.8236e-06, 6.2307e-06, 3.5532e-09, 1.8166e-03, 1.9085e-04,\n",
      "        6.4763e-05, 6.4081e-08, 9.2338e-05, 2.6126e-05, 1.5574e-06, 5.7769e-02,\n",
      "        3.2520e-07, 2.7209e-04, 9.6598e-05, 7.9217e-05, 1.8564e-05, 9.7434e-07,\n",
      "        5.1257e-03, 4.8304e-06, 1.4799e-06, 1.2662e-03, 1.0527e-03, 7.9632e-06,\n",
      "        4.6990e-06, 5.5715e-03, 4.0908e-03, 2.7929e-03], device='cuda:0')\n",
      "tensor([2.3823e+00, 1.9092e+00, 2.7301e-02, 6.8054e+01, 1.0229e+01, 1.3553e+00,\n",
      "        8.3663e-01, 5.5224e-01, 1.7847e+00, 1.7446e+01, 4.1784e+00, 2.0810e+00,\n",
      "        6.4601e+00, 1.7474e+01, 2.7949e+01, 2.7979e+01, 6.8145e+01, 1.8312e+02,\n",
      "        4.6837e+01, 3.1107e+01, 9.3977e+00, 4.8967e+01, 6.8672e+00, 5.1147e-01,\n",
      "        3.8198e+01, 4.1491e+00, 3.0704e+01, 2.4734e+01, 4.8321e+00, 6.5507e+00,\n",
      "        5.7442e+01, 1.9011e+00, 1.7300e+00, 4.8023e+00, 5.3505e+01, 3.7393e+01,\n",
      "        1.1789e+01, 2.8454e+01, 2.5789e+01, 1.5744e+02, 3.5638e-01, 2.7432e+00,\n",
      "        7.4913e+00, 9.3226e+01, 5.6753e+00, 1.3285e+01, 4.1792e+01, 1.6455e+01,\n",
      "        6.4498e+01, 1.6942e+00, 5.4625e+00, 6.4291e+00, 1.5892e+01, 4.8077e+01,\n",
      "        2.6708e+00, 2.8439e+01, 4.2455e+01, 5.5689e-02, 2.6395e-03, 2.3357e+01,\n",
      "        2.8734e+01, 2.9504e+00, 1.9846e+00, 1.0549e+00], device='cuda:0')\n",
      "tensor(23.9039, device='cuda:0')\n",
      "energy_error= tensor([3.6651e-07, 2.0712e+00, 4.8128e-03, 2.1194e-03, 1.0533e-03, 1.0267e-03,\n",
      "        3.2781e-03, 4.6430e-05, 1.4812e-04, 2.4951e-06, 1.1310e-03, 1.8181e-07,\n",
      "        1.1792e-08, 1.7683e-07, 2.1606e-02, 2.4332e-04, 4.2425e-03, 5.0288e-05,\n",
      "        1.7266e-04, 5.8092e-07, 1.0880e-05, 8.9346e-03, 7.2099e-03, 3.0225e-05,\n",
      "        8.7729e-05, 3.4069e-04, 6.0936e-05, 8.9144e-05, 5.4814e-07, 2.6938e-06,\n",
      "        9.0898e-03, 9.9435e-07, 4.7655e-04, 9.7418e-06, 7.2093e-05, 1.1814e-05,\n",
      "        8.4745e-06, 2.2651e-05, 1.1140e-05, 2.4106e-02, 2.8745e-07, 6.1278e-06,\n",
      "        6.2975e-01, 6.8013e-09, 4.8373e-01, 2.0906e-02, 7.3476e-04, 3.5974e-05,\n",
      "        5.7190e-07, 8.4241e-03, 1.3369e-02, 3.5459e-06, 7.9166e-03, 7.4471e-03,\n",
      "        4.1123e-05, 1.1311e+03, 7.4001e-05, 1.1299e-06, 1.2085e+01, 7.9111e-05,\n",
      "        1.6077e-07, 2.7688e-02, 4.7655e-04, 1.6619e-02], device='cuda:0')\n",
      "tensor([6.2592e+01, 5.8307e+01, 2.4689e+00, 5.6421e-01, 2.6941e-03, 6.9290e-04,\n",
      "        1.4096e+00, 9.4237e+00, 3.6472e+00, 3.5921e+01, 1.5147e-02, 7.4176e+01,\n",
      "        1.2878e+02, 7.4655e+01, 9.4432e+00, 1.9977e+00, 2.0885e+00, 8.9401e+00,\n",
      "        3.0850e+00, 5.5516e+01, 2.0438e+01, 4.7958e+00, 3.9024e+00, 1.2244e+01,\n",
      "        5.9219e+00, 1.1594e+00, 7.8284e+00, 5.8443e+00, 5.6385e+01, 3.5008e+01,\n",
      "        4.8715e+00, 4.7795e+01, 5.4936e-01, 2.1449e+01, 6.9159e+00, 1.9700e+01,\n",
      "        2.2759e+01, 1.4345e+01, 2.0225e+01, 1.0128e+01, 6.6495e+01, 2.5958e+01,\n",
      "        4.1542e+01, 1.4157e+02, 3.8211e+01, 9.2419e+00, 9.4995e-02, 1.1055e+01,\n",
      "        5.5749e+01, 4.5416e+00, 6.7234e+00, 3.1832e+01, 4.2806e+00, 4.0314e+00,\n",
      "        1.0184e+01, 1.9429e+02, 6.7792e+00, 4.6044e+01, 8.8354e+01, 6.4359e+00,\n",
      "        7.6310e+01, 1.1029e+01, 5.4936e-01, 7.8992e+00], device='cuda:0')\n",
      "tensor(27.2578, device='cuda:0')\n",
      "energy_error= tensor([8.4904e-07, 4.8128e-03, 3.5473e+00, 3.7645e-03, 1.1096e-07, 6.8886e-02,\n",
      "        1.7975e-09, 9.0008e-03, 2.4209e-03, 5.9237e-03, 1.3417e-02, 6.6068e-08,\n",
      "        8.1292e-05, 1.1339e-03, 1.0880e-05, 5.0332e-04, 1.0313e-04, 4.5274e-04,\n",
      "        1.2519e-01, 9.4093e-06, 1.3657e-03, 4.2567e-01, 1.1446e-04, 1.7295e-07,\n",
      "        1.5694e-05, 4.6373e-02, 5.0042e-04, 1.0984e-06, 6.3236e-05, 5.7361e-06,\n",
      "        9.9710e-06, 5.9410e-06, 3.0582e-06, 9.1124e-08, 9.4572e+00, 1.0142e-01,\n",
      "        3.4392e-06, 1.3356e-05, 6.5495e-03, 9.0538e-07, 3.6205e-08, 2.0645e-06,\n",
      "        8.6610e-03, 2.0329e-01, 1.7088e-06, 2.4700e-05, 8.9886e-07, 1.5703e-01,\n",
      "        6.2396e+00, 3.4513e-03, 2.1449e-07, 4.9971e-03, 1.6988e-07, 6.5880e-09,\n",
      "        2.3362e-03, 4.3918e-05, 8.1353e-06, 2.7139e-03, 1.4198e-05, 1.6704e-06,\n",
      "        1.6428e+00, 4.0221e-03, 4.7352e-03, 2.0674e-03], device='cuda:0')\n",
      "tensor([5.0005e+01, 2.4689e+00, 6.6813e+01, 1.7573e+00, 8.2925e+01, 1.7914e+01,\n",
      "        1.7501e+02, 4.8282e+00, 7.8168e-01, 3.1647e+00, 6.7418e+00, 9.2637e+01,\n",
      "        6.2986e+00, 1.5782e-02, 2.0438e+01, 4.7133e-01, 5.1610e+00, 6.2796e-01,\n",
      "        2.3327e+01, 2.1772e+01, 9.7114e-02, 3.6647e+01, 4.6983e+00, 7.5039e+01,\n",
      "        1.7260e+01, 1.4720e+01, 4.7928e-01, 4.6429e+01, 7.6225e+00, 2.6636e+01,\n",
      "        2.1234e+01, 2.6275e+01, 3.3523e+01, 8.6551e+01, 8.3805e+01, 2.1337e+01,\n",
      "        3.2177e+01, 1.8626e+01, 3.5321e+00, 4.9100e+01, 1.0458e+02, 3.8228e+01,\n",
      "        4.6605e+00, 2.8245e+01, 4.0602e+01, 1.3697e+01, 4.9202e+01, 2.5567e+01,\n",
      "        7.6364e+01, 1.5345e+00, 7.1356e+01, 2.5884e+00, 7.5350e+01, 1.4233e+02,\n",
      "        7.2001e-01, 9.7684e+00, 2.3151e+01, 9.9675e-01, 1.8102e+01, 4.0892e+01,\n",
      "        5.4822e+01, 1.9372e+00, 2.4181e+00, 5.2749e-01], device='cuda:0')\n",
      "tensor(31.5092, device='cuda:0')\n",
      "energy_error= tensor([1.9245e-01, 2.8459e-08, 1.6555e-05, 6.5875e-05, 4.7919e-04, 1.5790e-07,\n",
      "        1.1098e-07, 2.9239e-07, 1.6670e-02, 4.9172e-06, 7.3719e-04, 1.0731e-06,\n",
      "        6.8313e-06, 8.7478e-02, 9.8432e+00, 1.1452e-02, 6.8801e-06, 7.3061e-06,\n",
      "        9.5916e-03, 8.4058e-06, 2.5996e-07, 1.6988e-07, 5.6438e-05, 7.4892e-07,\n",
      "        3.6168e-04, 5.0131e-05, 5.9580e-04, 1.5261e+01, 6.8107e-06, 1.2112e-02,\n",
      "        1.2824e-03, 2.4165e-06, 8.5850e-08, 4.4000e-06, 4.7957e-08, 3.7942e-08,\n",
      "        2.3377e-02, 9.5916e-03, 1.8534e+00, 9.9228e-03, 7.4548e-04, 1.3391e-06,\n",
      "        8.7881e-03, 4.4927e-04, 4.7684e-03, 5.3846e-06, 6.5947e-04, 5.3765e-05,\n",
      "        3.2791e-06, 5.4846e-03, 2.7475e-02, 2.3990e-06, 1.3002e-05, 1.0701e-03,\n",
      "        6.0948e-03, 2.1240e-05, 7.2335e-03, 9.1124e-08, 7.4728e-02, 1.7048e-02,\n",
      "        1.1669e-07, 3.7426e-02, 9.9905e-04, 2.1372e-06], device='cuda:0')\n",
      "tensor([2.7666e+01, 1.0956e+02, 1.6819e+01, 7.3984e+00, 5.4120e-01, 7.6624e+01,\n",
      "        8.2922e+01, 6.6218e+01, 7.9164e+00, 2.8249e+01, 9.2968e-02, 4.6747e+01,\n",
      "        2.4863e+01, 1.9993e+01, 8.4539e+01, 5.9448e+00, 2.4792e+01, 2.4197e+01,\n",
      "        5.1116e+00, 2.2837e+01, 6.8145e+01, 7.5350e+01, 8.2634e+00, 5.1795e+01,\n",
      "        1.0343e+00, 8.9587e+00, 2.6817e-01, 9.2796e+01, 2.4893e+01, 6.2208e+00,\n",
      "        6.1867e-02, 3.6306e+01, 8.7664e+01, 2.9443e+01, 9.8907e+01, 1.0362e+02,\n",
      "        9.9336e+00, 5.1116e+00, 5.6622e+01, 5.2663e+00, 8.6276e-02, 4.3769e+01,\n",
      "        4.7236e+00, 6.4020e-01, 2.4399e+00, 2.7292e+01, 1.7332e-01, 8.5448e+00,\n",
      "        3.2720e+01, 2.8966e+00, 1.0978e+01, 3.6393e+01, 1.8859e+01, 4.5870e-03,\n",
      "        3.2668e+00, 1.4837e+01, 3.9153e+00, 8.6551e+01, 1.8609e+01, 8.0430e+00,\n",
      "        8.2010e+01, 1.3122e+01, 9.0669e-07, 3.7801e+01], device='cuda:0')\n",
      "tensor(29.8651, device='cuda:0')\n",
      "energy_error= tensor([1.9001e-02, 5.8918e-02, 3.7761e-03, 9.1963e-05, 9.0117e-05, 5.7548e-03,\n",
      "        1.1275e-03, 7.1945e-06, 3.4214e-02, 2.7598e-06, 1.0853e-06, 2.1532e-04,\n",
      "        2.1450e-07, 1.8536e-04, 2.6786e-03, 8.5282e-07, 5.7574e-06, 1.0626e-03,\n",
      "        4.1526e-04, 6.1011e-04, 1.2670e-02, 6.2883e-04, 1.5775e-06, 1.5694e-05,\n",
      "        6.3563e-03, 8.5540e-03, 6.8205e-05, 1.3280e-06, 7.3659e-09, 3.1952e-06,\n",
      "        7.5139e-03, 1.1459e-06, 4.9217e-03, 1.4442e-05, 5.0042e-04, 1.4364e-06,\n",
      "        3.4069e-01, 1.0701e-03, 3.2441e-03, 6.1547e-02, 1.1873e-02, 3.9287e-05,\n",
      "        8.5041e-03], device='cuda:0')\n",
      "tensor([8.6700e+00, 1.6615e+01, 1.7654e+00, 5.6947e+00, 5.7920e+00, 3.0626e+00,\n",
      "        1.4411e-02, 2.4349e+01, 1.2480e+01, 3.4723e+01, 4.6593e+01, 2.3582e+00,\n",
      "        7.1356e+01, 2.8408e+00, 9.7080e-01, 4.9942e+01, 2.6597e+01, 3.6911e-03,\n",
      "        7.7236e-01, 2.4415e-01, 6.4477e+00, 2.1520e-01, 4.1627e+01, 1.7260e+01,\n",
      "        3.4205e+00, 4.6070e+00, 7.2105e+00, 4.3879e+01, 1.3968e+02, 3.3018e+01,\n",
      "        4.0673e+00, 4.5854e+01, 2.5397e+00, 1.7957e+01, 4.7928e-01, 4.2845e+01,\n",
      "        3.4000e+01, 4.5870e-03, 1.3850e+00, 1.6973e+01, 6.1221e+00, 1.0477e+01,\n",
      "        4.5819e+00], device='cuda:0')\n",
      "tensor(18.5929, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_230351/2938017237.py:195: RuntimeWarning: invalid value encountered in log10\n",
      "  print(f\"Epoch [{epoch}/{num_epochs}], Timestep error: {train_res['time_step_relative_error']:.4e}/{val_res['time_step_relative_error']:.4e}, Energy Loss: {np.log10(train_res['energy_error']):.4e}/{np.log10(train_res['energy_error_fiducial']):.4e}, {np.log10(val_res['energy_error']):.4e}/{np.log10(val_res['energy_error_fiducial']):.4e}, Time step: {train_res['time_step']:.4e}/{train_res['time_step_fiducial']:.4e}, {val_res['time_step']:.4e}/{val_res['time_step_fiducial']:.4e}, {val_res['time_step_std']:.4e}/{val_res['time_step_fiducial_std']:.4e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/1000], Timestep error: 1.0531e+02/1.4294e+02, Energy Loss: nan/nan, nan/nan, Time step: 4.7320e-05/9.4821e-04, 4.3821e-05/8.6166e-04, 5.2429e-05/1.7175e-03\n",
      "energy_error= tensor([9.7498e-03, 2.3990e-06, 4.3786e-03, 4.3996e-08, 9.7309e-05, 4.6899e-06,\n",
      "        3.5696e-06, 1.8472e-02, 4.2848e-06, 1.4443e-04, 2.4365e-03, 2.8164e-06,\n",
      "        1.6522e-03, 2.8938e-03, 4.1298e-03, 1.3773e-03, 8.1582e-06, 3.7944e-05,\n",
      "        4.7915e-03, 1.1554e-03, 3.9258e-03, 3.4069e-04, 2.1400e-03, 1.1444e-01,\n",
      "        8.4637e-03, 4.6915e-07, 1.3551e-01, 6.1601e-07, 2.5302e-06, 7.7610e+00,\n",
      "        6.9206e-06, 4.0221e-03, 6.8974e-06, 7.3265e-01, 1.5260e-01, 3.8948e-02,\n",
      "        4.1293e-03, 6.6361e-03, 1.0644e-04, 7.3841e-07, 6.8654e-06, 6.9131e-07,\n",
      "        3.8190e-04, 1.0329e-02, 4.4091e-03, 6.2781e-07, 2.1535e-04, 4.2622e-01,\n",
      "        7.0525e-06, 7.3732e-06, 5.5807e-07, 2.0005e-02, 1.2175e-03, 2.6108e-02,\n",
      "        5.7828e-06, 4.2560e-05, 4.7699e-01, 1.7369e-02, 3.6069e-06, 1.0395e-07,\n",
      "        7.2048e-07, 1.0629e-04, 6.2850e-06, 1.3034e-05], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([5.1859e+00, 3.6393e+01, 2.1807e+00, 1.0063e+02, 5.4283e+00, 2.8755e+01,\n",
      "        3.1757e+01, 8.5047e+00, 2.9732e+01, 3.7440e+00, 7.9313e-01, 3.4484e+01,\n",
      "        2.5211e-01, 1.1291e+00, 2.0114e+00, 1.0250e-01, 2.3124e+01, 1.0704e+01,\n",
      "        2.4550e+00, 2.0853e-02, 1.8702e+00, 1.1594e+00, 5.7881e-01, 2.2468e+01,\n",
      "        4.5616e+00, 5.8746e+01, 2.4099e+01, 5.4645e+01, 3.5754e+01, 8.0225e+01,\n",
      "        2.4733e+01, 1.9372e+00, 2.4767e+01, 4.3516e+01, 2.5279e+01, 1.3412e+01,\n",
      "        2.0110e+00, 3.5816e+00, 5.0184e+00, 5.1999e+01, 2.4813e+01, 5.2954e+01,\n",
      "        9.2658e-01, 5.4520e+00, 2.2013e+00, 5.4365e+01, 2.3578e+00, 3.6663e+01,\n",
      "        2.4546e+01, 2.4107e+01, 5.6116e+01, 8.9760e+00, 3.8727e-02, 1.0642e+01,\n",
      "        2.6552e+01, 9.9656e+00, 3.8038e+01, 8.1494e+00, 3.1640e+01, 8.4119e+01,\n",
      "        5.2354e+01, 5.0248e+00, 2.5701e+01, 1.8837e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(22.0669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([1.9414e-06, 3.8973e-03, 1.8484e-02, 1.0284e-02, 2.6870e-06, 4.2788e-07,\n",
      "        1.9065e-03, 1.2105e-06, 1.6079e-07, 1.4605e-05, 5.2142e-03, 7.3705e-05,\n",
      "        7.0988e-06, 1.3803e+00, 1.4657e-04, 3.9624e-02, 3.1450e-03, 3.9639e-01,\n",
      "        4.5201e-07, 5.5358e-05, 4.4437e-05, 3.6077e-08, 3.4233e-06, 2.8732e-02,\n",
      "        1.0073e-03, 2.1298e-05, 8.1340e-03, 4.4840e-02, 9.6509e-09, 3.6751e-07,\n",
      "        1.0953e-04, 2.3508e-02, 8.4071e-06, 4.5911e-04, 7.5762e-03, 1.2707e-02,\n",
      "        1.4262e-03, 1.1358e-06, 1.2996e-03, 3.6077e-08, 4.4012e-06, 8.8525e-06,\n",
      "        5.5302e-02, 7.3838e-06, 1.0529e-05, 2.9837e-04, 3.5342e-02, 1.8672e-06,\n",
      "        3.7768e-07, 6.3230e-01, 2.2391e-02, 3.6633e-06, 5.0895e-07, 1.0569e-06,\n",
      "        7.2455e+00, 1.7030e-04, 3.5110e-01, 1.5401e-05, 2.3483e-03, 4.5516e-06,\n",
      "        1.4254e-02, 1.4817e-04, 5.2035e-04, 4.9536e-03], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([3.8992e+01, 1.8504e+00, 8.5083e+00, 5.4314e+00, 3.5039e+01, 6.0166e+01,\n",
      "        4.1638e-01, 4.5114e+01, 7.6307e+01, 1.7862e+01, 2.7271e+00, 6.8000e+00,\n",
      "        2.4481e+01, 5.2274e+01, 3.6874e+00, 1.3538e+01, 1.3129e+00, 3.5789e+01,\n",
      "        5.9318e+01, 8.3748e+00, 9.6951e+00, 1.0465e+02, 3.2230e+01, 1.1276e+01,\n",
      "        5.3339e-05, 1.4816e+01, 4.3934e+00, 1.4464e+01, 1.3337e+02, 6.2549e+01,\n",
      "        4.8911e+00, 9.9689e+00, 2.2836e+01, 6.0600e-01, 4.1007e+00, 6.4626e+00,\n",
      "        1.2604e-01, 4.5974e+01, 6.8670e-02, 1.0465e+02, 2.9440e+01, 2.2345e+01,\n",
      "        1.6103e+01, 2.4093e+01, 2.0735e+01, 1.4627e+00, 1.2710e+01, 3.9480e+01,\n",
      "        6.2117e+01, 4.1594e+01, 9.6638e+00, 3.1465e+01, 5.7504e+01, 4.6956e+01,\n",
      "        7.8999e+01, 3.1336e+00, 3.4352e+01, 1.7416e+01, 7.2878e-01, 2.9077e+01,\n",
      "        7.0599e+00, 3.6458e+00, 4.2675e-01, 2.5604e+00], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(26.2216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([4.9086e-06, 2.4734e-07, 6.8026e-05, 2.5071e-07, 5.8090e-03, 1.1015e-05,\n",
      "        2.5860e-04, 1.4346e-02, 8.9089e-03, 3.6443e-05, 1.4552e-01, 7.6126e-07,\n",
      "        2.4376e-02, 9.5821e-07, 1.4253e-04, 2.5572e-07, 4.1505e-05, 6.8276e-05,\n",
      "        2.7245e-05, 1.2578e-02, 3.7474e-01, 1.1721e-02, 1.9509e-03, 3.1013e-06,\n",
      "        1.3906e-03, 1.0537e-03, 1.1356e-02, 1.7841e-01, 1.1934e-02, 1.0993e-03,\n",
      "        7.8956e-07, 1.1376e-09, 5.8630e-05, 1.8680e-07, 1.3464e-06, 1.0730e-01,\n",
      "        1.8821e-03, 7.7464e-06, 2.4246e-03, 5.3529e-03, 2.3469e-02, 6.5215e-02,\n",
      "        1.4029e-01, 5.9953e-08, 6.9519e-07, 7.3331e-06, 4.6657e-06, 1.8456e-01,\n",
      "        2.8538e-05, 9.9392e-04, 3.7828e-02, 2.8870e-06, 1.8560e-04, 3.1565e-04,\n",
      "        4.5351e-04, 5.2558e-04, 5.1132e-07, 6.2824e-02, 8.3601e-03, 2.8953e-02,\n",
      "        1.2930e-06, 1.0109e-05, 5.5751e-05, 1.0710e-07], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([2.8268e+01, 6.8969e+01, 7.2247e+00, 6.8744e+01, 3.0955e+00, 2.0327e+01,\n",
      "        1.8292e+00, 7.0939e+00, 4.7832e+00, 1.0969e+01, 2.4804e+01, 5.1560e+01,\n",
      "        1.0199e+01, 4.8309e+01, 3.7955e+00, 6.8417e+01, 1.0125e+01, 7.2049e+00,\n",
      "        1.2981e+01, 6.4108e+00, 3.5120e+01, 6.0584e+00, 4.4658e-01, 3.3361e+01,\n",
      "        1.0871e-01, 2.7349e-03, 5.9035e+00, 2.6875e+01, 6.1473e+00, 8.9635e-03,\n",
      "        5.1037e+01, 1.8732e+02, 8.0457e+00, 7.3711e+01, 4.3697e+01, 2.1862e+01,\n",
      "        3.9993e-01, 2.3625e+01, 7.8440e-01, 2.8145e+00, 9.9584e+00, 1.7453e+01,\n",
      "        2.4440e+01, 9.4516e+01, 5.2872e+01, 2.4161e+01, 2.8810e+01, 2.7228e+01,\n",
      "        1.2649e+01, 3.7186e-05, 1.3199e+01, 3.4194e+01, 2.8365e+00, 1.3297e+00,\n",
      "        6.2528e-01, 4.1378e-01, 5.7434e+01, 1.7142e+01, 4.5091e+00, 1.1328e+01,\n",
      "        4.4233e+01, 2.1108e+01, 8.3339e+00, 8.3571e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(24.7622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([1.1816e-03, 2.9513e-06, 4.7677e-05, 1.7144e-05, 5.7650e-05, 1.3052e-03,\n",
      "        5.6524e-06, 2.3520e-01, 1.0735e-02, 1.7970e-03, 6.6834e-06, 9.6003e-03,\n",
      "        4.7593e-01, 7.3878e-07, 2.7560e-06, 1.0003e-03, 1.7359e-06, 1.6602e-08,\n",
      "        2.3558e-03, 3.6568e-07, 1.2648e-03, 4.9598e-04, 4.6822e-05, 2.2258e-02,\n",
      "        4.1307e-04, 1.6168e-06, 2.8422e-06, 5.4000e-06, 8.4762e-03, 8.6719e-05,\n",
      "        5.2823e-04, 6.2811e-07, 1.4975e-03, 1.3035e-02, 1.1367e-03, 3.1950e-03,\n",
      "        1.2177e-02, 4.5849e-04, 2.3451e-03, 4.6026e-05, 7.2876e-05, 2.5924e-08,\n",
      "        6.8808e-06, 1.5805e-01, 1.0514e-02, 8.8551e-06, 9.6307e-03, 1.5854e-05,\n",
      "        5.3916e-02, 7.7159e-06, 2.1941e-04, 1.4003e-06, 6.3185e-05, 4.8538e-06,\n",
      "        2.7446e-05, 8.4361e-03, 6.9785e-05, 1.0826e-05, 2.3090e-02, 1.9941e-01,\n",
      "        6.9165e-07, 1.1255e+03, 1.9163e-06, 2.1516e-07], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([2.7850e-02, 3.3936e+01, 9.2617e+00, 1.6533e+01, 8.1417e+00, 7.0955e-02,\n",
      "        2.6788e+01, 2.9816e+01, 5.6334e+00, 3.4354e-01, 2.5081e+01, 5.1157e+00,\n",
      "        3.8011e+01, 5.1991e+01, 3.4739e+01, 1.0467e-07, 4.0401e+01, 1.2113e+02,\n",
      "        7.3424e-01, 6.2628e+01, 5.5174e-02, 4.9172e-01, 9.3721e+00, 9.6268e+00,\n",
      "        7.8169e-01, 4.1310e+01, 3.4377e+01, 2.7263e+01, 4.5679e+00, 5.9784e+00,\n",
      "        4.0732e-01, 5.4358e+01, 1.6307e-01, 6.5928e+00, 1.6407e-02, 1.3493e+00,\n",
      "        6.2478e+00, 6.0811e-01, 7.2645e-01, 9.4775e+00, 6.8591e+00, 1.1152e+02,\n",
      "        2.4791e+01, 2.5633e+01, 5.5353e+00, 2.2342e+01, 5.1300e+00, 1.7176e+01,\n",
      "        1.5900e+01, 2.3663e+01, 2.3007e+00, 4.3179e+01, 7.6269e+00, 2.8387e+01,\n",
      "        1.2928e+01, 4.5476e+00, 7.0880e+00, 2.0483e+01, 9.8559e+00, 2.8041e+01,\n",
      "        5.2946e+01, 1.9415e+02, 3.9154e+01, 7.1303e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(23.5109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([1.1401e-03, 1.0806e-06, 1.4413e-01, 5.2579e-07, 7.0533e-06, 6.9871e-04,\n",
      "        7.6155e-04, 3.1167e-08, 1.0753e-05, 1.9423e-06, 7.6461e-05, 1.2671e-03,\n",
      "        5.9220e-02, 1.2515e-06, 1.9189e-03, 1.1778e-05, 2.5643e-07, 5.8145e-04,\n",
      "        3.2681e-08, 1.2781e-06, 2.5203e-04, 6.4279e-03, 9.2404e-05, 9.3678e-05,\n",
      "        3.8832e-01, 1.2858e-03, 5.9942e-07, 1.5828e-03, 6.5826e-01, 2.2167e-02,\n",
      "        3.8071e-05, 2.0191e-06, 1.7962e-02, 2.3008e-04, 6.9147e-07, 5.0260e-05,\n",
      "        3.5912e-03, 8.3769e-06, 5.3922e-06, 7.5652e-07, 1.0952e-08, 2.2434e-06,\n",
      "        1.3280e-06, 3.1986e-03, 1.3396e-01, 4.4428e-01, 1.6573e-05, 4.3909e-06,\n",
      "        1.0083e-06, 1.6354e-04, 1.9153e-06, 4.1081e-05, 5.6368e-06, 2.4955e-03,\n",
      "        2.2293e-04, 7.7454e-06, 3.0617e-06, 8.5475e-04, 1.2237e-06, 1.4157e-03,\n",
      "        8.9432e-03, 4.2416e-01, 1.1231e+03, 4.1621e-05], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([1.7199e-02, 4.6652e+01, 2.4708e+01, 5.7012e+01, 2.4545e+01, 1.2854e-01,\n",
      "        7.4203e-02, 1.0766e+02, 2.0544e+01, 3.8986e+01, 6.6099e+00, 5.6047e-02,\n",
      "        1.6657e+01, 4.4668e+01, 4.2477e-01, 1.9727e+01, 6.8371e+01, 2.9402e-01,\n",
      "        1.0668e+02, 4.4388e+01, 1.8995e+00, 3.4620e+00, 5.6720e+00, 5.6069e+00,\n",
      "        3.5543e+01, 6.3183e-02, 5.5050e+01, 2.1089e-01, 4.2115e+01, 9.6013e+00,\n",
      "        1.0682e+01, 3.8504e+01, 8.3419e+00, 2.1589e+00, 5.2950e+01, 8.9434e+00,\n",
      "        1.6346e+00, 2.2870e+01, 2.7278e+01, 5.1650e+01, 1.3046e+02, 3.7207e+01,\n",
      "        4.3879e+01, 1.3519e+00, 2.3986e+01, 3.7167e+01, 1.6810e+01, 2.9466e+01,\n",
      "        4.7603e+01, 3.2786e+00, 3.9161e+01, 1.0190e+01, 2.6816e+01, 8.3626e-01,\n",
      "        2.2527e+00, 2.3626e+01, 3.3510e+01, 2.4631e-02, 4.4968e+01, 1.2087e-01,\n",
      "        4.8000e+00, 3.6604e+01, 1.9409e+02, 1.0107e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(28.2932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([9.2020e-07, 4.2395e-05, 1.3416e-05, 7.4684e-02, 3.1409e-05, 5.8059e-04,\n",
      "        2.2557e-06, 2.6712e-04, 3.1775e-04, 2.2627e-06, 1.1204e-02, 1.7761e-06,\n",
      "        4.7312e-03, 2.2565e-07, 5.5618e-06, 6.5058e-08, 7.7587e-04, 3.9342e-02,\n",
      "        1.0142e-02, 1.5249e-05, 2.5183e-03, 3.0607e-06, 1.8153e-02, 3.0640e-06,\n",
      "        4.0685e-06, 1.0309e-04, 4.4643e-05, 2.8048e-02, 1.1683e-04, 8.3977e-03,\n",
      "        8.4100e-03, 1.6943e-07, 7.3542e-02, 1.6617e-04, 1.3718e-03, 3.4782e-02,\n",
      "        1.6617e-05, 3.0432e-06, 5.5676e-03, 1.8276e-07, 4.5383e-04, 4.1122e-03,\n",
      "        1.1097e-07, 4.3758e-03, 3.3468e-04, 2.9764e-06, 2.5609e-06, 2.7233e-05,\n",
      "        8.6273e-03, 3.4619e-05, 4.6875e-07, 1.9944e-02, 1.1255e+00, 2.0923e-02,\n",
      "        2.5183e-03, 5.9148e-04, 1.5653e-05, 1.0972e-04, 9.8913e-05, 4.5504e-06,\n",
      "        1.2288e-05, 5.4057e-02, 2.1273e-07, 1.1372e-04], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([4.8873e+01, 9.9902e+00, 1.8587e+01, 1.8604e+01, 1.1976e+01, 2.9563e-01,\n",
      "        3.7140e+01, 1.7426e+00, 1.3144e+00, 3.7103e+01, 5.8382e+00, 4.0111e+01,\n",
      "        2.4155e+00, 7.0502e+01, 2.6955e+01, 9.2934e+01, 6.4402e-02, 1.3486e+01,\n",
      "        5.3670e+00, 1.7500e+01, 8.5299e-01, 3.3514e+01, 8.4032e+00, 3.3501e+01,\n",
      "        3.0299e+01, 5.1625e+00, 9.6662e+00, 1.1115e+01, 4.6099e+00, 4.5282e+00,\n",
      "        4.5344e+00, 7.5396e+01, 1.8472e+01, 3.2211e+00, 9.9933e-02, 1.2596e+01,\n",
      "        1.6788e+01, 3.3580e+01, 2.9480e+00, 7.4086e+01, 6.2416e-01, 1.9993e+00,\n",
      "        8.2924e+01, 2.1789e+00, 1.1981e+00, 3.3838e+01, 3.5610e+01, 1.2984e+01,\n",
      "        4.6437e+00, 1.1312e+01, 5.8759e+01, 8.9576e+00, 4.9364e+01, 9.2469e+00,\n",
      "        8.5299e-01, 2.7576e-01, 1.7282e+01, 4.8832e+00, 5.3524e+00, 2.9080e+01,\n",
      "        1.9353e+01, 1.5920e+01, 7.1495e+01, 4.7262e+00], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(20.7349, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([1.1770e-02, 9.7552e-05, 8.6262e-05, 1.1357e+03, 3.5877e-06, 6.7849e-02,\n",
      "        2.4301e-04, 2.7350e-05, 2.0902e-02, 1.5312e-07, 1.7212e-02, 6.9622e-04,\n",
      "        2.4180e-02, 5.1181e-03, 6.8520e-03, 3.0377e-05, 6.1429e-02, 1.3455e-06,\n",
      "        1.6178e-06, 2.6222e-06, 2.9342e-06, 1.4960e-06, 1.0497e-01, 3.1130e-08,\n",
      "        2.9788e-01, 1.5294e-06, 3.0163e-06, 5.1100e-07, 2.2422e-06, 2.7480e-06,\n",
      "        2.2489e-04, 1.5569e-06, 7.3683e-02, 1.2096e-02, 4.2605e-07, 2.2330e-02,\n",
      "        1.1112e-02, 5.1955e-04, 1.5479e-05, 8.0943e-03, 5.0863e-06, 1.1607e-06,\n",
      "        1.1434e+03, 1.3669e-02, 1.0902e-02, 6.6779e-03, 1.2278e-05, 3.5879e-03,\n",
      "        4.3441e-07, 1.5318e-03, 3.0151e-01, 2.9424e-04, 7.6551e-03, 5.6109e-03,\n",
      "        1.6537e-05, 3.5300e-02, 3.5033e-02, 5.2040e-05, 9.2280e-08, 7.2995e-06,\n",
      "        6.5110e-05, 3.9031e-05, 1.7103e-07, 6.0930e-05], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([6.0789e+00, 5.4166e+00, 6.0043e+00, 1.9440e+02, 3.1700e+01, 1.7785e+01,\n",
      "        2.0012e+00, 1.2953e+01, 9.2407e+00, 7.7164e+01, 8.0976e+00, 1.3111e-01,\n",
      "        1.0147e+01, 2.6660e+00, 3.7038e+00, 1.2209e+01, 1.6957e+01, 4.3705e+01,\n",
      "        4.1303e+01, 3.5328e+01, 3.4004e+01, 4.2315e+01, 2.1657e+01, 1.0769e+02,\n",
      "        3.2452e+01, 4.2027e+01, 3.3683e+01, 5.7443e+01, 3.7214e+01, 3.4773e+01,\n",
      "        2.2265e+00, 4.1797e+01, 1.8488e+01, 6.2144e+00, 6.0232e+01, 9.6468e+00,\n",
      "        5.7984e+00, 4.2874e-01, 1.7374e+01, 4.3729e+00, 2.7891e+01, 4.5680e+01,\n",
      "        1.9459e+02, 6.8388e+00, 5.7069e+00, 3.6055e+00, 1.9360e+01, 1.6322e+00,\n",
      "        5.9931e+01, 1.8186e-01, 3.2590e+01, 1.4966e+00, 4.1427e+00, 2.9746e+00,\n",
      "        1.6827e+01, 1.2701e+01, 1.2647e+01, 8.7364e+00, 8.6317e+01, 2.4206e+01,\n",
      "        7.4620e+00, 1.0520e+01, 7.5233e+01, 7.8289e+00], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(28.3739, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([1.4581e-02, 7.4728e-04, 1.7082e-02, 6.2005e-04, 1.2974e-02, 8.0266e-03,\n",
      "        2.2266e-02, 1.4696e-04, 6.8664e-02, 7.9594e-02, 1.1207e+03, 4.2233e-01,\n",
      "        1.0189e-06, 8.6234e-06, 1.6979e-02, 1.4897e-07, 2.6809e-07, 6.0590e-05,\n",
      "        1.5403e-02, 2.2545e-06, 2.1984e-02, 9.7889e-02, 5.0953e-05, 1.1429e-02,\n",
      "        1.1445e+03, 4.4557e-05, 4.9407e-04, 4.7215e-07, 2.1360e-02, 1.7796e-02,\n",
      "        1.4036e-05, 2.0937e-06, 9.6021e-09, 5.4785e-07, 6.8840e-05, 2.7618e-03,\n",
      "        4.0804e-05, 2.8314e-02, 3.0509e-06, 1.9101e-05, 3.2111e-05, 1.7723e-02,\n",
      "        3.1051e-07, 3.6131e-06, 3.0975e-02, 5.0036e-05, 7.6539e-06, 9.2611e-07,\n",
      "        7.7303e-03, 5.9900e-04, 6.1709e-05, 3.7090e-02, 6.2935e-06, 1.9143e-06,\n",
      "        1.1249e-06, 4.0243e-01, 3.2138e-08, 6.5179e-03, 1.2096e-03, 2.5209e-06,\n",
      "        3.6325e-03, 3.4451e-04, 8.0719e-09, 5.1180e-02], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([7.1809e+00, 8.4865e-02, 8.0545e+00, 2.2844e-01, 6.5688e+00, 4.3379e+00,\n",
      "        9.6289e+00, 3.6772e+00, 1.7886e+01, 1.9158e+01, 1.9403e+02, 3.6551e+01,\n",
      "        4.7459e+01, 2.2594e+01, 8.0202e+00, 7.7647e+01, 6.7637e+01, 7.8603e+00,\n",
      "        7.4780e+00, 3.7147e+01, 9.5499e+00, 2.1012e+01, 8.8616e+00, 5.9350e+00,\n",
      "        1.9462e+02, 9.6783e+00, 4.9714e-01, 5.8648e+01, 9.3730e+00, 8.2885e+00,\n",
      "        1.8200e+01, 3.8055e+01, 1.3348e+02, 5.6393e+01, 7.1608e+00, 1.0320e+00,\n",
      "        1.0233e+01, 1.1178e+01, 3.3551e+01, 1.5666e+01, 1.1824e+01, 8.2647e+00,\n",
      "        6.5243e+01, 3.1620e+01, 1.1787e+01, 8.9701e+00, 2.3742e+01, 4.8783e+01,\n",
      "        4.1826e+00, 2.6265e-01, 7.7580e+00, 1.3056e+01, 2.5687e+01, 3.9168e+01,\n",
      "        4.6105e+01, 3.5970e+01, 1.0703e+02, 3.5139e+00, 3.6197e-02, 3.5798e+01,\n",
      "        1.6639e+00, 1.1356e+00, 1.3753e+02, 1.5487e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(29.9883, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([2.4751e-06, 3.6549e-07, 1.5056e-04, 2.4066e-05, 6.1481e-03, 1.7602e-06,\n",
      "        6.6895e-01, 1.1404e+03, 1.7592e-04, 1.4645e-01, 1.9498e-06, 1.2216e-06,\n",
      "        5.5817e-03, 9.6410e-09, 1.8449e-02, 1.8932e-06, 1.7642e-04, 1.5585e+00,\n",
      "        2.5152e-04, 4.1030e-04, 3.4845e-06, 4.4523e-05, 5.6217e-06, 1.8969e-02,\n",
      "        1.2216e-06, 1.0387e-07, 9.6597e-04, 4.1231e-04, 5.8074e-07, 2.7603e-03,\n",
      "        4.7888e-04, 5.2546e-07, 9.7964e-05, 8.9196e-03, 2.9329e-06, 3.2786e-06,\n",
      "        4.4283e-03, 8.4927e-07, 1.4731e-02, 4.8767e+00, 1.0901e-02, 8.9836e-03,\n",
      "        3.8176e-03, 6.9455e-03, 2.0452e-04, 9.3958e-02, 4.0922e-05, 4.9315e-03,\n",
      "        3.8890e-05, 1.1510e-06, 2.6052e-05, 1.4105e+00, 1.9149e-04, 1.8218e-01,\n",
      "        1.6538e-07, 4.7288e-05, 7.4109e-05, 7.1674e-06, 4.8213e-06, 1.4568e-06,\n",
      "        1.4407e-04, 1.0073e-06, 1.0551e-02, 7.2779e-08], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([3.6018e+01, 6.2636e+01, 3.5849e+00, 1.3890e+01, 3.2984e+00, 4.0225e+01,\n",
      "        4.2324e+01, 1.9452e+02, 3.0197e+00, 2.4867e+01, 3.8938e+01, 4.4992e+01,\n",
      "        2.9566e+00, 1.3339e+02, 8.4973e+00, 3.9306e+01, 3.0098e+00, 5.4044e+01,\n",
      "        1.9050e+00, 7.9365e-01, 3.2029e+01, 9.6830e+00, 2.6844e+01, 8.6600e+00,\n",
      "        4.4992e+01, 8.4133e+01, 1.1988e-03, 7.8497e-01, 5.5521e+01, 1.0309e+00,\n",
      "        5.4215e-01, 5.7021e+01, 5.3970e+00, 4.7885e+00, 3.4009e+01, 3.2722e+01,\n",
      "        2.2142e+00, 5.0001e+01, 7.2359e+00, 7.2118e+01, 5.7068e+00, 4.8198e+00,\n",
      "        1.7946e+00, 3.7562e+00, 2.5188e+00, 2.0637e+01, 1.0215e+01, 2.5461e+00,\n",
      "        1.0543e+01, 4.5794e+01, 1.3306e+01, 5.2588e+01, 2.7321e+00, 2.7092e+01,\n",
      "        7.5816e+01, 9.3117e+00, 6.7716e+00, 2.4386e+01, 2.8459e+01, 4.2661e+01,\n",
      "        3.7536e+00, 4.7617e+01, 5.5520e+00, 9.0784e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(28.4547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([2.3713e-05, 5.1426e-06, 1.4287e-02, 1.8972e-02, 5.2359e-03, 2.9630e-06,\n",
      "        7.6841e-01, 1.5906e-06, 5.2312e-04, 5.8968e-04, 9.6505e-04, 9.0524e-03,\n",
      "        2.8064e-04, 3.1982e-05, 2.5539e-06, 8.4094e-05, 4.2056e-01, 1.6594e-02,\n",
      "        2.6719e-02, 1.2951e-02, 5.3848e-04, 2.6105e+00, 3.5378e-06, 9.8588e-05,\n",
      "        7.5963e-04, 8.0151e-06, 3.7690e-03, 3.0445e-05, 3.3419e-06, 6.6111e-03,\n",
      "        8.5533e-03, 4.9168e+00, 6.5782e-03, 2.1458e-02, 1.1236e-03, 4.9328e-05,\n",
      "        3.5871e-02, 9.5614e-03, 3.6108e-02, 3.3685e-06, 1.2705e-06, 2.1462e-06,\n",
      "        3.5128e-07, 5.4991e-02, 3.3699e-03, 1.3382e-06, 5.4168e-03, 1.5990e-01,\n",
      "        1.9381e-01, 7.0556e-01, 8.0980e-03, 9.7628e-03, 1.5577e-07, 7.3486e-09,\n",
      "        3.5217e-01, 1.9047e-06, 1.0375e-06, 8.0175e-03, 1.1304e+03, 1.8313e-06,\n",
      "        2.6975e-09, 2.5121e-01, 3.5438e-06, 2.1743e-01], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([1.4001e+01, 2.7775e+01, 7.0723e+00, 8.6609e+00, 2.7408e+00, 3.3890e+01,\n",
      "        4.4147e+01, 4.1520e+01, 4.1983e-01, 2.7897e-01, 1.2656e-03, 4.8533e+00,\n",
      "        1.6147e+00, 1.1851e+01, 3.5643e+01, 6.1297e+00, 3.6501e+01, 7.8906e+00,\n",
      "        1.0794e+01, 6.5597e+00, 3.8316e-01, 6.1895e+01, 3.1857e+01, 5.3676e+00,\n",
      "        7.5585e-02, 2.3294e+01, 1.7604e+00, 1.2193e+01, 3.2504e+01, 3.5674e+00,\n",
      "        4.6067e+00, 7.2257e+01, 3.5485e+00, 9.4011e+00, 1.3582e-02, 9.0557e+00,\n",
      "        1.2816e+01, 5.0973e+00, 1.2863e+01, 3.2413e+01, 4.4467e+01, 3.7749e+01,\n",
      "        6.3265e+01, 1.6057e+01, 1.4759e+00, 4.3777e+01, 2.8544e+00, 2.5751e+01,\n",
      "        2.7740e+01, 4.3020e+01, 4.3749e+00, 5.1919e+00, 7.6863e+01, 1.3974e+02,\n",
      "        3.4388e+01, 3.9230e+01, 4.7209e+01, 4.3331e+00, 1.9427e+02, 3.9725e+01,\n",
      "        1.6443e+02, 3.0540e+01, 3.1838e+01, 2.8965e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(27.8839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([1.4959e-02, 1.3690e-06, 3.8145e-06, 4.4726e-07, 1.8273e-02, 7.1675e-07,\n",
      "        2.1968e-10, 1.1808e-01, 3.2992e-05, 3.1707e-08, 1.9917e-02, 1.0861e-02,\n",
      "        1.8503e-01, 7.6827e-03, 1.3963e-02, 1.0839e-06, 3.0617e-05, 6.1468e-01,\n",
      "        2.8222e-06, 7.3949e-08, 4.0803e-01, 1.2026e-04, 4.3282e-03, 3.8024e-08,\n",
      "        2.2332e-02, 4.4144e-02, 8.8298e+00, 2.0630e-05, 1.0563e-04, 6.0433e-07,\n",
      "        6.6744e-02, 1.5550e-05, 4.2094e-05, 8.3724e-06, 5.7642e-06, 4.3855e-01,\n",
      "        2.0536e-01, 7.5597e-07, 8.5217e-07, 3.3806e-06, 1.5665e-02, 6.8235e-05,\n",
      "        3.1380e-01, 3.1160e-04, 5.3775e-06, 2.5622e-04, 3.6539e-04, 3.0724e-07,\n",
      "        1.0018e-05, 2.3737e-01, 4.2784e-07, 2.3313e-03, 5.3082e+00, 9.4196e-07,\n",
      "        1.7845e-04, 4.5660e-03, 1.1332e-04, 3.7651e-03, 6.9094e-02, 2.1907e-06,\n",
      "        2.7543e-06, 7.2718e-05, 2.5849e-04, 3.4498e-03], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([  7.3188,  43.4762,  31.0131,  59.4806,   8.4414,  52.4289, 235.0429,\n",
      "         22.7657,  11.6384, 107.3080,   8.9494,   5.6890,  27.2535,   4.1574,\n",
      "          6.9505,  46.6110,  12.1537,  41.2305,  34.4597,  90.4808,  36.1362,\n",
      "          4.4862,   2.1466, 103.5775,   9.6475,  14.3448,  82.5533,  15.0621,\n",
      "          5.0526,  54.9287,  17.6473,  17.3362,  10.0352,  22.8753,  26.5853,\n",
      "         37.0087,  28.3531,  51.6602,  49.9527,  32.3727,   7.5703,   7.2081,\n",
      "         33.0480,   1.3596,  27.3061,   1.8543,   1.0136,  65.4139,  21.1909,\n",
      "         29.9166,  60.1675,   0.7164,  73.5650,  48.5467,   2.9703,   2.3063,\n",
      "          4.7417,   1.7577,  17.9392,  37.4975,  34.7460,   6.8705,   1.8304,\n",
      "          1.5335], device='cuda:0', grad_fn=<PowBackward0>)\n",
      "tensor(30.7763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([1.0154e-03, 3.3341e-02, 1.1104e-05, 2.5183e-06, 3.7142e-01, 1.5566e-02,\n",
      "        5.8174e-05, 2.4434e-05, 7.2989e-05, 8.4586e-06, 1.3675e+00, 7.2471e-02,\n",
      "        1.1426e-04, 2.5556e-04, 1.0082e-04, 8.6565e-03, 2.2399e-03, 2.9096e-02,\n",
      "        4.0312e-07, 7.4187e-01, 6.0283e-04, 5.2367e-05, 5.5165e-07, 1.7611e-06,\n",
      "        3.8511e-06, 2.2096e-03, 4.4037e-01, 4.1167e-04, 9.8689e-04, 3.6789e-07,\n",
      "        3.8013e-08, 7.2989e-05, 9.7674e-03, 3.9228e-02, 7.6224e-10, 1.4942e-06,\n",
      "        9.5150e+00, 2.5884e-05, 2.8395e-04, 4.6132e-08, 8.5050e-03, 2.2392e-06,\n",
      "        5.1689e-05, 1.3374e-04, 9.4064e-04, 3.3517e-03, 2.5523e-07, 4.5605e-03,\n",
      "        1.0079e-06, 7.0375e-07, 7.2579e-03, 1.1142e-01, 1.3991e-04, 1.6669e-01,\n",
      "        3.6453e-03, 4.0108e-07, 3.8371e-08, 2.6929e-06, 9.9395e-04, 2.2526e-05,\n",
      "        4.1184e-03, 2.6053e-04, 3.7619e-03, 2.8067e-06], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([2.3264e-04, 1.2298e+01, 2.0254e+01, 3.5810e+01, 3.5015e+01, 7.5356e+00,\n",
      "        8.0901e+00, 1.3777e+01, 6.8510e+00, 2.2777e+01, 5.2139e+01, 1.8346e+01,\n",
      "        4.7060e+00, 1.8613e+00, 5.2642e+00, 4.6583e+00, 6.5032e-01, 1.1361e+01,\n",
      "        6.1094e+01, 4.3681e+01, 2.5616e-01, 8.6994e+00, 5.6289e+01, 4.0218e+01,\n",
      "        3.0907e+01, 6.2858e-01, 3.7059e+01, 7.8770e-01, 1.7407e-04, 6.2532e+01,\n",
      "        1.0358e+02, 6.8510e+00, 5.1941e+00, 1.3464e+01, 1.9844e+02, 4.2330e+01,\n",
      "        8.3917e+01, 1.3353e+01, 1.5850e+00, 9.9681e+01, 4.5824e+00, 3.7230e+01,\n",
      "        8.7764e+00, 4.0476e+00, 3.7442e-03, 1.4628e+00, 6.8448e+01, 2.3026e+00,\n",
      "        4.7608e+01, 5.2694e+01, 3.9287e+00, 2.2215e+01, 3.8682e+00, 2.6175e+01,\n",
      "        1.6730e+00, 6.1173e+01, 1.0339e+02, 3.5013e+01, 3.6866e-05, 1.4388e+01,\n",
      "        2.0036e+00, 1.8091e+00, 1.7554e+00, 3.4524e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(26.7348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([3.2753e-06, 2.0476e-06, 8.8036e-07, 3.1933e-05, 4.2031e-05, 7.2330e-07,\n",
      "        4.0449e-02, 3.1219e-03, 6.4520e-02, 8.8453e-08, 1.8817e-03, 1.0632e-06,\n",
      "        1.5577e-02, 5.7885e-04, 3.3273e-04, 1.1305e-06, 4.4341e-05, 1.3232e-04,\n",
      "        3.8749e-02, 3.2137e-02, 2.4707e-01, 1.9303e-06, 2.2251e-08, 4.9459e-02,\n",
      "        8.0206e-08, 2.3051e-03, 9.1137e-03, 6.6474e-07, 2.1265e-01, 2.5814e-07,\n",
      "        2.2375e-03, 1.5220e-03, 1.1260e+03, 8.5315e-03, 2.3406e-02, 1.4906e-03,\n",
      "        6.4103e-05, 8.4021e-06, 5.1705e-04, 5.2850e-05, 7.2930e-06, 3.4341e-04,\n",
      "        2.5569e-03, 1.2195e-04, 1.8894e-06, 1.3655e-02, 4.9505e-06, 1.0028e-03,\n",
      "        2.6611e-05, 1.2744e-06, 1.6332e-07, 4.0441e-01, 6.9031e-05, 1.0115e-05,\n",
      "        6.5592e-04, 2.5566e-04, 1.6265e-06, 4.3953e-01, 4.0911e-06, 7.1890e-02,\n",
      "        3.3015e-06, 1.1591e-06, 6.2378e-04, 1.0736e-05], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([3.2734e+01, 3.8330e+01, 4.9494e+01, 1.1862e+01, 1.0045e+01, 5.2297e+01,\n",
      "        1.3690e+01, 1.2961e+00, 1.7364e+01, 8.7106e+01, 3.9967e-01, 4.6874e+01,\n",
      "        7.5393e+00, 2.9889e-01, 1.2109e+00, 4.6037e+01, 9.7086e+00, 4.0907e+00,\n",
      "        1.3374e+01, 1.2041e+01, 3.0356e+01, 3.9064e+01, 1.1477e+02, 1.5219e+01,\n",
      "        8.8942e+01, 6.9745e-01, 4.8831e+00, 5.3526e+01, 2.8726e+01, 6.8261e+01,\n",
      "        6.4862e-01, 1.7641e-01, 1.9416e+02, 4.5957e+00, 9.9414e+00, 1.5937e-01,\n",
      "        7.5475e+00, 2.2841e+01, 4.3509e-01, 8.6454e+00, 2.4215e+01, 1.1424e+00,\n",
      "        8.8130e-01, 4.4276e+00, 3.9332e+01, 6.8334e+00, 2.8178e+01, 7.6499e-06,\n",
      "        1.3151e+01, 4.4426e+01, 7.6035e+01, 3.6029e+01, 7.1460e+00, 2.1102e+01,\n",
      "        1.7785e-01, 1.8603e+00, 4.1233e+01, 3.7036e+01, 3.0238e+01, 1.8277e+01,\n",
      "        3.2643e+01, 4.5700e+01, 2.2274e-01, 2.0558e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(26.2536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([6.8070e-05, 1.5456e-03, 1.1244e-06, 1.7266e-03, 9.1853e-07, 3.3456e-03,\n",
      "        2.2490e-01, 1.1171e+03, 2.0188e-03, 1.0503e-02, 4.7575e-04, 1.2689e-02,\n",
      "        6.0503e-07, 7.0823e-06, 1.5568e-03, 3.1438e-06, 1.4205e-02, 2.7148e-07,\n",
      "        7.0977e-03, 1.1421e-04, 6.4988e-05, 7.5094e-06, 1.6147e-04, 3.0197e-05,\n",
      "        1.1841e-03, 1.8815e-01, 1.3275e-02, 1.0387e-03, 9.4948e-06, 4.7006e-06,\n",
      "        2.3145e-03, 5.5571e-01, 3.1622e-08, 2.2006e-04, 4.0938e-04, 2.0906e-06,\n",
      "        6.3232e-06, 9.6799e-05, 1.2193e-01, 1.2414e-03, 7.7181e-03, 5.6993e-03,\n",
      "        8.0919e-09, 1.3067e-05, 1.9620e-07, 5.0658e-03, 4.5796e-06, 3.0899e-02,\n",
      "        1.0188e-04, 6.5804e-03, 1.8899e-02, 1.5562e-07, 2.9834e-01, 1.7902e-09,\n",
      "        5.4384e-03, 5.2735e-03, 5.5057e-07, 1.1987e-03, 2.9500e-02, 8.6617e-07,\n",
      "        4.5060e-07, 3.0935e-06, 6.8162e-02, 6.3614e-01], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([7.2211e+00, 1.8960e-01, 4.6111e+01, 2.9826e-01, 4.8898e+01, 1.4584e+00,\n",
      "        2.9329e+01, 1.9394e+02, 4.9348e-01, 5.5302e+00, 5.5184e-01, 6.4555e+00,\n",
      "        5.4912e+01, 2.4504e+01, 1.9593e-01, 3.3204e+01, 7.0417e+00, 6.7431e+01,\n",
      "        3.8407e+00, 4.7075e+00, 7.4723e+00, 2.3928e+01, 3.3250e+00, 1.2250e+01,\n",
      "        2.8549e-02, 2.7429e+01, 6.6867e+00, 1.4385e-03, 2.1688e+01, 2.8730e+01,\n",
      "        7.0426e-01, 3.9946e+01, 1.0736e+02, 2.2918e+00, 7.9765e-01, 3.8073e+01,\n",
      "        2.5639e+01, 5.4528e+00, 2.3073e+01, 4.6753e-02, 4.1762e+00, 3.0288e+00,\n",
      "        1.3747e+02, 1.8815e+01, 7.2870e+01, 2.6326e+00, 2.9011e+01, 1.1770e+01,\n",
      "        5.2166e+00, 3.5498e+00, 8.6382e+00, 7.6879e+01, 3.2470e+01, 1.7512e+02,\n",
      "        2.8679e+00, 2.7646e+00, 5.6318e+01, 3.2841e-02, 1.1454e+01, 4.9723e+01,\n",
      "        5.9366e+01, 3.3390e+01, 1.7824e+01, 4.1672e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(27.6296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([1.3033e-05, 4.7231e-03, 3.2962e-06, 1.4047e-06, 9.1391e-07, 2.5203e-03,\n",
      "        1.4698e-02, 1.9325e-02, 5.9694e-05, 2.8889e-06, 4.0283e-07, 1.8709e-05,\n",
      "        4.5301e-04, 1.1611e-05, 1.8143e-07, 1.8089e-04, 2.7385e-06, 5.6071e-05,\n",
      "        2.1030e-03, 6.4796e-06, 4.1530e-02, 6.2409e-03, 3.9731e-02, 4.2763e-07,\n",
      "        4.9272e-06, 3.9381e-03, 4.5099e-07, 2.1312e+00, 4.1984e-03, 2.0246e-02,\n",
      "        2.9098e-07, 3.8136e-06, 3.1950e-08, 8.6317e-03, 1.5552e-02, 2.6203e-03,\n",
      "        2.0848e-04, 1.4548e-06, 1.5151e-04, 8.3021e-01, 1.0290e-01, 4.8268e-06,\n",
      "        8.0643e-07, 9.3154e-06, 2.8798e-06, 4.0345e-01, 1.5757e+01, 2.5040e-07,\n",
      "        2.1587e-02, 2.8317e-02, 2.5203e-03, 5.3506e-06, 5.3859e-02, 1.5159e-04,\n",
      "        2.0551e-07, 8.9005e-07, 1.6873e-04, 1.3546e-02, 2.3243e-06, 7.5091e-03,\n",
      "        2.2327e-06, 4.3597e-01, 3.7643e-03, 2.5558e-06], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([ 18.8379,   2.4101,  32.6610,  43.1380,  48.9689,   0.8545,   7.2238,\n",
      "          8.7698,   7.9440,  34.1860,  61.1054,  15.8305,   0.6270,  19.8544,\n",
      "         74.2117,   2.9236,  34.8141,   8.3009,   0.5526,  25.3925,  13.8861,\n",
      "          3.3530,  13.5582,  60.1749,  28.2277,   1.8788,  59.3526,  58.7435,\n",
      "          2.0584,   9.0479,  66.2961,  31.0158, 107.1502,   4.6459,   7.5305,\n",
      "          0.9279,   2.4583,  42.6789,   3.5611,  45.1809,  21.4718,  28.4470,\n",
      "         50.7356,  21.8658,  34.2230,  36.0008,  93.4135,  68.7645,   9.4377,\n",
      "         11.1788,   0.8545,  27.3586,  15.8912,   3.5592,  72.0805,  49.3399,\n",
      "          3.1665,   6.7917,  36.7760,   4.0647,  37.2655,  36.9370,   1.7571,\n",
      "         35.6339], device='cuda:0', grad_fn=<PowBackward0>)\n",
      "tensor(26.8336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([6.3393e-03, 5.0094e-03, 7.1436e-02, 4.3794e-08, 3.1297e-02, 5.1608e-04,\n",
      "        6.3171e-06, 1.0995e-02, 1.4871e-07, 4.7243e-06, 1.4638e-02, 2.1776e-04,\n",
      "        4.6520e-05, 7.3790e-03, 4.2888e-07, 4.6313e-05, 4.1180e-02, 6.9540e-04,\n",
      "        5.3223e-05, 1.0030e-05, 3.3208e-04, 1.8494e-06, 6.2913e-03, 1.2688e-03,\n",
      "        1.9103e-02, 5.2851e-05, 4.5263e-04, 7.6854e-03, 1.1601e-02, 3.8178e-06,\n",
      "        1.8218e-05, 1.1770e-05, 6.8596e-05, 1.2951e-03, 6.8558e-05, 5.3223e-05,\n",
      "        4.6520e-05, 8.4705e-07, 4.8081e-04, 4.3966e-03, 4.8817e-07, 1.3540e-02,\n",
      "        3.6824e-05, 3.4357e-03, 9.8558e-07, 3.5242e-09, 7.3925e-04, 5.2851e-05,\n",
      "        1.4764e-06, 1.1085e-07, 3.2270e-03, 7.5505e-07, 6.0761e-03, 1.3914e-05,\n",
      "        1.5582e-06, 1.0669e-04, 3.0693e-07, 9.2273e-06, 2.9494e-05, 2.1820e-02,\n",
      "        1.4205e-03, 3.5470e-06, 3.4234e-06, 1.3510e-05], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([3.4105e+00, 2.5963e+00, 1.8223e+01, 1.0072e+02, 1.1858e+01, 4.3758e-01,\n",
      "        2.5649e+01, 5.7478e+00, 7.7679e+01, 2.8676e+01, 7.2017e+00, 2.3236e+00,\n",
      "        9.4118e+00, 3.9946e+00, 6.0130e+01, 9.4392e+00, 1.3823e+01, 1.3197e-01,\n",
      "        8.6040e+00, 2.1180e+01, 1.2152e+00, 3.9600e+01, 3.3825e+00, 5.6671e-02,\n",
      "        8.7017e+00, 8.6452e+00, 6.2834e-01, 4.1588e+00, 6.0080e+00, 3.1003e+01,\n",
      "        1.6043e+01, 1.9733e+01, 7.1798e+00, 6.6881e-02, 7.1828e+00, 8.6040e+00,\n",
      "        9.4118e+00, 5.0038e+01, 5.3623e-01, 2.1929e+00, 5.8138e+01, 6.7895e+00,\n",
      "        1.0901e+01, 1.5233e+00, 4.7918e+01, 1.5765e+02, 9.1279e-02, 8.6452e+00,\n",
      "        4.2486e+01, 8.2943e+01, 1.3725e+00, 5.1678e+01, 3.2558e+00, 1.8274e+01,\n",
      "        4.1786e+01, 5.0080e+00, 6.5430e+01, 2.1955e+01, 1.2416e+01, 9.5037e+00,\n",
      "        1.2322e-01, 3.1828e+01, 3.2230e+01, 1.8527e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(21.3453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([1.0619e-03, 5.4063e+01, 2.4513e-02, 2.8567e-04, 9.9845e-01, 4.1149e-05,\n",
      "        5.0771e-04, 2.8398e-06, 4.0709e-01, 6.4418e-07, 6.8499e-04, 1.3451e-03,\n",
      "        7.0614e-01, 3.8999e-04, 6.3623e-03, 1.0479e-02, 3.1021e-07, 7.1605e-05,\n",
      "        3.3062e-07, 4.6125e-05, 6.3044e-06, 1.0990e-02, 2.8153e-05, 2.0012e-03,\n",
      "        2.8913e-02, 1.6122e-06, 1.5733e-06, 2.8496e-05, 1.2381e-03, 2.6553e-05,\n",
      "        1.0800e-03, 7.5334e-05, 1.3211e-09, 6.7822e-02, 7.0702e-07, 1.3332e-04,\n",
      "        9.5882e-06, 1.1236e-07, 6.8421e-06, 6.3987e-03, 8.6619e-04, 1.2074e-05,\n",
      "        4.1337e-07, 1.1961e-04, 4.2783e-01, 1.8156e-02, 3.9042e+00, 1.1753e-02,\n",
      "        1.5808e-05, 2.9624e-07, 9.7206e-07, 5.9545e-06, 1.5580e-06, 1.3439e-07,\n",
      "        7.7853e-02, 2.0560e-02, 2.6799e-06, 5.4359e-05, 6.8845e-02, 1.9300e-02,\n",
      "        4.2167e-03, 5.8084e-07, 8.5796e-03, 1.5279e-07], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([3.6065e-03, 1.1876e+02, 1.0235e+01, 1.5698e+00, 4.7696e+01, 1.0180e+01,\n",
      "        4.5949e-01, 3.4387e+01, 3.6109e+01, 5.3986e+01, 1.4315e-01, 8.7897e-02,\n",
      "        4.3031e+01, 8.8665e-01, 3.4239e+00, 5.5197e+00, 6.5258e+01, 6.9516e+00,\n",
      "        6.4233e+01, 9.4643e+00, 2.5670e+01, 5.7456e+00, 1.2746e+01, 4.8126e-01,\n",
      "        1.1318e+01, 4.1347e+01, 4.1662e+01, 1.2659e+01, 4.5616e-02, 1.3167e+01,\n",
      "        5.9277e-03, 6.6865e+00, 1.8325e+02, 1.7782e+01, 5.2627e+01, 4.0601e+00,\n",
      "        2.1597e+01, 8.2697e+01, 2.4847e+01, 3.4451e+00, 2.0635e-02, 1.9507e+01,\n",
      "        6.0702e+01, 4.5093e+00, 3.6708e+01, 8.4041e+00, 6.8390e+01, 6.0717e+00,\n",
      "        1.7200e+01, 6.6005e+01, 4.8109e+01, 2.6251e+01, 4.1787e+01, 7.9473e+01,\n",
      "        1.8965e+01, 9.1406e+00, 3.5070e+01, 8.4806e+00, 1.7909e+01, 8.7623e+00,\n",
      "        2.0709e+00, 5.5518e+01, 4.6199e+00, 7.7201e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(28.0485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([1.7105e-04, 7.6440e-05, 1.4266e-04, 8.8964e-08, 7.4299e-06, 1.3765e+01,\n",
      "        3.8782e-03, 3.3485e-03, 1.6119e-04, 1.0651e-04, 7.5420e-08, 1.1170e+03,\n",
      "        2.5450e-05, 3.0674e-03, 2.1775e-02, 2.7061e-04, 1.6311e-06, 3.1918e-09,\n",
      "        1.6199e-02, 5.6921e-04, 5.8711e-03, 3.5997e-07, 6.9395e-03, 1.7726e-03,\n",
      "        4.0247e-01, 9.7004e-08, 1.1593e-02, 3.0141e-05, 1.8186e-02, 3.3800e-03,\n",
      "        2.2321e-03, 6.2006e-03, 8.4602e-06, 3.6820e-06, 2.1193e-04, 4.6928e-05,\n",
      "        5.2810e-05, 4.6126e-05, 9.6873e-07, 1.9385e+00, 8.8649e-04, 3.9066e-03,\n",
      "        1.1897e-03, 6.4645e-02, 3.6503e-06, 1.0961e-05, 1.6880e-06, 2.0557e-06,\n",
      "        1.1867e-03, 9.8627e-07, 4.3011e-07, 7.5420e-08, 6.8672e-02, 3.0266e-05,\n",
      "        4.0845e-01, 4.3573e-03, 1.0269e-01, 8.1457e-07, 2.7286e-05, 5.0621e-03,\n",
      "        9.7967e-05, 1.2005e-04, 1.1347e-03, 1.2968e-05], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([3.1181e+00, 6.6113e+00, 3.7918e+00, 8.6998e+01, 2.4032e+01, 9.0819e+01,\n",
      "        1.8370e+00, 1.4605e+00, 3.3312e+00, 5.0156e+00, 9.0106e+01, 1.9394e+02,\n",
      "        1.3477e+01, 1.2562e+00, 9.4911e+00, 1.7084e+00, 4.1198e+01, 1.6015e+02,\n",
      "        7.7558e+00, 3.1753e-01, 3.1330e+00, 6.2877e+01, 3.7528e+00, 3.2767e-01,\n",
      "        3.5971e+01, 8.5392e+01, 6.0044e+00, 1.2263e+01, 8.4138e+00, 1.4832e+00,\n",
      "        6.4468e-01, 3.3293e+00, 2.2776e+01, 3.1408e+01, 2.4072e+00, 9.3584e+00,\n",
      "        8.6499e+00, 9.4641e+00, 4.8157e+01, 5.7300e+01, 1.4517e-02, 1.8569e+00,\n",
      "        3.0176e-02, 1.7380e+01, 3.1505e+01, 2.0371e+01, 4.0758e+01, 3.8281e+01,\n",
      "        2.9302e-02, 4.7908e+01, 6.0085e+01, 9.0106e+01, 1.7887e+01, 1.2234e+01,\n",
      "        3.6149e+01, 2.1663e+00, 2.1453e+01, 5.0593e+01, 1.2970e+01, 2.6302e+00,\n",
      "        5.3969e+00, 4.4938e+00, 1.5974e-02, 1.8882e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(26.4487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([6.3969e-03, 2.9642e-05, 1.8605e-07, 1.6845e-02, 1.1601e-03, 6.5703e-05,\n",
      "        2.0872e-06, 1.7245e-01, 3.8556e-06, 9.6981e-06, 2.9497e-05, 3.7460e-06,\n",
      "        5.9334e-07, 7.5471e-07, 4.1674e-06, 1.3254e-02, 5.8212e-03, 2.2665e-06,\n",
      "        6.8736e-02, 8.7146e-05, 2.6178e-04, 5.6424e-01, 9.9631e-04, 1.8088e-04,\n",
      "        7.0802e-03, 4.3310e-01, 2.5118e-05, 2.0162e-03, 2.3919e-01, 3.3474e-02,\n",
      "        3.6470e-07, 2.2517e-07, 4.5070e-05, 6.5239e-02, 2.2424e-05, 7.4834e-03,\n",
      "        5.5505e-06, 1.0499e-04, 5.3811e-06, 1.1321e-09, 9.5854e-05, 5.4777e-05,\n",
      "        1.5760e-05, 7.7127e-03, 7.3979e-06, 7.5681e-06, 3.1934e-05, 1.9024e-06,\n",
      "        7.2376e-03, 2.2676e-06, 3.4157e-03, 5.9543e-06, 3.5310e-08, 3.9026e-04,\n",
      "        4.4593e-07, 1.5887e-06, 7.9232e-07, 1.2580e-06, 3.1950e-09, 9.0710e-04,\n",
      "        7.3986e-05, 9.6981e-06, 1.8156e-06, 4.7658e-04], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([3.4441e+00, 1.2380e+01, 7.3779e+01, 7.9753e+00, 2.2051e-02, 7.4126e+00,\n",
      "        3.8093e+01, 2.6524e+01, 3.0894e+01, 2.1491e+01, 1.2415e+01, 3.1215e+01,\n",
      "        5.5201e+01, 5.1684e+01, 3.0035e+01, 6.6787e+00, 3.1029e+00, 3.7082e+01,\n",
      "        1.7895e+01, 5.9544e+00, 1.7963e+00, 4.0138e+01, 1.3676e-05, 2.9239e+00,\n",
      "        3.8310e+00, 3.6857e+01, 1.3573e+01, 4.9171e-01, 3.0000e+01, 1.2326e+01,\n",
      "        6.2670e+01, 7.0537e+01, 9.6072e+00, 1.7456e+01, 1.4422e+01, 4.0509e+00,\n",
      "        2.6976e+01, 5.0801e+00, 2.7299e+01, 1.8746e+02, 5.4987e+00, 8.4360e+00,\n",
      "        1.7225e+01, 4.1733e+00, 2.4074e+01, 2.3852e+01, 1.1862e+01, 3.9246e+01,\n",
      "        3.9176e+00, 3.7076e+01, 1.5089e+00, 2.6252e+01, 1.0509e+02, 8.8539e-01,\n",
      "        5.9527e+01, 4.1536e+01, 5.0987e+01, 4.4599e+01, 1.6012e+02, 9.5076e-03,\n",
      "        6.7802e+00, 2.1491e+01, 3.9833e+01, 5.4926e-01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(27.7391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([4.2548e-01, 3.2139e-03, 7.2823e-04, 6.1545e-06, 5.3701e-06, 1.2974e-05,\n",
      "        4.5087e-04, 6.2114e-03, 1.7429e-06, 2.5854e-05, 5.8029e-03, 1.3611e-03,\n",
      "        9.4479e-04, 7.0224e-05, 3.1007e-07, 1.0631e-06, 1.5982e-05, 4.4059e+00,\n",
      "        5.4599e-03, 5.6631e-06, 5.1436e-03, 5.2484e-07, 2.1223e-05, 4.6115e-08,\n",
      "        1.1035e-05, 4.4606e-07, 1.1765e-03, 1.5012e-03, 4.0809e-05, 6.7202e-01,\n",
      "        1.5162e-04, 3.6652e-03, 1.4135e-02, 4.2860e-01, 2.1673e-03, 1.4399e-05,\n",
      "        4.8397e-03, 1.1611e-03, 1.6645e-04, 2.3228e-03, 2.1673e-03, 2.4403e-05,\n",
      "        2.4441e-05, 1.1244e-06, 7.0959e-07, 8.8912e-02, 1.9698e-07, 7.1171e-09,\n",
      "        4.8195e-07, 1.9642e-03, 9.7539e-03, 3.9439e-06, 7.2176e-05, 1.0017e-05,\n",
      "        7.1896e-07, 5.4969e-03, 3.9585e-07, 1.1006e-05, 7.8168e-09, 1.1045e-02,\n",
      "        3.2310e-06, 9.6274e-07, 9.6274e-07, 4.3961e-04], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([3.6641e+01, 1.3630e+00, 1.0057e-01, 2.5914e+01, 2.7321e+01, 1.8877e+01,\n",
      "        6.3455e-01, 3.3357e+00, 4.0350e+01, 1.3361e+01, 3.0918e+00, 9.5045e-02,\n",
      "        3.2248e-03, 7.0547e+00, 6.5266e+01, 4.6876e+01, 1.7109e+01, 7.0404e+01,\n",
      "        2.8813e+00, 2.6768e+01, 2.6822e+00, 5.7039e+01, 1.4843e+01, 9.9687e+01,\n",
      "        2.0310e+01, 5.9522e+01, 2.6433e-02, 1.6507e-01, 1.0233e+01, 4.2384e+01,\n",
      "        3.5583e+00, 1.6871e+00, 7.0155e+00, 3.6730e+01, 5.9825e-01, 1.7983e+01,\n",
      "        2.4865e+00, 2.2322e-02, 3.2151e+00, 7.1030e-01, 5.9825e-01, 1.3787e+01,\n",
      "        1.3775e+01, 4.6110e+01, 5.2574e+01, 2.0139e+01, 7.2802e+01, 1.4049e+02,\n",
      "        5.8334e+01, 4.5576e-01, 5.1878e+00, 3.0643e+01, 6.9098e+00, 2.1192e+01,\n",
      "        5.2384e+01, 2.9043e+00, 6.1379e+01, 2.0334e+01, 1.3828e+02, 5.7696e+00,\n",
      "        3.2890e+01, 4.8243e+01, 4.8243e+01, 6.7545e-01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(26.2883, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([6.0095e-03, 2.6167e-05, 2.9823e-05, 5.1675e-05, 6.9420e-04, 7.9374e-07,\n",
      "        9.0393e-07, 4.7351e-06, 6.7972e-03, 1.4958e-04, 3.3145e-04, 7.6211e-10,\n",
      "        3.2079e-03, 9.1932e-05, 3.3571e-02, 1.0074e-02, 9.3919e-04, 4.8981e-06,\n",
      "        3.0567e-05, 3.8746e-02, 7.9910e-08, 4.0548e-05, 1.1281e-06, 9.9860e-04,\n",
      "        3.9149e-06, 9.2115e-08, 2.2084e-03, 4.3691e-06, 3.4750e-01, 1.2833e-05,\n",
      "        5.1022e-07, 1.7564e-06, 6.5928e-03, 1.4264e-04, 3.2320e-06, 1.9372e-03,\n",
      "        1.0099e-05, 2.6556e-04, 1.5911e-05, 4.1010e-01, 6.1180e-06, 1.3602e-04,\n",
      "        7.1001e-02, 1.3456e-05, 3.3399e-02, 5.8411e-03, 1.1078e-07, 6.8120e-03,\n",
      "        2.2482e-04, 8.6437e-03, 1.1621e-02, 7.0020e-02, 8.9084e-04, 1.0867e-05,\n",
      "        1.3208e-04, 3.1525e-03, 2.0612e-06, 2.6222e-04, 2.2519e-02, 1.0862e-03,\n",
      "        3.5261e-06, 7.9343e-07, 1.9623e-07, 3.0547e-06], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([3.2161e+00, 1.3273e+01, 1.2338e+01, 8.7780e+00, 1.3322e-01, 5.0962e+01,\n",
      "        4.9123e+01, 2.8652e+01, 3.6730e+00, 3.6098e+00, 1.2194e+00, 1.9845e+02,\n",
      "        1.3587e+00, 5.6963e+00, 1.2346e+01, 5.3361e+00, 3.9357e-03, 2.8291e+01,\n",
      "        1.2165e+01, 1.3374e+01, 8.9012e+01, 1.0274e+01, 4.6066e+01, 1.9574e-06,\n",
      "        3.0725e+01, 8.6350e+01, 6.2765e-01, 2.9520e+01, 3.4231e+01, 1.8972e+01,\n",
      "        5.7467e+01, 4.0253e+01, 3.5569e+00, 3.7924e+00, 3.2886e+01, 4.3725e-01,\n",
      "        2.1117e+01, 1.7581e+00, 1.7146e+01, 3.6197e+01, 2.5975e+01, 3.9798e+00,\n",
      "        1.8171e+01, 1.8562e+01, 1.2310e+01, 3.1149e+00, 8.2955e+01, 3.6814e+00,\n",
      "        2.2274e+00, 4.6519e+00, 6.0163e+00, 1.8052e+01, 1.3362e-02, 2.0449e+01,\n",
      "        4.0980e+00, 1.3184e+00, 3.8248e+01, 1.7918e+00, 9.6993e+00, 6.8318e-03,\n",
      "        3.1895e+01, 5.0967e+01, 7.2867e+01, 3.3536e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(23.0776, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([7.2571e-02, 2.5182e-06, 2.8742e-02, 4.9309e-06, 3.0368e-05, 1.2122e-06,\n",
      "        6.2044e-03, 9.3828e-02, 5.1497e+00, 2.9859e-06, 1.1791e-05, 4.3475e-05,\n",
      "        6.5025e-08, 2.5715e-07, 8.5952e-05, 1.0916e-04, 1.0579e-04, 5.3377e-07,\n",
      "        1.9066e-05, 3.3621e-03, 3.2150e-06, 2.4870e-07, 6.3379e-05, 8.4406e-04,\n",
      "        1.5187e-01, 3.7158e-02, 3.7611e-04, 2.2599e-06, 2.3304e-03, 4.8554e-04,\n",
      "        8.7281e-01, 5.4806e-04, 4.2645e-06, 5.0905e-05, 4.1843e-05, 1.2215e-02,\n",
      "        1.1903e-04, 1.0421e-05, 1.2780e-07, 1.2936e-01, 5.9537e-03, 6.5228e-05,\n",
      "        3.7444e-05, 3.3771e-03, 1.0856e-03, 2.3598e-02, 1.8777e-05, 3.3671e-06,\n",
      "        3.4747e-02, 1.9505e-03, 5.4058e-07, 1.1414e-02, 1.1008e-02, 5.8154e-07,\n",
      "        2.4817e-06, 1.3378e-06, 8.0658e-09, 7.5971e-04, 2.2855e-02, 5.3455e-05,\n",
      "        2.6270e-03, 1.5385e+00, 9.8842e-04, 1.3952e-02], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([1.8358e+01, 3.5811e+01, 1.1279e+01, 2.8220e+01, 1.2211e+01, 4.5095e+01,\n",
      "        3.3316e+00, 2.0625e+01, 7.3046e+01, 3.3801e+01, 1.9717e+01, 9.8318e+00,\n",
      "        9.2944e+01, 6.8324e+01, 6.0219e+00, 4.9061e+00, 5.0458e+00, 5.6785e+01,\n",
      "        1.5680e+01, 1.4703e+00, 3.2947e+01, 6.8877e+01, 7.6100e+00, 2.8742e-02,\n",
      "        2.5231e+01, 1.3069e+01, 9.5624e-01, 3.7118e+01, 7.1577e-01, 5.2199e-01,\n",
      "        4.5856e+01, 3.6164e-01, 2.9783e+01, 8.8673e+00, 1.0073e+01, 6.2634e+00,\n",
      "        4.5298e+00, 2.0829e+01, 8.0371e+01, 2.3645e+01, 3.1827e+00, 7.4522e+00,\n",
      "        1.0791e+01, 1.4811e+00, 6.7462e-03, 9.9930e+00, 1.5802e+01, 3.2418e+01,\n",
      "        1.2589e+01, 4.4634e-01, 5.6594e+01, 5.9286e+00, 5.7535e+00, 5.5500e+01,\n",
      "        3.5986e+01, 4.3781e+01, 1.3754e+02, 7.5524e-02, 9.7916e+00, 8.5786e+00,\n",
      "        9.3284e-01, 5.3854e+01, 1.3574e-04, 6.9465e+00], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(23.3685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([2.0267e-06, 5.9623e-04, 1.1133e+03, 6.6156e-04, 8.6171e-06, 2.0203e-07,\n",
      "        2.2981e-06, 1.2728e-03, 8.3276e-07, 1.8176e-06, 2.9734e-04, 8.2787e-06,\n",
      "        1.0964e-05, 3.2785e-02, 1.1724e-01, 7.2747e-08, 2.7995e-04, 3.1266e-05,\n",
      "        1.0523e-05, 1.7329e-06, 1.0180e-06, 2.8337e-05, 2.2981e-06, 1.1433e-04,\n",
      "        1.9515e-03, 9.3875e-03, 4.8392e-06, 1.5602e-03, 1.3350e-02, 2.6910e-04,\n",
      "        1.2553e-02, 9.5763e-03, 7.7145e-05, 1.0425e-04, 1.3774e-07, 1.2188e-03,\n",
      "        1.1701e-04, 6.9122e-06, 2.3501e-01, 9.1039e-04, 1.4826e-01, 1.0929e-06,\n",
      "        5.1443e-04, 9.3934e-06, 1.8019e-05, 1.0884e-05, 1.3042e-05, 4.0739e-03,\n",
      "        5.1024e-02, 5.1147e-04, 7.5584e-10, 1.0838e-05, 5.4809e-05, 3.4272e-06,\n",
      "        7.3047e-04, 1.5930e-05, 4.7726e-04, 5.9819e-05, 6.8245e-04, 5.5681e-03,\n",
      "        3.7385e-05, 7.5409e-05, 3.8283e-04, 6.6469e-03], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([3.8457e+01, 2.6742e-01, 1.9384e+02, 1.7070e-01, 2.2601e+01, 7.2371e+01,\n",
      "        3.6914e+01, 5.8186e-02, 5.0279e+01, 3.9819e+01, 1.4711e+00, 2.2983e+01,\n",
      "        2.0368e+01, 1.2180e+01, 2.2698e+01, 9.0793e+01, 1.6209e+00, 1.2008e+01,\n",
      "        2.0741e+01, 4.0423e+01, 4.7471e+01, 1.2699e+01, 3.6914e+01, 4.7030e+00,\n",
      "        4.4705e-01, 5.0148e+00, 2.8420e+01, 1.9787e-01, 6.7158e+00, 1.7231e+00,\n",
      "        6.4006e+00, 5.1044e+00, 6.5642e+00, 5.1118e+00, 7.9035e+01, 3.9167e-02,\n",
      "        4.6031e+00, 2.4745e+01, 2.9807e+01, 8.8138e-03, 2.4990e+01, 4.6497e+01,\n",
      "        4.4182e-01, 2.1788e+01, 1.6131e+01, 2.0435e+01, 1.8832e+01, 1.9729e+00,\n",
      "        1.5463e+01, 4.4953e-01, 1.9868e+02, 2.0473e+01, 8.4326e+00, 3.2217e+01,\n",
      "        9.8638e-02, 1.7136e+01, 5.4715e-01, 7.9323e+00, 1.4597e-01, 2.9483e+00,\n",
      "        1.0801e+01, 6.6814e+00, 9.2191e-01, 3.5878e+00], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(23.1781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([8.0741e-07, 5.7450e-06, 3.7711e-02, 6.9084e-05, 3.1297e-02, 4.1103e-05,\n",
      "        1.2528e+00, 2.4700e-03, 4.9347e-07, 5.0481e-06, 3.2484e+00, 2.7806e-05,\n",
      "        3.4725e-06, 6.0493e-05, 2.1549e-03, 1.4177e-02, 5.9833e-07, 2.3269e-06,\n",
      "        1.1155e+03, 1.1348e+03, 9.3921e-03, 4.4214e-03, 9.2414e-04, 3.3825e-06,\n",
      "        1.7664e-07, 3.2740e-06, 2.1650e-02, 1.0126e-05, 2.5832e-07, 1.9865e-05,\n",
      "        1.8745e-01, 6.9168e-05, 5.1346e-02, 7.1683e-04, 3.1272e-03, 6.6776e-08,\n",
      "        4.7211e-05, 1.4582e-05, 2.4485e-03, 3.1177e-04, 9.1338e-03, 1.2220e-02,\n",
      "        5.6438e-06, 4.9560e-06, 3.5850e-06, 3.9553e-05, 1.7066e-02, 1.6209e-04,\n",
      "        5.9842e-05, 2.5296e-01, 8.5541e-07, 3.6047e-07, 2.5538e-06, 5.8607e-03,\n",
      "        6.6618e-07, 8.9628e-03, 2.4042e-05, 1.1155e-02, 2.1087e-07, 1.1780e-08,\n",
      "        1.0248e-02, 7.4362e-01, 2.4869e-07, 2.0574e-04], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([5.0718e+01, 2.6620e+01, 1.3177e+01, 7.1419e+00, 1.1858e+01, 1.0187e+01,\n",
      "        5.0881e+01, 8.1764e-01, 5.7974e+01, 2.7971e+01, 6.5382e+01, 1.2834e+01,\n",
      "        3.2068e+01, 7.8693e+00, 5.8943e-01, 7.0310e+00, 5.5077e+01, 3.6763e+01,\n",
      "        1.9390e+02, 1.9438e+02, 5.0170e+00, 2.2095e+00, 6.2241e-03, 3.2366e+01,\n",
      "        7.4674e+01, 3.2738e+01, 9.4558e+00, 2.1092e+01, 6.8249e+01, 1.5357e+01,\n",
      "        2.7390e+01, 7.1354e+00, 1.5512e+01, 1.1084e-01, 1.2999e+00, 9.2432e+01,\n",
      "        9.3216e+00, 1.7876e+01, 8.0185e-01, 1.3584e+00, 4.8929e+00, 6.2654e+00,\n",
      "        2.6803e+01, 2.8166e+01, 3.1708e+01, 1.0434e+01, 8.0490e+00, 3.3110e+00,\n",
      "        7.9301e+00, 3.0617e+01, 4.9899e+01, 6.2855e+01, 3.5643e+01, 3.1268e+00,\n",
      "        5.3494e+01, 4.8096e+00, 1.3898e+01, 5.8174e+00, 7.1644e+01, 1.2880e+02,\n",
      "        5.4153e+00, 4.3712e+01, 6.8878e+01, 2.5001e+00], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(31.3486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([9.1869e-07, 1.7933e+00, 4.1217e-02, 2.1313e-03, 2.5994e-01, 3.4196e-06,\n",
      "        8.1007e-09, 2.5873e-04, 5.4741e-02, 2.3308e+00, 4.7772e-06, 5.1424e-06,\n",
      "        3.9173e-01, 6.5093e-03, 1.0299e-04, 6.2616e-06, 2.1073e-01, 5.8948e-04,\n",
      "        5.8575e-04, 3.9184e-04, 3.5773e-06, 1.0397e-05, 1.0300e-06, 3.7919e-03,\n",
      "        3.3743e-03, 7.6265e-01, 2.3768e-05, 2.1248e-05, 1.2476e-02, 2.3600e-02,\n",
      "        1.7447e-06, 3.8454e-04, 1.4546e-02, 1.0435e-04, 1.3817e-05, 3.8601e-06,\n",
      "        4.1043e-04, 2.1300e-02, 3.6712e-07, 2.9343e-06, 8.7023e-02, 1.0557e-04,\n",
      "        1.8023e-05, 3.0053e-06, 2.2105e-01, 2.7284e-07, 2.7390e-05, 2.2695e-06,\n",
      "        7.9569e-06, 8.9514e-05, 8.3592e-03, 6.0688e-05, 2.3528e-02, 1.5832e-05,\n",
      "        3.2394e-02, 1.4983e-03, 1.6512e-06, 1.0077e-02, 1.3099e-03, 6.5789e-06,\n",
      "        1.1151e+03, 2.1695e-05, 1.9394e-06, 4.1206e-06], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([4.8896e+01, 5.6128e+01, 1.3830e+01, 5.7267e-01, 3.0919e+01, 3.2242e+01,\n",
      "        1.3744e+02, 1.8278e+00, 1.6021e+01, 6.0124e+01, 2.8557e+01, 2.7775e+01,\n",
      "        3.5648e+01, 3.5090e+00, 5.1669e+00, 2.5739e+01, 2.8629e+01, 2.7932e-01,\n",
      "        2.8608e-01, 8.7780e-01, 3.1732e+01, 2.0851e+01, 4.7310e+01, 1.7765e+00,\n",
      "        1.4791e+00, 4.4047e+01, 1.3983e+01, 1.4834e+01, 6.3696e+00, 9.9934e+00,\n",
      "        4.0338e+01, 9.1339e-01, 7.1680e+00, 5.1074e+00, 1.8334e+01, 3.0881e+01,\n",
      "        7.9308e-01, 9.3558e+00, 6.2565e+01, 3.4004e+01, 1.9947e+01, 5.0554e+00,\n",
      "        1.6129e+01, 3.3725e+01, 2.9142e+01, 6.7348e+01, 1.2943e+01, 3.7066e+01,\n",
      "        2.3365e+01, 5.8243e+00, 4.5087e+00, 7.8513e+00, 9.9743e+00, 1.7187e+01,\n",
      "        1.2096e+01, 1.6346e-01, 4.1040e+01, 5.3373e+00, 7.2873e-02, 2.5239e+01,\n",
      "        1.9389e+02, 1.4674e+01, 3.9005e+01, 3.0159e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(25.1257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([8.0170e-03, 7.3441e-06, 6.6775e-04, 1.1904e-03, 4.1666e-05, 2.1030e-02,\n",
      "        9.0167e-07, 2.5263e-03, 2.1696e-05, 3.4670e-02, 2.5631e-03, 6.5478e-04,\n",
      "        6.3219e-03, 5.4252e-03, 8.4855e-04, 1.5182e-03, 1.2951e-03, 1.2770e-03,\n",
      "        1.4593e-05, 1.3396e-04, 3.6814e-07, 2.3955e-05, 4.5818e-05, 6.3760e-07,\n",
      "        4.1811e-01, 5.6889e-04, 1.1855e-01, 1.2543e-03, 9.8901e-04, 5.5758e-07,\n",
      "        7.7003e-05, 1.3519e-03, 5.5065e-05, 3.6196e-02, 4.5747e-04, 6.3819e-03,\n",
      "        9.7549e-07, 4.2160e-05, 5.2597e-06, 4.7700e-02, 3.5357e-08, 6.0054e-07,\n",
      "        6.0506e-05, 1.7555e-04, 9.8159e-07, 2.0900e-06, 9.6037e-03, 2.5394e-04,\n",
      "        6.8017e-06, 1.2689e-02, 2.0244e-05, 3.0401e-03, 1.9395e-06, 3.2068e-05,\n",
      "        6.5260e-05, 1.0879e-02, 1.3407e-04, 5.1512e-08, 5.8381e-08, 2.3603e-02,\n",
      "        7.4732e-07, 2.2897e-02, 2.8719e-07, 1.5171e-07], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([4.3329e+00, 2.4146e+01, 1.6309e-01, 3.0370e-02, 1.0100e+01, 9.2778e+00,\n",
      "        4.9158e+01, 8.5886e-01, 1.4674e+01, 1.2573e+01, 8.8590e-01, 1.7931e-01,\n",
      "        3.4004e+00, 2.8597e+00, 2.6971e-02, 1.7434e-01, 6.6851e-02, 5.9789e-02,\n",
      "        1.7869e+01, 4.0408e+00, 6.2521e+01, 1.3925e+01, 9.5054e+00, 5.4137e+01,\n",
      "        3.6430e+01, 3.1817e-01, 2.2804e+01, 5.1332e-02, 1.2210e-04, 5.6129e+01,\n",
      "        6.5736e+00, 9.0916e-02, 8.4056e+00, 1.2881e+01, 6.1158e-01, 3.4353e+00,\n",
      "        4.8061e+01, 1.0025e+01, 2.7538e+01, 1.4938e+01, 1.0506e+02, 5.5022e+01,\n",
      "        7.8681e+00, 3.0271e+00, 4.7974e+01, 3.8076e+01, 5.1173e+00, 1.8787e+00,\n",
      "        2.4906e+01, 6.4553e+00, 1.5209e+01, 1.2363e+00, 3.9004e+01, 1.1833e+01,\n",
      "        7.4495e+00, 5.6970e+00, 4.0376e+00, 9.7490e+01, 9.5033e+01, 9.9944e+00,\n",
      "        5.1826e+01, 9.8031e+00, 6.6510e+01, 7.7327e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(20.7984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([6.0621e-03, 4.7868e-03, 2.9924e-06, 1.2299e-03, 6.5519e-04, 7.6600e-08,\n",
      "        8.7343e-03, 1.4470e-01, 1.8993e-06, 1.6522e-05, 8.0141e-03, 8.9241e-05,\n",
      "        1.0911e-04, 7.3104e-02, 3.7611e-04, 5.9675e-04, 1.0469e-07, 6.1065e-03,\n",
      "        8.5216e-07, 4.3968e-06, 2.1889e-10, 5.4701e-03, 1.5286e-06, 2.3424e-01,\n",
      "        7.8930e-05, 2.5965e-06, 1.6553e-02, 6.0839e-04, 6.8597e-07, 2.4209e-03,\n",
      "        4.1353e-01, 8.7343e-03, 7.1778e-07, 3.9582e-01, 4.9920e-04, 2.4874e-06,\n",
      "        3.0247e-02, 1.5468e-05, 1.1166e+03, 5.5217e-03, 6.8061e-03, 1.6590e-08,\n",
      "        8.2798e-05, 2.9924e-06, 2.8674e-02], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([3.2474e+00, 2.4519e+00, 3.3776e+01, 4.2820e-02, 1.7879e-01, 8.9812e+01,\n",
      "        4.6970e+00, 2.4747e+01, 3.9266e+01, 1.6835e+01, 4.3314e+00, 5.8390e+00,\n",
      "        4.9081e+00, 1.8420e+01, 9.5622e-01, 2.6652e-01, 8.3989e+01, 3.2738e+00,\n",
      "        4.9953e+01, 2.9451e+01, 2.3515e+02, 2.8876e+00, 4.2034e+01, 2.9772e+01,\n",
      "        6.4475e+00, 3.5445e+01, 7.8767e+00, 2.4695e-01, 5.3066e+01, 7.8169e-01,\n",
      "        3.6297e+01, 4.6970e+00, 5.2408e+01, 3.5772e+01, 4.8268e-01, 3.5958e+01,\n",
      "        1.1624e+01, 1.7381e+01, 1.9393e+02, 2.9196e+00, 3.6780e+00, 1.2115e+02,\n",
      "        6.2068e+00, 3.3776e+01, 1.1263e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(31.0598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([2.4960e-06, 6.1912e-02, 5.1250e-07, 7.1276e-02, 2.0613e-04, 1.1665e-07,\n",
      "        2.1947e-05, 2.5879e-06, 2.8495e-02, 7.0870e-06, 8.7462e-01, 8.6026e-03,\n",
      "        1.0495e-05, 1.5530e-03, 6.4055e-08, 4.9419e-04, 1.7381e-03, 1.5768e-06,\n",
      "        1.0534e-05, 2.5794e-04, 3.2088e-06, 6.8719e+00, 1.2821e-03, 1.9104e-05,\n",
      "        2.5321e-05, 3.8617e-06, 4.0151e-07, 3.9087e-04, 6.1958e-04, 6.2922e-06,\n",
      "        4.2716e-07, 1.1214e+03, 2.1896e-07, 4.2704e-03, 9.3215e-07, 1.2218e-03,\n",
      "        2.2822e-05, 3.2393e-06, 3.1967e-09, 1.7604e-04, 1.1712e-04, 1.9451e-06,\n",
      "        1.2988e-05, 6.6214e-03, 1.2120e-02, 1.8878e-02, 1.6287e-06, 2.1449e-05,\n",
      "        6.5687e-06, 4.8139e-05, 1.8667e-06, 2.7990e-02, 4.6065e-06, 5.2742e-06,\n",
      "        1.2640e-02, 2.0319e-03, 1.4915e-02, 4.5289e-01, 3.4420e-08, 3.6642e-06,\n",
      "        3.1374e-05, 1.4915e-02, 4.5902e-06, 2.4722e-06], device='cuda:0')\n",
      "tensor([3.5917e+01, 1.7021e+01, 5.7399e+01, 1.8203e+01, 2.4941e+00, 8.2017e+01,\n",
      "        1.4586e+01, 3.5485e+01, 1.1221e+01, 2.4497e+01, 4.5884e+01, 4.6314e+00,\n",
      "        2.0765e+01, 1.9375e-01, 9.3234e+01, 4.9680e-01, 3.0557e-01, 4.1633e+01,\n",
      "        2.0731e+01, 1.8361e+00, 3.2969e+01, 7.8061e+01, 6.1738e-02, 1.5664e+01,\n",
      "        1.3514e+01, 3.0876e+01, 6.1157e+01, 8.8243e-01, 2.2917e-01, 2.5689e+01,\n",
      "        6.0192e+01, 1.9405e+02, 7.1008e+01, 2.1074e+00, 4.8693e+01, 4.0145e-02,\n",
      "        1.4289e+01, 3.2860e+01, 1.6011e+02, 3.0174e+00, 4.5992e+00, 3.8968e+01,\n",
      "        1.8868e+01, 3.5733e+00, 6.2243e+00, 8.6320e+00, 4.1216e+01, 1.4761e+01,\n",
      "        2.5255e+01, 9.2031e+00, 3.9484e+01, 1.1101e+01, 2.8947e+01, 2.7509e+01,\n",
      "        6.4358e+00, 5.0265e-01, 7.3029e+00, 3.7401e+01, 1.0561e+02, 3.1463e+01,\n",
      "        1.1984e+01, 7.3029e+00, 2.8986e+01, 3.6032e+01], device='cuda:0')\n",
      "tensor(30.0841, device='cuda:0')\n",
      "energy_error= tensor([1.8225e-03, 5.4891e-07, 7.6053e-05, 1.1466e-04, 4.0946e-05, 5.0199e-05,\n",
      "        5.6449e-04, 1.9887e+00, 6.2280e-06, 9.6520e-04, 3.9407e-07, 4.8268e-07,\n",
      "        1.8867e-05, 7.1697e-06, 3.1574e-02, 3.9581e-05, 8.0102e-08, 2.9105e-06,\n",
      "        1.3183e-06, 1.3622e-02, 2.1113e-07, 9.9195e-04, 5.1157e-04, 5.1722e-03,\n",
      "        1.0870e-05, 2.0760e-02, 1.6369e-05, 5.8103e-05, 7.3314e-03, 9.5350e-04,\n",
      "        6.6663e-07, 7.6099e-07, 4.1052e-04, 1.0685e+00, 1.0556e-02, 4.9977e-04,\n",
      "        9.7061e-07, 2.8736e-04, 5.5808e-07, 5.2741e-05, 6.4295e-04, 1.1967e-03,\n",
      "        7.2915e-04, 6.9846e-04, 1.3409e-04, 5.0390e-01, 8.3991e-06, 1.4866e+00,\n",
      "        5.2432e-05, 1.6109e-04, 3.7334e-02, 6.5860e-03, 7.6751e-02, 1.1999e-03,\n",
      "        2.2454e-06, 7.8303e-03, 7.2568e-05, 1.0248e-02, 3.5399e-06, 3.1360e-05,\n",
      "        1.3632e-02, 5.6547e-03, 6.6208e-03, 1.9111e-04], device='cuda:0')\n",
      "tensor([3.6023e-01, 5.6364e+01, 6.6375e+00, 4.6907e+00, 1.0211e+01, 8.9506e+00,\n",
      "        3.2699e-01, 5.7687e+01, 2.5793e+01, 1.2547e-03, 6.1450e+01, 5.8311e+01,\n",
      "        1.5763e+01, 2.4383e+01, 1.1919e+01, 1.0429e+01, 8.8967e+01, 3.4099e+01,\n",
      "        4.3976e+01, 6.8209e+00, 7.1623e+01, 6.5315e-05, 4.4927e-01, 2.7005e+00,\n",
      "        2.0447e+01, 9.1991e+00, 1.6912e+01, 8.0971e+00, 3.9688e+00, 2.2674e-03,\n",
      "        5.3484e+01, 5.1565e+01, 7.9270e-01, 4.8636e+01, 5.5538e+00, 4.8108e-01,\n",
      "        4.8130e+01, 1.5551e+00, 5.6115e+01, 8.6575e+00, 1.9509e-01, 3.2247e-02,\n",
      "        9.9777e-02, 1.2879e-01, 4.0370e+00, 3.8718e+01, 2.2845e+01, 5.3352e+01,\n",
      "        8.6922e+00, 3.3335e+00, 1.3104e+01, 3.5530e+00, 1.8840e+01, 3.3207e-02,\n",
      "        3.7196e+01, 4.2353e+00, 6.8813e+00, 5.4155e+00, 3.1851e+01, 1.1987e+01,\n",
      "        6.8249e+00, 3.0015e+00, 3.5729e+00, 2.7387e+00], device='cuda:0')\n",
      "tensor(19.0028, device='cuda:0')\n",
      "energy_error= tensor([4.6754e-03, 3.9653e-03, 1.1747e-03, 3.8136e+00, 4.0741e-05, 3.1836e-03,\n",
      "        3.9970e-04, 4.7370e-04, 3.7888e-03, 1.5340e-05, 7.7003e-03, 4.2214e-03,\n",
      "        1.2661e-02, 6.5181e-02, 5.0538e-06, 1.9780e-01, 2.5986e-07, 1.3265e-09,\n",
      "        1.0657e-06, 3.7813e-06, 4.6399e-05, 9.1363e-07, 1.3708e-02, 2.0415e-03,\n",
      "        4.8056e-01, 7.6419e-03, 3.9202e-06, 1.4428e-01, 8.9851e-03, 7.7255e-05,\n",
      "        5.1083e-07, 2.5134e-04, 3.7186e-03, 8.9193e-03, 6.6546e-07, 2.2085e-06,\n",
      "        3.2119e-05, 4.8222e-06, 6.2280e-06, 3.5693e-09, 1.8074e-03, 1.8883e-04,\n",
      "        6.4729e-05, 6.4055e-08, 9.2142e-05, 2.6078e-05, 1.5568e-06, 5.7582e-02,\n",
      "        3.2532e-07, 2.7154e-04, 9.6422e-05, 7.9288e-05, 1.8487e-05, 9.7392e-07,\n",
      "        5.1102e-03, 4.8282e-06, 1.4792e-06, 1.2607e-03, 1.0493e-03, 7.9601e-06,\n",
      "        4.6982e-06, 5.5528e-03, 4.0828e-03, 2.7874e-03], device='cuda:0')\n",
      "tensor([2.3787e+00, 1.8977e+00, 2.5937e-02, 6.8002e+01, 1.0243e+01, 1.3410e+00,\n",
      "        8.4096e-01, 5.5829e-01, 1.7744e+00, 1.7450e+01, 4.1667e+00, 2.0741e+00,\n",
      "        6.4441e+00, 1.7449e+01, 2.7959e+01, 2.7955e+01, 6.8151e+01, 1.8314e+02,\n",
      "        4.6842e+01, 3.1111e+01, 9.4278e+00, 4.8973e+01, 6.8540e+00, 5.0933e-01,\n",
      "        3.8130e+01, 4.1357e+00, 3.0710e+01, 2.4718e+01, 4.8205e+00, 6.5569e+00,\n",
      "        5.7448e+01, 1.9070e+00, 1.7249e+00, 4.7883e+00, 5.3510e+01, 3.7399e+01,\n",
      "        1.1822e+01, 2.8457e+01, 2.5793e+01, 1.5733e+02, 3.5030e-01, 2.7786e+00,\n",
      "        7.4942e+00, 9.3234e+01, 5.6855e+00, 1.3298e+01, 4.1798e+01, 1.6429e+01,\n",
      "        6.4492e+01, 1.6995e+00, 5.4710e+00, 6.4246e+00, 1.5925e+01, 4.8083e+01,\n",
      "        2.6609e+00, 2.8444e+01, 4.2461e+01, 5.3654e-02, 2.3194e-03, 2.3361e+01,\n",
      "        2.8736e+01, 2.9388e+00, 1.9790e+00, 1.0508e+00], device='cuda:0')\n",
      "tensor(23.9011, device='cuda:0')\n",
      "energy_error= tensor([3.6862e-07, 2.0626e+00, 4.8014e-03, 2.1146e-03, 1.0479e-03, 1.0214e-03,\n",
      "        3.2626e-03, 4.6404e-05, 1.4792e-04, 2.4942e-06, 1.1257e-03, 1.8174e-07,\n",
      "        1.1788e-08, 1.7676e-07, 2.1555e-02, 2.4281e-04, 4.2359e-03, 5.0184e-05,\n",
      "        1.7255e-04, 5.8081e-07, 1.0888e-05, 8.9103e-03, 7.1946e-03, 3.0218e-05,\n",
      "        8.7596e-05, 3.4011e-04, 6.0808e-05, 8.9031e-05, 5.4791e-07, 2.6927e-06,\n",
      "        9.0663e-03, 9.9314e-07, 4.7568e-04, 9.7373e-06, 7.1993e-05, 1.1780e-05,\n",
      "        8.4718e-06, 2.3914e-05, 1.1127e-05, 2.4047e-02, 2.8733e-07, 6.1251e-06,\n",
      "        6.2676e-01, 6.7949e-09, 4.8004e-01, 2.0860e-02, 7.3278e-04, 3.5915e-05,\n",
      "        5.8389e-07, 8.4003e-03, 1.3337e-02, 3.5399e-06, 7.9001e-03, 7.4277e-03,\n",
      "        4.1128e-05, 1.1251e+03, 7.4084e-05, 1.1295e-06, 1.2053e+01, 7.8999e-05,\n",
      "        1.6070e-07, 2.7623e-02, 4.7568e-04, 1.6572e-02], device='cuda:0')\n",
      "tensor([6.2501e+01, 5.8244e+01, 2.4615e+00, 5.6082e-01, 2.1859e-03, 4.5003e-04,\n",
      "        1.3984e+00, 9.4272e+00, 3.6523e+00, 3.5925e+01, 1.4021e-02, 7.4183e+01,\n",
      "        1.2879e+02, 7.4662e+01, 9.4288e+00, 2.0035e+00, 2.0840e+00, 8.9524e+00,\n",
      "        3.0874e+00, 5.5519e+01, 2.0431e+01, 4.7839e+00, 3.8941e+00, 1.2245e+01,\n",
      "        5.9293e+00, 1.1631e+00, 7.8402e+00, 5.8504e+00, 5.6391e+01, 3.5013e+01,\n",
      "        4.8601e+00, 4.7812e+01, 5.5208e-01, 2.1454e+01, 6.9232e+00, 1.9726e+01,\n",
      "        2.2763e+01, 1.3937e+01, 2.0236e+01, 1.0113e+01, 6.6502e+01, 2.5963e+01,\n",
      "        4.1481e+01, 1.4159e+02, 3.8117e+01, 9.2284e+00, 9.6662e-02, 1.1066e+01,\n",
      "        5.5440e+01, 4.5295e+00, 6.7108e+00, 3.1851e+01, 4.2720e+00, 4.0209e+00,\n",
      "        1.0183e+01, 1.9414e+02, 6.7733e+00, 4.6050e+01, 8.8304e+01, 6.4431e+00,\n",
      "        7.6317e+01, 1.1014e+01, 5.5208e-01, 7.8833e+00], device='cuda:0')\n",
      "tensor(27.2397, device='cuda:0')\n",
      "energy_error= tensor([8.4868e-07, 4.8014e-03, 3.5333e+00, 3.7569e-03, 1.1092e-07, 6.8679e-02,\n",
      "        1.7958e-09, 8.9805e-03, 2.4165e-03, 5.9017e-03, 1.3383e-02, 6.6038e-08,\n",
      "        8.1166e-05, 1.1284e-03, 1.0888e-05, 5.0136e-04, 1.0298e-04, 4.4988e-04,\n",
      "        1.2491e-01, 9.4033e-06, 1.3637e-03, 4.2359e-01, 1.1441e-04, 1.7128e-07,\n",
      "        1.5687e-05, 4.6218e-02, 4.9973e-04, 1.0980e-06, 6.3295e-05, 5.7180e-06,\n",
      "        9.9637e-06, 5.9439e-06, 3.0569e-06, 9.1087e-08, 9.4283e+00, 1.0119e-01,\n",
      "        3.4374e-06, 1.3348e-05, 6.5240e-03, 9.0502e-07, 3.6191e-08, 2.0636e-06,\n",
      "        8.6377e-03, 2.0318e-01, 1.7078e-06, 2.4698e-05, 8.9533e-07, 1.5791e-01,\n",
      "        6.2181e+00, 3.4410e-03, 2.1439e-07, 4.9863e-03, 1.6981e-07, 6.6039e-09,\n",
      "        2.3277e-03, 4.3864e-05, 8.1262e-06, 2.7097e-03, 1.4188e-05, 1.6697e-06,\n",
      "        1.6352e+00, 4.0076e-03, 4.7156e-03, 2.0539e-03], device='cuda:0')\n",
      "tensor([5.0011e+01, 2.4615e+00, 6.6749e+01, 1.7519e+00, 8.2933e+01, 1.7888e+01,\n",
      "        1.7503e+02, 4.8183e+00, 7.7845e-01, 3.1515e+00, 6.7286e+00, 9.2646e+01,\n",
      "        6.3064e+00, 1.4601e-02, 2.0431e+01, 4.7668e-01, 5.1675e+00, 6.3804e-01,\n",
      "        2.3306e+01, 2.1778e+01, 9.6243e-02, 3.6587e+01, 4.7002e+00, 7.5207e+01,\n",
      "        1.7264e+01, 1.4695e+01, 4.8121e-01, 4.6435e+01, 7.6173e+00, 2.6668e+01,\n",
      "        2.1241e+01, 2.6270e+01, 3.3528e+01, 8.6559e+01, 8.3749e+01, 2.1317e+01,\n",
      "        3.2183e+01, 1.8631e+01, 3.5175e+00, 4.9106e+01, 1.0459e+02, 3.8233e+01,\n",
      "        4.6489e+00, 2.8240e+01, 4.0609e+01, 1.3698e+01, 4.9257e+01, 2.5624e+01,\n",
      "        7.6304e+01, 1.5271e+00, 7.1364e+01, 2.5815e+00, 7.5356e+01, 1.4227e+02,\n",
      "        7.1382e-01, 9.7760e+00, 2.3162e+01, 9.9369e-01, 1.8108e+01, 4.0898e+01,\n",
      "        5.4753e+01, 1.9271e+00, 2.4052e+00, 5.1806e-01], device='cuda:0')\n",
      "tensor(31.5075, device='cuda:0')\n",
      "energy_error= tensor([1.9187e-01, 3.0903e-08, 1.6557e-05, 6.5840e-05, 4.7820e-04, 1.5784e-07,\n",
      "        1.1094e-07, 2.9207e-07, 1.6614e-02, 4.9141e-06, 7.3586e-04, 1.0727e-06,\n",
      "        6.8275e-06, 8.7220e-02, 9.8196e+00, 1.1425e-02, 6.8759e-06, 7.3030e-06,\n",
      "        9.5678e-03, 8.4020e-06, 2.5986e-07, 1.6981e-07, 5.6353e-05, 7.4861e-07,\n",
      "        3.6115e-04, 5.0105e-05, 5.9369e-04, 1.5231e+01, 6.8064e-06, 1.2084e-02,\n",
      "        1.2774e-03, 2.4148e-06, 8.6800e-08, 4.3954e-06, 4.7914e-08, 3.7927e-08,\n",
      "        2.3313e-02, 9.5678e-03, 1.8456e+00, 9.8994e-03, 7.4379e-04, 1.3385e-06,\n",
      "        8.7708e-03, 4.4741e-04, 4.7516e-03, 5.3823e-06, 6.5833e-04, 5.3733e-05,\n",
      "        3.2769e-06, 5.4651e-03, 2.7400e-02, 2.3980e-06, 1.2988e-05, 1.0658e-03,\n",
      "        6.0707e-03, 2.1298e-05, 7.2184e-03, 9.1087e-08, 7.4526e-02, 1.7015e-02,\n",
      "        1.1622e-07, 3.7334e-02, 9.9717e-04, 2.1363e-06], device='cuda:0')\n",
      "tensor([2.7634e+01, 1.0784e+02, 1.6818e+01, 7.4013e+00, 5.4425e-01, 7.6631e+01,\n",
      "        8.2929e+01, 6.6235e+01, 7.8976e+00, 2.8256e+01, 9.4072e-02, 4.6753e+01,\n",
      "        2.4868e+01, 1.9967e+01, 8.4495e+01, 5.9333e+00, 2.4798e+01, 2.4201e+01,\n",
      "        5.1004e+00, 2.2842e+01, 6.8151e+01, 7.5356e+01, 8.2721e+00, 5.1801e+01,\n",
      "        1.0373e+00, 8.9618e+00, 2.7185e-01, 9.2758e+01, 2.4899e+01, 6.2095e+00,\n",
      "        5.9935e-02, 3.6314e+01, 8.7458e+01, 2.9454e+01, 9.8925e+01, 1.0363e+02,\n",
      "        9.9163e+00, 5.1004e+00, 5.6558e+01, 5.2554e+00, 8.7614e-02, 4.3775e+01,\n",
      "        4.7151e+00, 6.4685e-01, 2.4288e+00, 2.7297e+01, 1.7477e-01, 8.5481e+00,\n",
      "        3.2728e+01, 2.8845e+00, 1.0960e+01, 3.6399e+01, 1.8868e+01, 4.0603e-03,\n",
      "        3.2525e+00, 1.4816e+01, 3.9071e+00, 8.6559e+01, 1.8586e+01, 8.0322e+00,\n",
      "        8.2085e+01, 1.3104e+01, 8.0404e-06, 3.7806e+01], device='cuda:0')\n",
      "tensor(29.8327, device='cuda:0')\n",
      "energy_error= tensor([1.8960e-02, 5.8733e-02, 3.7686e-03, 9.1954e-05, 8.9723e-05, 5.7329e-03,\n",
      "        1.1254e-03, 7.1758e-06, 3.4139e-02, 2.7570e-06, 1.0848e-06, 2.1418e-04,\n",
      "        2.1390e-07, 1.8444e-04, 2.6735e-03, 8.5245e-07, 5.7534e-06, 1.0583e-03,\n",
      "        4.1335e-04, 6.0796e-04, 1.2640e-02, 6.2773e-04, 1.5768e-06, 1.5687e-05,\n",
      "        6.3531e-03, 8.5319e-03, 6.8172e-05, 1.3279e-06, 7.3589e-09, 3.2023e-06,\n",
      "        7.4944e-03, 1.1475e-06, 4.9118e-03, 1.4209e-05, 4.9973e-04, 1.4358e-06,\n",
      "        3.3972e-01, 1.0658e-03, 3.2352e-03, 6.1326e-02, 1.1838e-02, 3.9249e-05,\n",
      "        8.4842e-03], device='cuda:0')\n",
      "tensor([8.6573e+00, 1.6589e+01, 1.7601e+00, 5.6952e+00, 5.8130e+00, 3.0493e+00,\n",
      "        1.3948e-02, 2.4374e+01, 1.2464e+01, 3.4735e+01, 4.6599e+01, 2.3745e+00,\n",
      "        7.1402e+01, 2.8575e+00, 9.6703e-01, 4.9948e+01, 2.6605e+01, 3.2121e-03,\n",
      "        7.8048e-01, 2.4766e-01, 6.4358e+00, 2.1683e-01, 4.1633e+01, 1.7264e+01,\n",
      "        3.4186e+00, 4.5959e+00, 7.2131e+00, 4.3879e+01, 1.3970e+02, 3.2992e+01,\n",
      "        4.0568e+00, 4.5835e+01, 2.5333e+00, 1.8096e+01, 4.8121e-01, 4.2851e+01,\n",
      "        3.3967e+01, 4.0603e-03, 1.3785e+00, 1.6943e+01, 6.1074e+00, 1.0484e+01,\n",
      "        4.5719e+00], device='cuda:0')\n",
      "tensor(18.5952, device='cuda:0')\n",
      "Epoch [1/1000], Timestep error: 1.0525e+02/1.4285e+02, Energy Loss: nan/nan, nan/nan, Time step: 4.7294e-05/9.4821e-04, 4.3795e-05/8.6166e-04, 5.2398e-05/1.7175e-03\n",
      "energy_error= tensor([2.4230e-03, 3.4298e-06, 1.3265e-09, 1.5428e+00, 7.9594e-07, 2.8578e-06,\n",
      "        2.8848e-06, 2.1146e-03, 3.5537e-06, 1.7074e-02, 2.7410e-05, 2.0504e-06,\n",
      "        2.3000e-06, 9.1293e-04, 6.8413e-03, 1.1759e-02, 7.0412e-02, 3.9243e-04,\n",
      "        5.7475e-05, 2.7433e-05, 2.2639e-05, 1.4941e-03, 1.8471e-01, 4.9621e-02,\n",
      "        1.7102e-07, 6.8907e-05, 8.3760e-03, 5.4216e-02, 5.9935e-05, 2.4872e-06,\n",
      "        2.7376e-06, 1.0248e-02, 1.5840e-05, 1.8118e-02, 1.2774e-03, 1.1261e-06,\n",
      "        9.9717e-04, 6.1702e-05, 1.2316e-03, 3.0961e-07, 2.3480e-01, 2.9549e-05,\n",
      "        1.5611e-06, 4.0585e-01, 9.4168e-05, 7.9594e-07, 2.6811e-07, 6.2707e-04,\n",
      "        1.8487e-05, 1.5240e-04, 4.0909e-01, 1.7869e-03, 2.9549e-05, 1.1068e-02,\n",
      "        7.7267e-03, 9.9272e-04, 1.0580e-04, 4.7339e-05, 1.4293e-02, 1.8270e-07,\n",
      "        3.7739e-03, 2.3284e-06, 4.8764e-04, 7.7430e-03], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([7.8324e-01, 3.2208e+01, 1.8314e+02, 5.3895e+01, 5.0922e+01, 3.4313e+01,\n",
      "        3.4202e+01, 5.6082e-01, 3.1807e+01, 8.0517e+00, 1.2937e+01, 3.8313e+01,\n",
      "        3.6904e+01, 8.2975e-03, 3.6979e+00, 6.0743e+00, 1.8100e+01, 8.7495e-01,\n",
      "        8.1590e+00, 1.2931e+01, 1.4350e+01, 1.6123e-01, 2.7236e+01, 1.5244e+01,\n",
      "        7.5234e+01, 7.1556e+00, 4.5172e+00, 1.5944e+01, 7.9214e+00, 3.5959e+01,\n",
      "        3.4818e+01, 5.4155e+00, 1.7183e+01, 8.3920e+00, 5.9935e-02, 4.6090e+01,\n",
      "        8.0404e-06, 7.7587e+00, 4.3404e-02, 6.5289e+01, 2.9798e+01, 1.2402e+01,\n",
      "        4.1762e+01, 3.6072e+01, 5.5822e+00, 5.0922e+01, 6.7636e+01, 2.1781e-01,\n",
      "        1.5925e+01, 3.5391e+00, 3.6167e+01, 3.3695e-01, 1.2402e+01, 5.7796e+00,\n",
      "        4.1807e+00, 5.3429e-05, 5.0455e+00, 9.3051e+00, 7.0745e+00, 7.4091e+01,\n",
      "        1.7639e+00, 3.6755e+01, 5.1577e-01, 4.1894e+00], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(22.1581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([1.4757e-02, 3.0608e-06, 2.2566e-07, 3.7100e-02, 1.5573e-06, 3.7268e-02,\n",
      "        3.9368e-03, 4.7578e-03, 2.9120e-02, 1.6009e-01, 2.0683e-05, 2.8949e-06,\n",
      "        4.2245e-05, 2.3434e-03, 1.8497e-02, 2.2628e-02, 1.6076e-07, 1.3512e-05,\n",
      "        1.1367e-09, 1.8476e-04, 5.4126e-07, 2.2428e-06, 5.0038e-04, 1.4904e-07,\n",
      "        1.2301e-01, 2.1509e-02, 4.2545e-05, 3.3823e-03, 5.1554e-08, 3.4614e-03,\n",
      "        5.8886e-03, 4.9467e-04, 1.8462e-02, 7.5706e-07, 1.2925e-06, 1.4011e-02,\n",
      "        4.0130e-03, 7.5758e-10, 2.0120e-06, 1.6159e-06, 2.8016e-02, 2.9349e-06,\n",
      "        9.8058e-06, 2.7633e-03, 1.9600e-03, 8.0311e-03, 6.6230e-06, 1.5130e-01,\n",
      "        2.3685e-02, 3.2305e-09, 8.0156e-08, 3.9492e-06, 6.9622e-04, 9.5791e-03,\n",
      "        7.3504e-06, 5.1974e-04, 1.0741e-05, 7.7520e-03, 9.6064e-03, 8.7686e-01,\n",
      "        4.4404e-04, 7.0969e-06, 2.0260e-05, 6.8898e-05], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([7.2453e+00, 3.3514e+01, 7.0501e+01, 1.3058e+01, 4.1793e+01, 1.3091e+01,\n",
      "        1.8779e+00, 2.4329e+00, 1.1366e+01, 2.5763e+01, 1.5042e+01, 3.4162e+01,\n",
      "        1.0013e+01, 7.2520e-01, 8.5123e+00, 9.7293e+00, 7.6311e+01, 1.8526e+01,\n",
      "        1.8734e+02, 2.8516e+00, 5.6575e+01, 3.7210e+01, 4.7939e-01, 7.7639e+01,\n",
      "        2.3158e+01, 9.4156e+00, 9.9679e+00, 1.4849e+00, 9.7474e+01, 1.5417e+00,\n",
      "        3.1436e+00, 4.9544e-01, 8.5013e+00, 5.1640e+01, 4.4238e+01, 6.9686e+00,\n",
      "        1.9308e+00, 1.9862e+02, 3.8547e+01, 4.1317e+01, 1.1107e+01, 3.4001e+01,\n",
      "        2.1389e+01, 1.0331e+00, 4.5287e-01, 4.3402e+00, 2.5172e+01, 2.5193e+01,\n",
      "        1.0016e+01, 1.5984e+02, 8.8954e+01, 3.0628e+01, 1.3111e-01, 5.1057e+00,\n",
      "        2.4138e+01, 4.2827e-01, 2.0554e+01, 4.1941e+00, 5.1186e+00, 4.5919e+01,\n",
      "        6.5909e-01, 2.4484e+01, 1.5203e+01, 7.1563e+00], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(29.0535, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([3.8089e-05, 1.1888e-01, 5.1258e-02, 1.0084e-06, 3.8821e-05, 1.7694e-04,\n",
      "        2.8932e-02, 3.5911e-03, 4.7689e-06, 2.9414e-06, 2.0927e-06, 1.8154e-04,\n",
      "        1.1100e-02, 2.4885e-01, 1.0146e-02, 7.7022e-01, 6.3221e-06, 1.4340e-02,\n",
      "        4.5921e-04, 6.1292e-03, 4.3771e-03, 1.5322e-07, 1.2547e-03, 3.0610e-05,\n",
      "        6.7913e-01, 2.4735e-07, 6.9643e-07, 6.9526e-02, 4.1119e-05, 1.1723e-04,\n",
      "        6.6044e-03, 3.6090e-08, 4.8380e-07, 6.6345e-03, 6.9521e-07, 2.1723e-05,\n",
      "        1.4303e-03, 5.3548e-05, 3.2346e-06, 3.5082e-01, 4.6593e-05, 6.8672e-07,\n",
      "        2.5984e-04, 1.1027e-05, 1.9158e-06, 1.9907e-05, 9.0085e-03, 8.6311e-06,\n",
      "        1.0825e-03, 1.1308e-03, 1.3441e-04, 4.2302e-05, 1.2104e-04, 8.4089e-06,\n",
      "        2.4346e-04, 6.6004e-02, 1.0956e-04, 1.1989e-03, 1.0496e-02, 1.0265e-03,\n",
      "        2.0337e-03, 7.5716e-03, 6.5127e-02, 3.7816e-04], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([1.0679e+01, 2.2830e+01, 1.5499e+01, 4.7601e+01, 1.0555e+01, 2.9996e+00,\n",
      "        1.1323e+01, 1.6344e+00, 2.8576e+01, 3.3976e+01, 3.8061e+01, 2.9114e+00,\n",
      "        5.7934e+00, 3.0436e+01, 5.3687e+00, 4.4178e+01, 2.5641e+01, 7.0919e+00,\n",
      "        6.0566e-01, 3.2872e+00, 2.1797e+00, 7.7152e+01, 5.1484e-02, 1.2155e+01,\n",
      "        4.2521e+01, 6.8968e+01, 5.2846e+01, 1.7992e+01, 1.0184e+01, 4.5952e+00,\n",
      "        3.5636e+00, 1.0464e+02, 5.8276e+01, 3.5808e+00, 5.2872e+01, 1.4664e+01,\n",
      "        1.2806e-01, 8.5683e+00, 3.2877e+01, 3.4343e+01, 9.4022e+00, 5.3051e+01,\n",
      "        1.8163e+00, 2.0316e+01, 3.9158e+01, 1.5340e+01, 4.8320e+00, 2.2585e+01,\n",
      "        6.2856e-03, 1.5112e-02, 4.0274e+00, 1.0004e+01, 4.4591e+00, 2.2834e+01,\n",
      "        1.9960e+00, 1.7554e+01, 4.8897e+00, 3.2906e-02, 5.5273e+00, 6.8461e-04,\n",
      "        5.0387e-01, 4.0982e+00, 1.7442e+01, 9.4565e-01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(18.9382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([3.7506e-05, 9.0149e-03, 2.1555e-07, 6.4585e-05, 4.4109e-08, 8.5348e-07,\n",
      "        1.1434e+03, 8.4752e-03, 2.6018e-04, 3.1970e-08, 3.4516e-06, 7.4948e-02,\n",
      "        1.9076e-02, 3.7889e-03, 7.6514e-05, 5.6177e-01, 1.0403e-07, 1.0224e-05,\n",
      "        4.1922e-01, 2.2363e-08, 3.8369e-05, 1.4119e-05, 6.2317e-06, 6.4835e-08,\n",
      "        1.4976e-06, 7.7638e+00, 5.4761e-07, 3.0454e-06, 4.6938e-07, 7.7639e-03,\n",
      "        2.1790e-02, 1.2645e-03, 8.6851e-07, 2.7257e-05, 1.3018e-02, 9.3832e-05,\n",
      "        3.2824e-06, 9.4313e-02, 4.1228e-04, 2.1898e-03, 2.5883e-04, 1.3082e-03,\n",
      "        1.1397e-04, 5.7831e-04, 1.7846e-02, 4.1378e-01, 5.3648e-06, 6.5382e-05,\n",
      "        3.1469e-03, 2.5766e-03, 1.7252e-01, 3.0342e-06, 2.5293e-04, 3.2734e-08,\n",
      "        9.4354e-07, 4.5491e-04, 9.5654e+00, 5.8290e-07, 3.8663e-06, 4.6659e-06,\n",
      "        3.2297e-03, 2.6157e-01, 1.4274e-03, 2.5630e-06], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([1.0780e+01, 4.8351e+00, 7.1273e+01, 7.5063e+00, 1.0058e+02, 4.9931e+01,\n",
      "        1.9459e+02, 4.5674e+00, 1.8127e+00, 1.0714e+02, 3.2137e+01, 1.8635e+01,\n",
      "        8.6932e+00, 1.7744e+00, 6.6064e+00, 4.0083e+01, 8.4104e+01, 2.1004e+01,\n",
      "        3.6462e+01, 1.1466e+02, 1.0631e+01, 1.8150e+01, 2.5787e+01, 9.3000e+01,\n",
      "        4.2301e+01, 8.0232e+01, 5.6399e+01, 3.3572e+01, 5.8738e+01, 4.2004e+00,\n",
      "        9.4955e+00, 5.5089e-02, 4.9685e+01, 1.2978e+01, 6.5861e+00, 5.5991e+00,\n",
      "        3.2709e+01, 2.0672e+01, 7.8509e-01, 6.1435e-01, 1.8267e+00, 7.2165e-02,\n",
      "        4.7168e+00, 2.9991e-01, 8.3045e+00, 3.6305e+01, 2.7331e+01, 7.4393e+00,\n",
      "        1.3143e+00, 8.9578e-01, 2.6528e+01, 3.3615e+01, 1.8897e+00, 1.0665e+02,\n",
      "        4.8523e+01, 6.2041e-01, 8.4014e+01, 5.5465e+01, 3.0863e+01, 2.8810e+01,\n",
      "        1.3745e+00, 3.0988e+01, 1.2661e-01, 3.5600e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(32.0770, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([4.6687e-05, 2.8776e-07, 1.5343e-05, 2.5530e-04, 6.9253e-05, 5.8593e-04,\n",
      "        1.1731e-03, 7.1604e-09, 1.4575e-04, 6.9283e-06, 9.4624e-03, 3.4266e-06,\n",
      "        4.4556e-03, 5.4336e-02, 3.1505e-03, 1.0102e-03, 9.0697e-04, 3.1512e-05,\n",
      "        2.8607e-04, 1.1449e-07, 4.8292e-06, 3.9613e-02, 6.5219e-08, 3.3770e-06,\n",
      "        5.2165e-04, 7.3142e-06, 2.3503e-06, 6.2250e-04, 2.0407e-02, 1.9088e-06,\n",
      "        7.4251e-05, 4.2442e-01, 1.5705e-02, 6.5386e-02, 6.2851e-07, 2.9854e-02,\n",
      "        3.8110e-08, 3.0674e-05, 1.3025e-03, 8.9226e-08, 2.3503e-06, 3.6747e-04,\n",
      "        7.3221e-03, 7.5044e-08, 1.2592e-02, 1.5610e-07, 3.0528e-05, 2.7565e-07,\n",
      "        2.3557e-03, 1.2024e-03, 3.1100e-07, 6.0841e-05, 1.7411e-02, 6.6122e-04,\n",
      "        4.8857e-06, 1.5838e-05, 7.1461e-03, 5.2171e-04, 3.2396e-05, 3.5929e-06,\n",
      "        1.9434e-06, 3.1224e-08, 3.0048e-01, 3.3043e-06], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([9.3898e+00, 6.6477e+01, 1.7448e+01, 1.8641e+00, 7.1288e+00, 2.8574e-01,\n",
      "        2.5475e-02, 1.4035e+02, 3.7089e+00, 2.4722e+01, 5.0505e+00, 3.2219e+01,\n",
      "        2.2325e+00, 1.5961e+01, 1.3169e+00, 1.0390e-04, 9.5340e-03, 1.1953e+01,\n",
      "        1.5663e+00, 8.2356e+01, 2.8442e+01, 1.3536e+01, 9.2886e+01, 3.2385e+01,\n",
      "        4.2348e-01, 2.4186e+01, 3.6642e+01, 2.2469e-01, 9.0956e+00, 3.9203e+01,\n",
      "        6.7616e+00, 3.6611e+01, 7.5845e+00, 1.7475e+01, 5.4349e+01, 1.1535e+01,\n",
      "        1.0353e+02, 1.2141e+01, 6.9845e-02, 8.6943e+01, 3.6642e+01, 1.0023e+00,\n",
      "        3.9636e+00, 9.0201e+01, 6.4164e+00, 7.6825e+01, 1.2174e+01, 6.7181e+01,\n",
      "        7.3419e-01, 3.3962e-02, 6.5217e+01, 7.8371e+00, 8.1631e+00, 1.7112e-01,\n",
      "        2.8318e+01, 1.7184e+01, 3.8674e+00, 4.2335e-01, 1.1763e+01, 3.1683e+01,\n",
      "        3.8979e+01, 1.0763e+02, 3.2551e+01, 3.2633e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(26.8700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([8.6063e-04, 5.4150e-04, 2.7608e-04, 3.1750e-06, 3.8463e-08, 1.5635e-04,\n",
      "        2.1717e-04, 4.1270e-04, 4.5264e-07, 5.8039e-06, 7.3381e-06, 3.4810e-03,\n",
      "        1.1176e-02, 6.7885e-05, 1.9650e-07, 3.2313e-05, 1.1558e-04, 1.1171e-05,\n",
      "        7.3960e-07, 4.4610e-02, 2.3573e-01, 1.1361e-06, 3.3307e-05, 1.4019e-06,\n",
      "        7.4249e-02, 1.1006e-05, 4.9442e-06, 5.4027e-02, 3.0755e-05, 2.3549e+00,\n",
      "        1.0048e-03, 5.2915e-04, 9.6575e-04, 1.7378e-06, 2.3564e-02, 6.6593e-03,\n",
      "        6.9249e-07, 4.8861e-03, 4.0784e-03, 8.0973e-07, 5.2431e-03, 6.4960e-01,\n",
      "        1.2245e-06, 3.0809e-07, 1.8878e-01, 5.0138e-05, 3.2403e-08, 1.0411e-01,\n",
      "        4.5264e-07, 7.5580e-05, 1.4620e-05, 3.3948e-06, 1.0758e-01, 2.3575e-01,\n",
      "        1.5751e-03, 1.3711e-04, 4.1178e-05, 1.5340e-07, 3.2066e-03, 2.3113e-04,\n",
      "        1.7490e-06, 2.0980e-06, 1.1347e+03, 4.4923e-02], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([2.2526e-02, 3.7628e-01, 1.6565e+00, 3.3091e+01, 1.0334e+02, 3.4435e+00,\n",
      "        2.3319e+00, 7.8330e-01, 5.9296e+01, 2.6514e+01, 2.4154e+01, 1.5558e+00,\n",
      "        5.8263e+00, 7.2358e+00, 7.2843e+01, 1.1781e+01, 4.6559e+00, 2.0200e+01,\n",
      "        5.1976e+01, 1.4424e+01, 2.9841e+01, 4.5970e+01, 1.1574e+01, 4.3164e+01,\n",
      "        1.8554e+01, 2.0334e+01, 2.8191e+01, 1.5916e+01, 1.2122e+01, 6.0283e+01,\n",
      "        2.3190e-05, 4.0512e-01, 1.2148e-03, 4.0388e+01, 9.9839e+00, 3.5949e+00,\n",
      "        5.2929e+01, 2.5167e+00, 1.9760e+00, 5.0677e+01, 2.7454e+00, 4.1943e+01,\n",
      "        4.4960e+01, 6.5369e+01, 2.7464e+01, 8.9579e+00, 1.0686e+02, 2.1580e+01,\n",
      "        5.9296e+01, 6.6696e+00, 1.7854e+01, 3.2325e+01, 2.1886e+01, 2.9842e+01,\n",
      "        2.0640e-01, 3.9480e+00, 1.0175e+01, 7.7131e+01, 1.3577e+00, 2.1455e+00,\n",
      "        4.0306e+01, 3.8029e+01, 1.9438e+02, 1.4478e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(27.5599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([5.3678e-03, 1.2226e-03, 6.4611e-03, 4.3752e-06, 1.5383e-03, 2.1548e-10,\n",
      "        5.8884e-05, 2.3695e-01, 6.5393e-08, 4.1967e-05, 3.3198e-07, 1.0694e-05,\n",
      "        8.8760e-08, 1.4685e-02, 1.6699e-04, 6.0412e-03, 2.4227e-05, 3.3991e-03,\n",
      "        7.3365e-03, 1.0669e-04, 2.3074e-02, 4.4559e-01, 3.9707e-01, 3.8115e-02,\n",
      "        3.5229e-07, 5.1068e-05, 1.9446e-01, 1.4094e-02, 6.4528e-03, 7.2177e-07,\n",
      "        1.0535e-04, 3.6908e-07, 3.2706e+00, 4.1833e-02, 7.2366e-05, 3.9294e-03,\n",
      "        3.6612e-07, 3.3088e-02, 1.0127e-03, 4.3534e-01, 2.1485e-02, 6.6267e-04,\n",
      "        3.5884e-06, 2.1973e-06, 2.8915e-04, 1.2576e-02, 4.1073e-03, 2.2684e-05,\n",
      "        2.8745e-02, 3.2421e-08, 1.0980e-05, 4.3960e-03, 5.0630e-06, 2.0064e-07,\n",
      "        3.2642e-06, 4.6102e-04, 3.2597e-02, 1.2169e-02, 1.4685e-02, 9.8502e-03,\n",
      "        6.1116e-04, 1.1461e-04, 4.1139e-05, 5.2142e-05], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([2.8238e+00, 4.0395e-02, 3.4812e+00, 2.9505e+01, 1.8550e-01, 2.3563e+02,\n",
      "        8.0213e+00, 2.9897e+01, 9.2835e+01, 1.0054e+01, 6.4167e+01, 2.0594e+01,\n",
      "        8.7041e+01, 7.2191e+00, 3.2034e+00, 3.2350e+00, 1.3841e+01, 1.4970e+00,\n",
      "        3.9715e+00, 5.0077e+00, 9.8516e+00, 3.7203e+01, 3.5810e+01, 1.3254e+01,\n",
      "        6.3219e+01, 8.8482e+00, 2.7775e+01, 7.0000e+00, 3.4764e+00, 5.2328e+01,\n",
      "        5.0646e+00, 6.2481e+01, 6.5492e+01, 1.3940e+01, 6.8960e+00, 1.8728e+00,\n",
      "        6.2608e+01, 1.2244e+01, 1.5845e-04, 3.6919e+01, 9.4088e+00, 1.6932e-01,\n",
      "        3.1697e+01, 3.7461e+01, 1.5396e+00, 6.4102e+00, 1.9959e+00, 1.4335e+01,\n",
      "        1.1279e+01, 1.0685e+02, 2.0355e+01, 2.1925e+00, 2.7940e+01, 7.2488e+01,\n",
      "        3.2773e+01, 5.9955e-01, 1.2140e+01, 6.2446e+00, 7.2191e+00, 5.2326e+00,\n",
      "        2.4246e-01, 4.6925e+00, 1.0181e+01, 8.7249e+00], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(24.6985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([3.5098e-02, 3.4823e-06, 7.2421e-05, 1.2148e-03, 1.7832e-02, 1.1858e-03,\n",
      "        1.1038e-04, 4.5229e-07, 1.3798e-06, 2.2266e-02, 1.6450e-04, 1.2176e-04,\n",
      "        2.2757e-06, 2.7496e-05, 6.9181e-05, 1.4514e-04, 3.8161e-03, 3.6473e-03,\n",
      "        9.5936e-04, 3.6973e-05, 1.6450e-04, 9.6224e-06, 2.7768e-03, 6.3890e-07,\n",
      "        3.1573e-01, 1.8032e-03, 3.3579e-06, 8.6830e-05, 3.7919e-02, 9.7729e-05,\n",
      "        1.2339e-05, 3.1459e-04, 8.3983e-03, 8.7031e-03, 9.0282e-07, 1.0956e-06,\n",
      "        1.0385e-04, 2.2109e-02, 1.0917e-06, 7.6024e-06, 5.5229e-05, 1.4752e-04,\n",
      "        1.3492e-04, 3.1459e-04, 7.2768e-05, 6.1866e-03, 1.1430e-04, 1.8850e-06,\n",
      "        1.5688e-02, 3.0377e-01, 3.7834e-05, 1.2770e-02, 6.0990e-03, 1.9973e-01,\n",
      "        5.7810e-06, 8.1236e-09, 1.0818e-05, 1.6615e-08, 6.3095e-03, 3.6810e-07,\n",
      "        7.9071e-07, 3.9325e-02, 6.9253e-07, 6.8949e-03], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([1.2660e+01, 3.2036e+01, 6.8920e+00, 3.7866e-02, 8.3002e+00, 2.9046e-02,\n",
      "        4.8567e+00, 5.9308e+01, 4.3373e+01, 9.6290e+00, 3.2574e+00, 4.4338e+00,\n",
      "        3.7033e+01, 1.2915e+01, 7.1344e+00, 3.7251e+00, 1.7936e+00, 1.6744e+00,\n",
      "        1.7210e-03, 1.0874e+01, 3.2574e+00, 2.1564e+01, 1.0431e+00, 5.4107e+01,\n",
      "        3.3119e+01, 3.4758e-01, 3.2449e+01, 5.9722e+00, 1.3216e+01, 5.4082e+00,\n",
      "        1.9316e+01, 1.3375e+00, 4.5285e+00, 4.6815e+00, 4.9140e+01, 4.6464e+01,\n",
      "        5.1292e+00, 9.5850e+00, 4.6513e+01, 2.3808e+01, 8.3884e+00, 3.6625e+00,\n",
      "        4.0124e+00, 1.3375e+00, 6.8669e+00, 3.3211e+00, 4.7043e+00, 3.9361e+01,\n",
      "        7.5784e+00, 3.2676e+01, 1.0723e+01, 6.4875e+00, 3.2693e+00, 2.8058e+01,\n",
      "        2.6555e+01, 1.3738e+02, 2.0490e+01, 1.2111e+02, 3.3932e+00, 6.2523e+01,\n",
      "        5.1016e+01, 1.3482e+01, 5.2928e+01, 3.7279e+00], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(20.2188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([6.1310e-03, 2.3120e-02, 9.6606e-03, 7.2473e-07, 4.8014e-02, 1.1453e+03,\n",
      "        3.5339e-01, 1.0974e-02, 2.3763e-02, 5.1002e-07, 5.6627e-06, 7.5280e-04,\n",
      "        2.2156e-02, 3.6523e-02, 2.7291e-05, 3.8907e-04, 1.5878e-05, 1.4226e-03,\n",
      "        8.4667e-03, 2.4520e-05, 4.0296e-02, 6.3860e-03, 5.5958e-03, 3.5960e-06,\n",
      "        2.9400e-06, 7.1490e-03, 3.4874e-02, 5.6363e-06, 4.4388e-01, 2.6919e-06,\n",
      "        1.5954e-06, 5.3067e-05, 3.0250e-05, 1.1632e+00, 1.7718e-07, 1.8295e-08,\n",
      "        2.2019e-04, 4.2297e-05, 1.7581e-03, 1.9033e-06, 5.5771e-05, 1.1770e-02,\n",
      "        8.6210e-03, 1.2776e-02, 1.5027e-04, 2.5909e-07, 8.6872e-03, 1.3437e-05,\n",
      "        3.1611e-02, 2.5614e-06, 1.5954e-06, 6.1221e-05, 1.4428e-02, 6.1337e-04,\n",
      "        1.9945e-03, 2.1205e-02, 1.0200e-02, 2.1517e-02, 5.2014e-02, 2.8612e-02,\n",
      "        4.7321e-05, 2.5614e-06, 2.8289e-06, 9.2651e-06], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([3.2883e+00, 9.8640e+00, 5.1441e+00, 5.2269e+01, 1.4988e+01, 1.9464e+02,\n",
      "        3.4428e+01, 5.7387e+00, 1.0037e+01, 5.7472e+01, 2.6769e+01, 8.0633e-02,\n",
      "        9.5982e+00, 1.2945e+01, 1.2969e+01, 8.9115e-01, 1.7163e+01, 1.2426e-01,\n",
      "        4.5631e+00, 1.3751e+01, 1.3662e+01, 3.4377e+00, 2.9653e+00, 3.1674e+01,\n",
      "        3.3981e+01, 3.8690e+00, 1.2615e+01, 2.6817e+01, 3.7156e+01, 3.5017e+01,\n",
      "        4.1482e+01, 8.6213e+00, 1.2238e+01, 4.9828e+01, 7.4621e+01, 1.1900e+02,\n",
      "        2.2900e+00, 1.0005e+01, 3.1834e-01, 3.9240e+01, 8.3319e+00, 6.0789e+00,\n",
      "        4.6406e+00, 6.4901e+00, 3.5922e+00, 6.8200e+01, 4.6736e+00, 1.8574e+01,\n",
      "        1.1927e+01, 3.5608e+01, 4.1482e+01, 7.8023e+00, 7.1246e+00, 2.3891e-01,\n",
      "        4.7661e-01, 9.3284e+00, 5.3936e+00, 9.4177e+00, 1.5614e+01, 1.1248e+01,\n",
      "        9.3074e+00, 3.5608e+01, 3.4432e+01, 2.1916e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(22.2354, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([2.8308e-06, 8.5837e-04, 7.5573e-05, 5.9688e-06, 6.4544e-03, 3.2857e-06,\n",
      "        8.8659e-06, 1.9302e-04, 3.6901e-07, 5.1877e-04, 2.1992e-04, 4.0791e-02,\n",
      "        3.9976e-03, 1.1870e-04, 2.1485e-03, 1.4020e-01, 1.3549e-05, 1.6552e-06,\n",
      "        4.2849e-07, 3.2857e-06, 9.2797e-07, 1.3280e-06, 8.5309e-06, 2.2590e-06,\n",
      "        4.7783e-01, 6.9245e-07, 4.6495e-05, 1.0667e-04, 4.9888e-05, 4.4169e-06,\n",
      "        1.1589e-03, 3.3221e-03, 4.3496e-07, 7.0117e-04, 2.0202e-03, 4.1246e-03,\n",
      "        5.7872e-06, 2.0021e-06, 3.7797e-07, 7.2661e-02, 2.1186e-01, 5.8939e-04,\n",
      "        1.7255e-04, 1.1315e-06, 2.5297e-04, 3.1590e-05, 3.6615e-06, 3.3912e-02,\n",
      "        7.8207e-05, 7.5749e-07, 2.8429e-06, 1.7377e-06, 1.9567e-03, 1.1932e-03,\n",
      "        4.4202e-08, 1.0988e-02, 2.9958e-06, 4.0222e-07, 1.4500e-04, 7.6608e-10,\n",
      "        4.2773e-06, 2.5897e-07, 8.0696e-03, 9.2505e-08], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([3.4424e+01, 2.3324e-02, 6.6701e+00, 2.6227e+01, 3.4773e+00, 3.2698e+01,\n",
      "        2.2331e+01, 2.7058e+00, 6.2484e+01, 4.3073e-01, 2.2936e+00, 1.3753e+01,\n",
      "        1.9201e+00, 4.5417e+00, 5.8484e-01, 2.4434e+01, 1.8503e+01, 4.1009e+01,\n",
      "        6.0144e+01, 3.2698e+01, 4.8755e+01, 4.3878e+01, 2.2696e+01, 3.7122e+01,\n",
      "        3.8060e+01, 5.2930e+01, 9.4151e+00, 5.0089e+00, 8.9879e+00, 2.9401e+01,\n",
      "        2.1760e-02, 1.4414e+00, 5.9912e+01, 1.2603e-01, 4.9452e-01, 2.0078e+00,\n",
      "        2.6544e+01, 3.8608e+01, 6.2105e+01, 1.8368e+01, 2.8686e+01, 2.7948e-01,\n",
      "        3.0873e+00, 4.6026e+01, 1.8892e+00, 1.1937e+01, 3.1471e+01, 1.2417e+01,\n",
      "        6.4943e+00, 5.1631e+01, 3.4374e+01, 4.0389e+01, 4.5057e-01, 3.1206e-02,\n",
      "        1.0054e+02, 5.7446e+00, 3.3762e+01, 6.1129e+01, 3.7289e+00, 1.9830e+02,\n",
      "        2.9751e+01, 6.8208e+01, 4.3602e+00, 8.6271e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(27.4717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([8.1498e-03, 5.8213e-03, 2.1808e-02, 7.8397e-09, 1.8006e-02, 6.6082e-04,\n",
      "        1.3030e-02, 1.0626e-02, 5.9958e-04, 2.5561e-03, 6.1162e-05, 1.1729e-03,\n",
      "        3.9266e-06, 2.0041e-02, 8.5444e-07, 1.1834e-05, 1.3775e-02, 1.0627e-05,\n",
      "        2.2655e-06, 6.2891e-06, 4.7809e-06, 3.2012e-08, 1.1406e+03, 1.0512e-04,\n",
      "        4.7810e-07, 1.6317e-04, 2.4815e-02, 9.6905e-05, 3.0644e-06, 3.0086e-05,\n",
      "        1.1505e-06, 6.8916e-02, 1.0745e-02, 2.3419e-03, 3.4476e-04, 6.9743e-02,\n",
      "        4.1106e-01, 9.1780e-07, 1.1278e-06, 1.4046e-05, 3.5952e-06, 1.6936e-06,\n",
      "        1.9172e-05, 1.6680e-04, 2.5257e-03, 5.8283e-04, 1.1528e-04, 2.1323e-05,\n",
      "        5.5866e-07, 7.5811e-07, 1.9081e-02, 6.0165e-05, 3.3965e-03, 1.3713e-02,\n",
      "        7.3711e-02, 1.1358e+03, 1.1447e-03, 1.0610e-02, 1.7181e-02, 2.8363e-05,\n",
      "        2.5592e-07, 3.1174e-02, 9.4284e-02, 6.4645e-07], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([4.4016e+00, 3.1029e+00, 9.5005e+00, 1.3821e+02, 8.3561e+00, 1.7163e-01,\n",
      "        6.5909e+00, 5.5854e+00, 2.6166e-01, 8.8073e-01, 7.8077e+00, 2.5427e-02,\n",
      "        3.0691e+01, 8.9868e+00, 4.9915e+01, 1.9685e+01, 6.8794e+00, 2.0652e+01,\n",
      "        3.7088e+01, 2.5694e+01, 2.8549e+01, 1.0711e+02, 1.9452e+02, 5.0744e+00,\n",
      "        5.8456e+01, 3.2868e+00, 1.0313e+01, 5.4477e+00, 3.3500e+01, 1.2276e+01,\n",
      "        4.5800e+01, 1.7917e+01, 5.6379e+00, 7.2413e-01, 1.1340e+00, 1.8019e+01,\n",
      "        3.6225e+01, 4.8909e+01, 4.6070e+01, 1.8194e+01, 3.1676e+01, 4.0715e+01,\n",
      "        1.5637e+01, 3.2076e+00, 8.5841e-01, 2.9144e-01, 4.6672e+00, 1.4807e+01,\n",
      "        5.6100e+01, 5.1620e+01, 8.6947e+00, 7.8998e+00, 1.4951e+00, 6.8555e+00,\n",
      "        1.8491e+01, 1.9440e+02, 1.8259e-02, 5.5779e+00, 8.0874e+00, 1.2693e+01,\n",
      "        6.8404e+01, 1.1831e+01, 2.0669e+01, 5.3935e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(26.8794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([3.1570e-04, 4.9591e-03, 1.4085e-04, 5.3888e-06, 6.0785e-05, 1.0617e-06,\n",
      "        3.4095e-06, 1.8989e-06, 1.0296e-02, 8.9561e-03, 6.9131e-06, 8.7895e-05,\n",
      "        7.6859e-06, 1.2111e-04, 2.1610e-04, 6.8578e-04, 2.9863e-04, 3.7802e-04,\n",
      "        7.7422e-05, 3.5391e-01, 5.2764e-03, 1.7096e-05, 3.9442e-05, 3.4095e-06,\n",
      "        5.5320e-03, 1.3020e-03, 9.9170e-05, 1.1888e-02, 4.8012e-04, 4.3572e-05,\n",
      "        1.5830e-05, 2.5172e-06, 2.5762e-03, 4.3178e-07, 1.1442e+03, 7.1151e-07,\n",
      "        7.4223e-05, 1.4810e-06, 1.0167e-04, 3.1797e-03, 1.5545e-05, 9.8606e-05,\n",
      "        1.9237e-02, 4.5486e-04, 1.0715e-07, 3.9055e-06, 1.8976e-05, 2.6814e-05,\n",
      "        5.1962e-05, 6.9260e-06, 2.2558e-03, 1.3403e-06, 3.0520e-03, 6.9131e-06,\n",
      "        2.2599e-06, 2.6418e-04, 7.3796e-09, 5.2626e-07, 2.2734e-06, 4.3620e-03,\n",
      "        3.8828e-01, 5.2626e-07, 7.5322e-03, 5.4949e-05], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([1.3293e+00, 2.5639e+00, 3.8419e+00, 2.7284e+01, 7.8423e+00, 4.6894e+01,\n",
      "        3.2276e+01, 3.9269e+01, 5.4369e+00, 4.8063e+00, 2.4744e+01, 5.9127e+00,\n",
      "        2.3701e+01, 4.4566e+00, 2.3470e+00, 1.4228e-01, 1.4606e+00, 9.4635e-01,\n",
      "        6.5458e+00, 3.4446e+01, 2.7664e+00, 1.6556e+01, 1.0452e+01, 3.2276e+01,\n",
      "        2.9260e+00, 6.9649e-02, 5.3403e+00, 6.1282e+00, 5.3833e-01, 9.8178e+00,\n",
      "        1.7188e+01, 3.5815e+01, 8.9552e-01, 6.0025e+01, 1.9461e+02, 5.2535e+01,\n",
      "        6.7636e+00, 4.2446e+01, 5.2258e+00, 1.3382e+00, 1.7339e+01, 5.3668e+00,\n",
      "        8.7428e+00, 6.2057e-01, 8.3562e+01, 3.0751e+01, 1.5718e+01, 1.3096e+01,\n",
      "        8.7452e+00, 2.4726e+01, 6.6177e-01, 4.3757e+01, 1.2450e+00, 2.4744e+01,\n",
      "        3.7118e+01, 1.7719e+00, 1.3964e+02, 5.6998e+01, 3.7045e+01, 2.1695e+00,\n",
      "        3.5542e+01, 5.6998e+01, 4.0771e+00, 8.4178e+00], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(22.4813, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([4.7954e-04, 4.9396e-06, 3.1922e-03, 3.3503e-04, 2.0930e-06, 1.5826e-03,\n",
      "        1.6586e-05, 6.6447e-03, 1.2629e-02, 7.6080e-07, 1.0482e-07, 5.1341e-04,\n",
      "        1.4518e-01, 7.2121e-07, 6.1826e-06, 1.3479e-07, 3.0549e-05, 1.8582e-01,\n",
      "        4.7461e-01, 2.3307e-06, 4.0263e-01, 9.0144e-05, 1.7834e-01, 2.6170e-05,\n",
      "        1.3741e-03, 1.4673e-01, 1.5097e-03, 5.5082e-04, 1.2861e-03, 5.3835e-06,\n",
      "        4.9400e-07, 5.2067e-04, 8.9297e-03, 6.5767e-01, 1.1381e-09, 3.5721e-06,\n",
      "        9.1912e-03, 4.1217e-04, 2.3067e-02, 6.5899e-05, 1.5692e-03, 1.3754e+00,\n",
      "        2.8386e-02, 6.0514e-07, 2.3458e-05, 1.5307e-04, 1.5114e-03, 1.9071e-02,\n",
      "        1.5721e-02, 7.1698e-02, 1.7603e-06, 9.5173e-04, 6.9629e-02, 6.8236e-05,\n",
      "        3.5463e-06, 1.0648e-04, 3.1067e-03, 5.4471e-03, 1.3663e-02, 1.6336e-05,\n",
      "        6.9766e-02, 3.0621e-06, 8.8583e-06, 2.2492e-04], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([5.4013e-01, 2.8201e+01, 1.3473e+00, 1.1958e+00, 3.8058e+01, 2.1076e-01,\n",
      "        1.6804e+01, 3.5866e+00, 6.4314e+00, 5.1569e+01, 8.3965e+01, 4.4445e-01,\n",
      "        2.4780e+01, 5.2339e+01, 2.5867e+01, 7.9420e+01, 1.2169e+01, 2.7298e+01,\n",
      "        3.7976e+01, 3.6743e+01, 3.5976e+01, 5.7905e+00, 2.6871e+01, 1.3273e+01,\n",
      "        1.0099e-01, 2.4886e+01, 1.6967e-01, 3.5563e-01, 6.3296e-02, 2.7294e+01,\n",
      "        5.7957e+01, 4.2594e-01, 4.7934e+00, 4.2103e+01, 1.8731e+02, 3.1749e+01,\n",
      "        4.9206e+00, 7.8558e-01, 9.8496e+00, 7.3964e+00, 2.0303e-01, 5.2222e+01,\n",
      "        1.1195e+01, 5.4909e+01, 1.4082e+01, 3.5226e+00, 1.7060e-01, 8.6918e+00,\n",
      "        7.5901e+00, 1.8254e+01, 4.0224e+01, 2.4481e-03, 1.8005e+01, 7.2081e+00,\n",
      "        3.1830e+01, 5.0168e+00, 1.2849e+00, 2.8733e+00, 6.8367e+00, 1.6928e+01,\n",
      "        1.8021e+01, 3.3509e+01, 2.2339e+01, 2.2261e+00], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(21.6901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([2.4863e-07, 2.4135e-05, 5.2571e-07, 5.2971e-05, 2.9793e-01, 2.6412e-03,\n",
      "        7.4462e-03, 1.8929e-05, 4.5739e-04, 1.9493e-03, 5.5175e-05, 1.7621e-06,\n",
      "        9.0904e-03, 2.3529e-03, 7.7100e-05, 4.3243e-01, 6.1446e-05, 9.7462e-07,\n",
      "        5.9182e-04, 3.7998e-03, 1.1466e-02, 3.1404e-03, 1.1387e-03, 4.0856e-05,\n",
      "        5.6152e-06, 6.5445e-03, 2.1639e-03, 1.3004e-05, 4.2927e-01, 1.1848e-01,\n",
      "        1.7986e-09, 1.4584e-06, 9.9279e-04, 8.7500e-02, 9.5139e-06, 1.9500e-02,\n",
      "        8.6993e-03, 5.0262e-05, 1.1796e-08, 8.0377e-08, 7.3389e-04, 5.4832e-07,\n",
      "        1.9136e-06, 2.2224e-03, 4.7303e-03, 6.0029e-04, 1.5039e-03, 1.0200e-06,\n",
      "        1.7639e-04, 5.1366e-06, 4.4696e-05, 1.2153e-02, 3.2456e-03, 1.0519e-03,\n",
      "        5.4459e-03, 1.0955e-04, 4.7291e-07, 1.3444e-04, 1.9003e-01, 2.5178e-03,\n",
      "        2.4766e-06, 1.3953e-05, 4.2797e-07, 5.0815e-03], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([6.8883e+01, 1.3869e+01, 5.7014e+01, 8.6319e+00, 3.2454e+01, 9.4333e-01,\n",
      "        4.0308e+00, 1.5737e+01, 6.1187e-01, 4.4552e-01, 8.3940e+00, 4.0211e+01,\n",
      "        4.8718e+00, 7.3214e-01, 6.5672e+00, 3.6838e+01, 7.7818e+00, 4.8073e+01,\n",
      "        2.7515e-01, 1.7821e+00, 5.9505e+00, 1.3096e+00, 1.6877e-02, 1.0225e+01,\n",
      "        2.6856e+01, 3.5292e+00, 5.9588e-01, 1.8857e+01, 3.6749e+01, 2.2798e+01,\n",
      "        1.7499e+02, 4.2646e+01, 5.2356e-05, 1.9996e+01, 2.1669e+01, 8.8235e+00,\n",
      "        4.6796e+00, 8.9432e+00, 1.2877e+02, 8.8902e+01, 9.5728e-02, 5.6380e+01,\n",
      "        3.9172e+01, 6.3778e-01, 2.4149e+00, 2.6045e-01, 1.6649e-01, 4.7444e+01,\n",
      "        3.0103e+00, 2.7787e+01, 9.6589e+00, 6.2378e+00, 1.3860e+00, 2.5625e-03,\n",
      "        2.8726e+00, 4.8902e+00, 5.8623e+01, 4.0265e+00, 2.7533e+01, 8.5267e-01,\n",
      "        3.6010e+01, 1.8250e+01, 6.0163e+01, 2.6426e+00], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(21.7965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([3.8891e-02, 1.3888e-03, 6.9835e-03, 3.8926e-03, 1.2529e-03, 5.3723e-06,\n",
      "        3.6074e-08, 7.3140e-01, 2.8806e-07, 2.5614e-06, 3.9309e-04, 7.7937e-02,\n",
      "        2.7356e-05, 3.8076e-08, 9.7708e-05, 8.6291e-06, 2.8496e-05, 6.5137e-05,\n",
      "        4.6552e-05, 1.0955e-03, 7.4079e-06, 1.4235e-02, 1.5664e-05, 1.0830e-03,\n",
      "        5.1191e-03, 1.3600e-01, 2.0598e-07, 6.0055e-05, 1.0566e-06, 7.2883e-05,\n",
      "        9.8162e-06, 3.1006e-06, 2.5216e-06, 1.6354e-07, 7.4652e-01, 1.0384e-06,\n",
      "        1.0068e-03, 2.5611e-05, 1.2829e-03, 1.5849e-05, 1.3396e-06, 1.7423e-03,\n",
      "        3.5394e-08, 2.0907e-02, 1.0935e-06, 3.6579e-07, 5.3464e-07, 1.9416e-06,\n",
      "        1.8334e-06, 1.6633e-01, 2.2546e-01, 4.2850e-06, 7.6339e-04, 4.4015e-03,\n",
      "        1.4238e-04, 5.5199e-05, 3.2170e-05, 2.8455e-02, 1.3430e-04, 6.2569e-03,\n",
      "        1.2609e-06, 1.0904e-02, 4.2263e-01, 1.2227e-06], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([1.3401e+01, 1.0787e-01, 3.7774e+00, 1.8471e+00, 5.0841e-02, 2.7316e+01,\n",
      "        1.0465e+02, 4.3493e+01, 6.6461e+01, 3.5607e+01, 8.7181e-01, 1.8974e+01,\n",
      "        1.2951e+01, 1.0355e+02, 5.4092e+00, 2.2587e+01, 1.2659e+01, 7.4598e+00,\n",
      "        9.4076e+00, 8.3141e-03, 2.4061e+01, 7.0528e+00, 1.7275e+01, 6.3551e-03,\n",
      "        2.6666e+00, 2.4134e+01, 7.2042e+01, 7.9101e+00, 4.6960e+01, 6.8586e+00,\n",
      "        2.1379e+01, 3.3364e+01, 3.5795e+01, 7.6012e+01, 4.3764e+01, 4.7197e+01,\n",
      "        4.5558e-05, 1.3430e+01, 6.2073e-02, 1.7178e+01, 4.3764e+01, 3.0828e-01,\n",
      "        1.0504e+02, 9.2422e+00, 4.6490e+01, 6.2623e+01, 5.6760e+01, 3.8991e+01,\n",
      "        3.9710e+01, 2.6153e+01, 2.9356e+01, 2.9731e+01, 7.2890e-02, 2.1962e+00,\n",
      "        3.7996e+00, 8.3915e+00, 1.1811e+01, 1.1211e+01, 4.0308e+00, 3.3624e+00,\n",
      "        4.4568e+01, 5.7080e+00, 3.6560e+01, 4.4979e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(25.8219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([5.1939e-03, 1.5204e-01, 1.8198e-06, 1.3658e-02, 1.0194e-06, 3.1497e-06,\n",
      "        9.7091e-07, 2.9226e-07, 7.6487e-03, 2.0455e-04, 8.0225e-06, 5.4851e-03,\n",
      "        2.4191e-03, 3.3429e-02, 7.3740e-06, 4.7129e-06, 5.6492e-06, 1.5643e-05,\n",
      "        1.9151e-03, 3.5385e-08, 6.5118e-05, 1.1141e-06, 6.6937e-01, 5.5365e-03,\n",
      "        3.5021e-02, 1.6554e-05, 2.6304e-06, 6.6385e-04, 1.8938e-03, 5.1487e-02,\n",
      "        7.2653e-05, 2.0975e-04, 1.8038e-05, 3.6082e-07, 2.4341e-03, 1.0478e-01,\n",
      "        1.3160e-05, 3.0393e-05, 7.2336e+00, 9.2302e-07, 1.5757e-01, 4.2811e-07,\n",
      "        6.1446e-07, 2.5993e-05, 4.4217e-01, 4.1328e-06, 4.2318e-05, 7.6010e-04,\n",
      "        2.3392e-03, 1.4283e-04, 8.0753e-09, 2.4860e-03, 3.5924e-02, 3.8418e-04,\n",
      "        1.3393e-02, 1.6248e-04, 1.2285e-05, 1.1097e-07, 1.5543e-03, 4.8537e-06,\n",
      "        1.1685e-02, 1.4711e-04, 1.4489e-01, 2.3520e-02], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([2.7142e+00, 2.5242e+01, 3.9804e+01, 6.8349e+00, 4.7452e+01, 3.3183e+01,\n",
      "        4.8126e+01, 6.6225e+01, 4.1393e+00, 2.5185e+00, 2.3286e+01, 2.8969e+00,\n",
      "        7.8038e-01, 1.2316e+01, 2.4106e+01, 2.8702e+01, 2.6793e+01, 1.7287e+01,\n",
      "        4.2219e-01, 1.0505e+02, 7.4614e+00, 4.6236e+01, 4.2333e+01, 2.9288e+00,\n",
      "        1.2645e+01, 1.6819e+01, 3.5291e+01, 1.6785e-01, 4.0776e-01, 1.5534e+01,\n",
      "        6.8752e+00, 2.4394e+00, 1.6122e+01, 6.2839e+01, 7.9132e-01, 2.1640e+01,\n",
      "        1.8754e+01, 1.2205e+01, 7.8970e+01, 4.8830e+01, 2.5602e+01, 6.0157e+01,\n",
      "        5.4683e+01, 1.3322e+01, 3.7109e+01, 3.0127e+01, 1.0002e+01, 7.5242e-02,\n",
      "        7.2220e-01, 3.7873e+00, 1.3752e+02, 8.2936e-01, 1.2826e+01, 9.1519e-01,\n",
      "        6.7326e+00, 3.3023e+00, 1.9354e+01, 8.2923e+01, 1.9451e-01, 2.8388e+01,\n",
      "        6.0432e+00, 3.6734e+00, 2.4761e+01, 9.9721e+00], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(24.0653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([2.2187e-02, 6.1185e-07, 1.2249e-02, 7.9006e-05, 7.6563e-06, 1.8034e-05,\n",
      "        1.1674e-04, 6.4971e-02, 3.3736e-03, 8.4158e-05, 3.3387e-04, 7.0580e-01,\n",
      "        9.4119e-03, 6.1255e-06, 2.2118e-01, 8.5609e-03, 7.1701e-06, 3.9317e+00,\n",
      "        3.6035e-09, 7.1804e-04, 3.0753e-07, 2.3964e-05, 2.2488e-04, 7.3657e-05,\n",
      "        3.3631e-03, 2.6103e+00, 1.0921e-03, 3.1124e-08, 1.0087e-05, 4.0817e-05,\n",
      "        1.1177e-02, 4.3603e-01, 1.9942e-02, 6.8421e-06, 4.8223e-06, 3.8947e-02,\n",
      "        1.3041e-05, 3.9253e-04, 3.8337e-06, 2.1261e-05, 3.2507e-09, 2.4522e-05,\n",
      "        1.6964e-02, 1.0097e-02, 3.4051e-03, 1.1148e+03, 3.2734e-06, 8.4387e-03,\n",
      "        4.3475e-07, 4.1213e-05, 1.0723e-04, 3.9582e-05, 7.6389e-01, 2.4141e-02,\n",
      "        1.1732e-05, 5.9892e-07, 3.1736e-04, 1.2605e-03, 4.1308e-03, 2.4814e-03,\n",
      "        4.6614e-05, 1.4744e-02, 1.0299e-04, 9.0508e-07], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([9.6070e+00, 5.4746e+01, 6.2774e+00, 6.4426e+00, 2.3739e+01, 1.6124e+01,\n",
      "        4.6129e+00, 1.7422e+01, 1.4786e+00, 6.1259e+00, 1.2034e+00, 4.3025e+01,\n",
      "        5.0264e+00, 2.5962e+01, 2.9149e+01, 4.6105e+00, 2.4382e+01, 6.8506e+01,\n",
      "        1.5709e+02, 1.0972e-01, 6.5399e+01, 1.3922e+01, 2.2266e+00, 6.8034e+00,\n",
      "        1.4710e+00, 6.1893e+01, 7.7696e-03, 1.0769e+02, 2.1128e+01, 1.0231e+01,\n",
      "        5.8268e+00, 3.6938e+01, 8.9570e+00, 2.4847e+01, 2.8457e+01, 1.3412e+01,\n",
      "        1.8832e+01, 8.7448e-01, 3.0957e+01, 1.4829e+01, 1.5968e+02, 1.3751e+01,\n",
      "        8.0152e+00, 5.3463e+00, 1.5013e+00, 1.9388e+02, 3.2741e+01, 4.5489e+00,\n",
      "        5.9919e+01, 1.0170e+01, 4.9851e+00, 1.0429e+01, 4.4069e+01, 1.0137e+01,\n",
      "        1.9762e+01, 5.5062e+01, 1.3173e+00, 5.3601e-02, 2.0121e+00, 8.2595e-01,\n",
      "        9.3994e+00, 7.2407e+00, 5.1671e+00, 4.9105e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(26.3980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([2.6731e-02, 3.9577e-01, 4.2726e-07, 3.6323e-05, 9.1951e-05, 6.2500e-02,\n",
      "        3.9155e-03, 8.0786e-07, 6.2968e-01, 5.7298e-03, 1.6966e-04, 1.4082e+00,\n",
      "        9.8701e-05, 2.6999e-09, 4.2014e-01, 1.8422e-02, 5.1407e-06, 4.1162e-05,\n",
      "        3.7215e-01, 3.9191e-02, 8.3683e-03, 6.3224e-06, 2.6307e-04, 3.4685e-02,\n",
      "        9.7226e-03, 2.2997e-06, 1.9558e-03, 2.2415e-06, 2.4281e-02, 1.1738e-01,\n",
      "        7.2745e-05, 4.4536e-05, 1.6173e-06, 9.4015e-06, 1.1129e+03, 4.5479e-06,\n",
      "        7.2794e-08, 1.2761e-07, 1.2992e-05, 1.0312e-01, 9.7915e-05, 6.5885e-06,\n",
      "        6.2976e-06, 2.2295e-04, 5.5776e-07, 4.4396e-05, 5.2954e-05, 4.4226e-04,\n",
      "        1.7753e-06, 9.6609e-04, 1.2067e-03, 2.8812e-03, 3.1464e-02, 5.5589e-06,\n",
      "        8.3172e-06, 6.3273e-03, 4.0663e-06, 4.0362e-07, 5.7816e-04, 6.1486e-01,\n",
      "        2.5273e-03, 5.5775e-03, 1.1321e-02, 5.0945e-05], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([1.0797e+01, 3.5770e+01, 6.0188e+01, 1.0991e+01, 5.6954e+00, 1.7100e+01,\n",
      "        1.8631e+00, 5.0710e+01, 4.1541e+01, 3.0474e+00, 3.1469e+00, 5.2564e+01,\n",
      "        5.3623e+00, 1.6441e+02, 3.6489e+01, 8.4887e+00, 2.7779e+01, 1.0178e+01,\n",
      "        3.5038e+01, 1.3458e+01, 4.5133e+00, 2.5641e+01, 1.7831e+00, 1.2576e+01,\n",
      "        5.1731e+00, 3.6906e+01, 4.4996e-01, 3.7217e+01, 1.0174e+01, 2.2709e+01,\n",
      "        6.8686e+00, 9.6811e+00, 4.1306e+01, 2.1780e+01, 1.9384e+02, 2.9085e+01,\n",
      "        9.0780e+01, 8.0399e+01, 1.8865e+01, 2.1492e+01, 5.3994e+00, 2.5225e+01,\n",
      "        2.5680e+01, 2.2524e+00, 5.6124e+01, 9.7008e+00, 8.6338e+00, 6.6561e-01,\n",
      "        4.0117e+01, 1.1903e-03, 3.5289e-02, 1.1198e+00, 1.1895e+01, 2.6961e+01,\n",
      "        2.2939e+01, 3.4035e+00, 3.0305e+01, 6.1075e+01, 3.0020e-01, 4.1234e+01,\n",
      "        8.5961e-01, 2.9541e+00, 5.8885e+00, 8.8626e+00], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(25.8982, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([1.5796e+01, 1.0029e-05, 4.5211e-05, 1.3913e-01, 5.5735e-03, 1.3669e-03,\n",
      "        1.9052e-06, 4.1162e-03, 1.5471e-05, 1.2094e-06, 2.5296e-01, 8.8733e-03,\n",
      "        7.2963e-06, 1.1139e+03, 5.5435e-03, 6.9695e-04, 1.0584e-04, 4.8449e-06,\n",
      "        8.2806e-06, 1.2984e-02, 4.7847e-03, 1.3724e-03, 1.3224e-04, 1.0844e-06,\n",
      "        9.2878e-06, 1.1993e-05, 1.8291e-02, 9.2222e-07, 7.3050e-04, 2.1889e-10,\n",
      "        5.2409e-05, 2.2074e-04, 4.1684e-05, 1.5228e-04, 3.4202e-06, 7.5934e-04,\n",
      "        7.0303e-05, 1.1022e-05, 2.5667e-04, 6.6545e-03, 2.2412e-06, 1.1905e-03,\n",
      "        2.6943e-04, 6.4182e-03, 1.6282e-06, 2.5544e-07, 1.0880e-02, 2.9757e-04,\n",
      "        8.8304e+00, 2.5269e-05, 9.7576e-07, 1.9414e-02, 6.3337e-05, 4.2193e-05,\n",
      "        1.7177e-02, 8.3859e-03, 5.2628e-06, 4.6514e-05, 9.7627e-02, 6.6639e-07,\n",
      "        6.7684e-02, 1.6952e-04, 9.6677e-07, 1.3318e-02], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([9.3461e+01, 2.1181e+01, 9.5877e+00, 2.4358e+01, 2.9516e+00, 9.7671e-02,\n",
      "        3.9227e+01, 2.0021e+00, 1.7379e+01, 4.5126e+01, 3.0617e+01, 4.7657e+00,\n",
      "        2.4210e+01, 1.9386e+02, 2.9331e+00, 1.3035e-01, 5.0439e+00, 2.8407e+01,\n",
      "        2.2981e+01, 6.5728e+00, 2.4505e+00, 1.0022e-01, 4.0931e+00, 4.6604e+01,\n",
      "        2.1894e+01, 1.9567e+01, 8.4473e+00, 4.8842e+01, 9.8616e-02, 2.3515e+02,\n",
      "        8.6947e+00, 2.2825e+00, 1.0097e+01, 3.5420e+00, 3.2240e+01, 7.5795e-02,\n",
      "        7.0487e+00, 2.0321e+01, 1.8496e+00, 3.5921e+00, 3.7219e+01, 3.0401e-02,\n",
      "        1.7199e+00, 3.4564e+00, 4.1220e+01, 6.8434e+01, 5.6974e+00, 1.4692e+00,\n",
      "        8.2555e+01, 1.3529e+01, 4.8057e+01, 8.7972e+00, 7.6137e+00, 1.0020e+01,\n",
      "        8.0858e+00, 4.5222e+00, 2.7532e+01, 9.4126e+00, 2.0987e+01, 5.3489e+01,\n",
      "        1.7765e+01, 3.1499e+00, 4.8185e+01, 6.7036e+00], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(24.7115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([1.5190e-03, 1.0069e-05, 4.4727e-07, 2.5648e-07, 4.9544e-06, 5.4080e-06,\n",
      "        1.0434e-03, 4.1618e-02, 5.6803e-04, 4.7215e-05, 3.0933e-06, 2.9301e-04,\n",
      "        6.7991e-03, 7.6585e-08, 2.0272e-06, 3.9335e-02, 1.4703e-02, 8.4529e-04,\n",
      "        5.3746e-06, 1.2767e-06, 3.3950e-04, 6.8199e-06, 1.0384e-07, 1.0035e+00,\n",
      "        6.2721e-07, 2.4475e-03, 1.0836e-05, 1.0668e-03, 1.4345e-01, 8.4889e-07,\n",
      "        2.9323e-06, 7.6464e-06, 9.6290e-09, 1.0943e-08, 2.1302e-03, 8.4054e-06,\n",
      "        5.3300e-05, 3.0968e-06, 1.6929e-07, 8.0129e-03, 1.9493e-06, 1.0534e-02,\n",
      "        1.1142e-01, 5.2553e-04, 3.8148e-06, 1.3814e-05, 7.0485e-06, 4.8211e-04,\n",
      "        1.0640e-06, 8.4821e-07, 1.2530e-03, 2.3110e-03, 4.2123e-03, 2.6926e-06,\n",
      "        1.0640e-06, 6.3369e-05, 1.3511e-03, 2.1246e-05, 1.7903e+00, 5.5459e-07,\n",
      "        2.6612e-04, 1.7550e-04, 9.4355e-09, 9.1085e-04], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([1.7476e-01, 2.1144e+01, 5.9480e+01, 6.8367e+01, 2.8169e+01, 2.7247e+01,\n",
      "        1.8066e-03, 1.3902e+01, 3.1988e-01, 9.3211e+00, 3.3391e+01, 1.5069e+00,\n",
      "        3.6741e+00, 8.9816e+01, 3.8454e+01, 1.3484e+01, 7.2255e+00, 2.8251e-02,\n",
      "        2.7312e+01, 4.4402e+01, 1.1670e+00, 2.4879e+01, 8.4137e+01, 4.7765e+01,\n",
      "        5.4379e+01, 8.0117e-01, 2.0474e+01, 4.1771e-03, 2.4661e+01, 5.0007e+01,\n",
      "        3.4012e+01, 2.3751e+01, 1.3342e+02, 1.3048e+02, 5.7185e-01, 2.2838e+01,\n",
      "        8.5956e+00, 3.3378e+01, 7.5410e+01, 4.3308e+00, 3.8941e+01, 5.5440e+00,\n",
      "        2.2215e+01, 4.1390e-01, 3.1012e+01, 1.8336e+01, 2.4551e+01, 5.3230e-01,\n",
      "        4.6864e+01, 5.0019e+01, 5.0868e-02, 7.0167e-01, 2.0679e+00, 3.5014e+01,\n",
      "        4.6864e+01, 7.6108e+00, 9.0536e-02, 1.4835e+01, 5.6102e+01, 5.6209e+01,\n",
      "        1.7524e+00, 3.0281e+00, 1.3389e+02, 8.7194e-03], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(29.0490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([2.1853e-02, 6.0012e-07, 2.0203e-07, 1.9064e-05, 6.8235e-05, 8.7162e-04,\n",
      "        8.3575e-06, 1.4162e-02, 2.7514e-06, 2.5617e-04, 7.7333e-06, 7.3966e-08,\n",
      "        3.1896e-05, 7.9413e-07, 1.0069e-06, 3.5128e-02, 2.5149e-06, 2.7976e-05,\n",
      "        5.2999e+00, 2.0489e-01, 4.6151e-08, 4.1006e-04, 2.3939e-01, 2.8154e-06,\n",
      "        1.1284e-07, 4.5605e-03, 1.3501e-03, 8.3153e-01, 3.7994e-03, 6.9154e-05,\n",
      "        2.4869e-06, 1.9627e-07, 4.9536e-06, 2.5908e-05, 1.8114e-04, 3.4282e-03,\n",
      "        4.4364e-05, 8.5071e-03, 1.4916e-03, 2.5719e-07, 6.7989e-06, 5.8878e-04,\n",
      "        3.3035e-06, 4.7793e-04, 1.1796e-05, 8.6525e-03, 1.0963e-05, 2.6134e-04,\n",
      "        7.7333e-06, 4.4751e-04, 7.9347e-02, 2.2109e-03, 4.0434e-01, 4.3983e-01,\n",
      "        2.1720e-03, 1.6586e-08, 1.1135e+03, 4.4641e-07, 1.8224e-02, 3.3621e-03,\n",
      "        3.8146e-06, 1.5166e-07, 1.7443e-06, 1.5575e-07], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([9.5132e+00, 5.5032e+01, 7.2371e+01, 1.5681e+01, 7.2081e+00, 1.8879e-02,\n",
      "        2.2892e+01, 7.0255e+00, 3.4759e+01, 1.8548e+00, 2.3641e+01, 9.0476e+01,\n",
      "        1.1870e+01, 5.0955e+01, 4.7622e+01, 1.2667e+01, 3.5826e+01, 1.2791e+01,\n",
      "        7.3538e+01, 2.8329e+01, 9.9672e+01, 7.9469e-01, 3.0009e+01, 3.4488e+01,\n",
      "        8.2620e+01, 2.3026e+00, 9.0089e-02, 4.5202e+01, 1.7818e+00, 7.1365e+00,\n",
      "        3.5960e+01, 7.2864e+01, 2.8171e+01, 1.3346e+01, 2.9190e+00, 1.5179e+00,\n",
      "        9.7052e+00, 4.5834e+00, 1.5987e-01, 6.8321e+01, 2.4910e+01, 2.8059e-01,\n",
      "        3.2636e+01, 5.4509e-01, 1.9713e+01, 4.6563e+00, 2.0369e+01, 1.8008e+00,\n",
      "        2.3641e+01, 6.4651e-01, 1.9130e+01, 6.2949e-01, 3.6027e+01, 3.7044e+01,\n",
      "        6.0164e-01, 1.2115e+02, 1.9385e+02, 5.9510e+01, 8.4260e+00, 1.4703e+00,\n",
      "        3.1013e+01, 7.7332e+01, 4.0341e+01, 7.6865e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(31.0673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy_error= tensor([6.8147e-05, 2.9688e-05, 4.7684e-03, 7.4746e-07, 3.6036e-07, 3.2162e-02,\n",
      "        7.5218e-03, 1.4885e-07, 5.9807e-07, 1.3083e-03, 6.7968e-03, 2.5266e-03,\n",
      "        5.3275e-05, 2.0607e-02, 2.2300e-02, 1.9841e-02, 2.9077e-02, 5.0257e-03,\n",
      "        9.7098e-08, 8.8057e-07, 9.5009e-09, 3.0150e-02, 1.3787e+01, 1.4576e-05,\n",
      "        6.6372e-03, 6.9461e-04, 1.3441e-06, 3.3670e-06, 7.0308e-07, 8.1377e-06,\n",
      "        9.4693e-04, 9.8750e-04, 3.7478e-06, 2.2235e-02, 5.5703e-03, 5.6473e-01,\n",
      "        7.3655e-06, 8.5926e-05, 6.0505e-07, 1.2218e-06, 5.6189e-05, 4.1140e-04,\n",
      "        8.2620e-05, 1.4059e-06, 1.2729e-06, 8.0628e-03, 5.4470e-03, 2.6255e-03,\n",
      "        1.3035e-05, 7.0868e-06, 1.5274e-06, 1.2696e-02, 4.3842e-06, 8.3263e-07,\n",
      "        1.0699e-04, 7.6704e-03, 4.1300e-01, 2.3284e-03, 2.6032e-06, 1.5274e-06,\n",
      "        2.0618e-06, 8.0766e-03, 1.1001e-02, 2.9783e-06], device='cuda:0',\n",
      "       grad_fn=<AbsBackward0>)\n",
      "tensor([7.2151e+00, 1.2369e+01, 2.4399e+00, 5.1823e+01, 6.2860e+01, 1.2046e+01,\n",
      "        4.0715e+00, 7.7661e+01, 5.5083e+01, 7.2228e-02, 3.6728e+00, 8.5906e-01,\n",
      "        8.5983e+00, 9.1543e+00, 9.6384e+00, 8.9267e+00, 1.1357e+01, 2.6068e+00,\n",
      "        8.5374e+01, 4.9490e+01, 1.3373e+02, 1.1602e+01, 9.0849e+01, 1.7879e+01,\n",
      "        3.5823e+00, 1.3279e-01, 4.3719e+01, 3.2419e+01, 5.2708e+01, 2.3148e+01,\n",
      "        2.9736e-03, 1.5816e-04, 3.1210e+01, 9.6203e+00, 2.9496e+00, 4.0149e+01,\n",
      "        2.4117e+01, 6.0234e+00, 5.4911e+01, 4.4990e+01, 8.2888e+00, 7.8886e-01,\n",
      "        6.2176e+00, 4.3127e+01, 4.4441e+01, 4.3566e+00, 2.8732e+00, 9.3173e-01,\n",
      "        1.8837e+01, 2.4498e+01, 4.2044e+01, 6.4582e+00, 2.9482e+01, 5.0281e+01,\n",
      "        4.9952e+00, 4.1509e+00, 3.6282e+01, 7.1435e-01, 3.5415e+01, 4.2044e+01,\n",
      "        3.8244e+01, 4.3638e+00, 5.7505e+00, 3.3830e+01], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n",
      "tensor(24.8043, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 45\u001b[0m\n\u001b[1;32m     39\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epoch0, num_epochs):\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m \n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m#train_loss, train_energy = \\\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m#    train_one_epoch(model, optimizer, criterion, train_loader, input_mask, weights, device)\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m     train_res \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch_deepspeed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_engine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m#test_loss, energy_error, energy_error_std, energy_error_fiducial, energy_error_fiducial_std, energy_pred, energy_init, time_step, time_step_fiducial = \\\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m#    validate(model, criterion, test_loader, input_mask, weights, device)\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     val_res \u001b[38;5;241m=\u001b[39m validate_deepspeed(model_engine, criterion, test_loader, input_mask, weights, device)\n",
      "File \u001b[0;32m~/projects/AITimeStepper/jupyter_notebooks/../src/trainer.py:24\u001b[0m, in \u001b[0;36mtrain_one_epoch_deepspeed\u001b[0;34m(model_engine, optimizer, criterion, train_loader, input_mask, weights, device)\u001b[0m\n\u001b[1;32m     20\u001b[0m loss, loss_terms \u001b[38;5;241m=\u001b[39m criterion(model_engine, output, X, weights)  \u001b[38;5;66;03m# Compute loss between output and input\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#loss.backward(retain_graph=True)               # Backpropagation\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#loss.backward()               # Backpropagation\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#optimizer.step()              # Update parameters\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[43mmodel_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m model_engine\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     28\u001b[0m dt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m10\u001b[39m, output[:,\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/pyenv/torch/lib/python3.10/site-packages/deepspeed/utils/nvtx.py:18\u001b[0m, in \u001b[0;36minstrument_w_nvtx.<locals>.wrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m enable_nvtx:\n\u001b[1;32m     17\u001b[0m     get_accelerator()\u001b[38;5;241m.\u001b[39mrange_push(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m ret_val \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m enable_nvtx:\n\u001b[1;32m     20\u001b[0m     get_accelerator()\u001b[38;5;241m.\u001b[39mrange_pop()\n",
      "File \u001b[0;32m~/pyenv/torch/lib/python3.10/site-packages/deepspeed/runtime/engine.py:2126\u001b[0m, in \u001b[0;36mDeepSpeedEngine.backward\u001b[0;34m(self, loss, release_loss, retain_graph, scale_wrt_gas)\u001b[0m\n\u001b[1;32m   2124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzero_optimization():\n\u001b[1;32m   2125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mis_gradient_accumulation_boundary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_gradient_accumulation_boundary()\n\u001b[0;32m-> 2126\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2127\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamp_enabled():\n\u001b[1;32m   2128\u001b[0m     \u001b[38;5;66;03m# AMP requires delaying unscale when inside gradient accumulation boundaries\u001b[39;00m\n\u001b[1;32m   2129\u001b[0m     \u001b[38;5;66;03m# https://nvidia.github.io/apex/advanced.html#gradient-accumulation-across-iterations\u001b[39;00m\n\u001b[1;32m   2130\u001b[0m     delay_unscale \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_gradient_accumulation_boundary()\n",
      "File \u001b[0;32m~/pyenv/torch/lib/python3.10/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:2067\u001b[0m, in \u001b[0;36mDeepSpeedZeroOptimizer.backward\u001b[0;34m(self, loss, retain_graph)\u001b[0m\n\u001b[1;32m   2065\u001b[0m     scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   2066\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2067\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_scaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2069\u001b[0m \u001b[38;5;66;03m# Only for Stage 1, Mode 2\u001b[39;00m\n\u001b[1;32m   2070\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_grad_accum_attribute:\n",
      "File \u001b[0;32m~/pyenv/torch/lib/python3.10/site-packages/deepspeed/runtime/fp16/loss_scaler.py:63\u001b[0m, in \u001b[0;36mLossScalerBase.backward\u001b[0;34m(self, loss, retain_graph)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(\u001b[38;5;28mself\u001b[39m, loss, retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     62\u001b[0m     scaled_loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_scale\n\u001b[0;32m---> 63\u001b[0m     \u001b[43mscaled_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import structures\n",
    "importlib.reload(structures)\n",
    "from structures import *\n",
    "import losses\n",
    "importlib.reload(losses)\n",
    "from losses import *\n",
    "import trainer\n",
    "importlib.reload(trainer)\n",
    "from trainer import *\n",
    "\n",
    "ds_config = {\n",
    "    \"train_batch_size\": batch_size,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"Adam\",\n",
    "        \"params\": {\"lr\": 1e-5, \"betas\": [0.9, 0.999], \"eps\": 1e-8}\n",
    "    },\n",
    "    \"fp32\": {\n",
    "        \"enabled\": True  # Enables mixed precision training\n",
    "    },\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 1  # Enable ZeRO Stage 1 for memory optimization\n",
    "    }\n",
    "}\n",
    "\n",
    "model_engine, optimizer, _, _ = deepspeed.initialize(\n",
    "    model=model,\n",
    "    model_parameters=model.parameters(),\n",
    "    config=ds_config\n",
    ")\n",
    "\n",
    "reset = True\n",
    "if reset:\n",
    "    lists = {\"training_loss\":[], \"val_loss\":[], \"training_energy\":[], \"val_energy\":[], \"training_time_step\":[], \"val_time_step\":[]}\n",
    "    epoch0= 0\n",
    "else:\n",
    "    epoch0= epoch\n",
    "# Training routine\n",
    "num_epochs = 1000\n",
    "for epoch in range(epoch0, num_epochs):\n",
    "\n",
    "\n",
    "    #train_loss, train_energy = \\\n",
    "    #    train_one_epoch(model, optimizer, criterion, train_loader, input_mask, weights, device)\n",
    "    train_res = train_one_epoch_deepspeed(model_engine, optimizer, criterion, train_loader, input_mask, weights, device)\n",
    "        \n",
    "    #test_loss, energy_error, energy_error_std, energy_error_fiducial, energy_error_fiducial_std, energy_pred, energy_init, time_step, time_step_fiducial = \\\n",
    "    #    validate(model, criterion, test_loader, input_mask, weights, device)\n",
    "    val_res = validate_deepspeed(model_engine, criterion, test_loader, input_mask, weights, device)\n",
    "\n",
    "    lists[\"training_loss\"].append(train_res[\"train_loss\"])\n",
    "    lists[\"training_energy\"].append(train_res[\"energy_error\"])\n",
    "    lists[\"training_time_step\"].append(train_res[\"time_step\"])\n",
    "\n",
    "    lists[\"val_loss\"].append(val_res[\"val_loss\"])\n",
    "    lists[\"val_energy\"].append(val_res[\"energy_error\"])\n",
    "    lists[\"val_time_step\"].append(val_res[\"time_step\"])\n",
    "\n",
    "    if epoch > 5:\n",
    "        # Save the best model based on validation loss\n",
    "        if val_res['val_loss'] < best_val_loss:\n",
    "            best_val_loss = val_res['val_loss']\n",
    "            torch.save(model.state_dict(), best_val_path)\n",
    "            #traced_model = torch.jit.trace(model, example_input)\n",
    "            traced_model = torch.jit.script(model)\n",
    "            traced_model.save(base_path + f\"c++/best_model_loss.pt\")\n",
    "            print(f\"--> Best model saved at epoch {epoch} with val loss {best_val_loss:.4e}\")\n",
    "        \n",
    "        # Save the best model based on validation largest timestep\n",
    "        if val_res['time_step'] > best_largest_timestep:\n",
    "            best_largest_timestep = val_res['time_step']\n",
    "            torch.save(model.state_dict(), best_timestep_path)\n",
    "            #traced_model = torch.jit.trace(model, example_input)\n",
    "            traced_model = torch.jit.script(model)\n",
    "            traced_model.save(base_path + f\"c++/best_model_timestep.pt\")\n",
    "            print(f\"--> Best model saved at epoch {epoch} with largest timestep {best_largest_timestep:.4e}\")\n",
    "\n",
    "    # Save the last model after every epoch (or just once at the end)\n",
    "    torch.save(model.state_dict(), base_path + f\"model_{epoch}.pth\")\n",
    "    #traced_model = torch.jit.trace(model, example_input)\n",
    "    traced_model = torch.jit.script(model)\n",
    "    traced_model.save(base_path + f\"c++/model_{epoch}.pt\")\n",
    "\n",
    "\n",
    "\n",
    "    fig, axes = pu.generateAxesForMultiplePlots(shape=(1,3),figsize=(10,10),hspace=0.1,wspace=0.1,\n",
    "                                    gridspec=None)\n",
    "    for i, (key, value) in enumerate(lists.items()):\n",
    "        y = i//2\n",
    "        axes[y].plot(range(epoch+1), value, label=key)\n",
    "        axes[y].scatter(range(epoch+1), value)\n",
    "    \n",
    "    axes[0].set_yscale(\"log\")\n",
    "    axes[2].set_yscale(\"log\")\n",
    "\n",
    "    axes[0].grid()\n",
    "    axes[1].grid()\n",
    "    axes[2].grid()\n",
    "\n",
    "\n",
    "    axes[2].axhline(y=val_res['time_step_fiducial'], c='r',alpha=0.5,zorder=-1,label=\"Timestep Fiducial\")\n",
    "    axes[1].axhline(y=np.log10(TargetEnergyError), c='r',alpha=0.5,zorder=-1,label=\"Target energy\")\n",
    "    #plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left', borderaxespad=0.)\n",
    "    axes[0].legend()\n",
    "    axes[1].legend()\n",
    "    axes[2].legend()\n",
    "    #plt.tight_layout()\n",
    "    axes[0].set_ylabel(\"Loss\")\n",
    "    axes[1].set_ylabel(\"log(Relative Error of Energy)\")\n",
    "    axes[2].set_ylabel(\"Timestep\")\n",
    "    axes[2].set_xlabel(\"epoch\")\n",
    "    plt.savefig(\"learning_curve_re.png\",dpi=100)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    fig, axes = pu.generateAxesForMultiplePlots(shape=(1,2),figsize=(10,15),hspace=0.1,wspace=0.1,\n",
    "                                    gridspec=None)\n",
    "    # Get one batch from the validation loader\n",
    "    dataiter = iter(train_loader)\n",
    "    inputs, = next(dataiter)\n",
    "\n",
    "    # Determine how many samples to take (if batch size < 50, take the whole batch)\n",
    "    num_samples = min(50, batch_size)\n",
    "\n",
    "    # Randomly select indices from the batch\n",
    "    indices = random.sample(range(batch_size), num_samples)\n",
    "    sampled_inputs = inputs[:,input_mask][indices]\n",
    "    sampled_targets = inputs[indices,25]\n",
    "\n",
    "    # Compute model predictions with no gradient computation\n",
    "    with torch.no_grad():\n",
    "        sampled_predictions = model(sampled_inputs)\n",
    "\n",
    "    # Convert tensors to numpy arrays for plotting\n",
    "    sampled_predictions = sampled_predictions[:,0].cpu().numpy().flatten()\n",
    "    sampled_targets = sampled_targets.cpu().numpy().flatten()\n",
    "\n",
    "    # Create sample indices for the x-axis (1st sample, 2nd sample, etc.)\n",
    "    sample_indices = list(range(1, num_samples + 1))\n",
    "\n",
    "    # Plot predictions and ground truth vs sample number\n",
    "    # plt.figure(figsize=(8, 6))\n",
    "    # Add vertical lines for each data point\n",
    "    for x in sample_indices:\n",
    "        axes[0].axvline(x=x, color='grey', linestyle='-', alpha=0.2,zorder=0)\n",
    "    axes[0].scatter(sample_indices, sampled_targets, marker='o', label='Ground Truth', fc=\"none\", ec=\"k\",zorder=10)\n",
    "    axes[0].scatter(sample_indices, np.power(10,sampled_predictions), marker='s', label='Predictions', fc=\"none\",ec=\"r\" ,zorder=10)\n",
    "    axes[0].set_yscale(\"log\")\n",
    "    axes[0].set_xlabel('Sample Number')\n",
    "    axes[0].set_ylabel('Value')\n",
    "\n",
    "    # Get one batch from the validation loader\n",
    "    dataiter = iter(test_loader)\n",
    "    inputs, = next(dataiter)\n",
    "\n",
    "    # Determine how many samples to take (if batch size < 50, take the whole batch)\n",
    "    num_samples = min(50, batch_size)\n",
    "\n",
    "    # Randomly select indices from the batch\n",
    "    indices = random.sample(range(batch_size), num_samples)\n",
    "    sampled_inputs = inputs[:,input_mask][indices]\n",
    "    sampled_targets = inputs[indices,25]\n",
    "\n",
    "    # Compute model predictions with no gradient computation\n",
    "    with torch.no_grad():\n",
    "        sampled_predictions = model(sampled_inputs)\n",
    "\n",
    "    # Convert tensors to numpy arrays for plotting\n",
    "    sampled_predictions = sampled_predictions[:,0].cpu().numpy().flatten()\n",
    "    sampled_targets = sampled_targets.cpu().numpy().flatten()\n",
    "\n",
    "    # Create sample indices for the x-axis (1st sample, 2nd sample, etc.)\n",
    "    sample_indices = list(range(1, num_samples + 1))\n",
    "\n",
    "    # Plot predictions and ground truth vs sample number\n",
    "    # plt.figure(figsize=(8, 6))\n",
    "    # Add vertical lines for each data point\n",
    "    for x in sample_indices:\n",
    "        axes[1].axvline(x=x, color='grey', linestyle='-', alpha=0.2,zorder=0)\n",
    "    axes[1].scatter(sample_indices, sampled_targets, marker='o', label='Ground Truth', fc=\"none\", ec=\"k\",zorder=10)\n",
    "    axes[1].scatter(sample_indices, np.power(10,sampled_predictions), marker='s', label='Predictions', fc=\"none\",ec=\"r\" ,zorder=10)\n",
    "    axes[1].set_yscale(\"log\")\n",
    "    axes[1].set_xlabel('Sample Number')\n",
    "    axes[1].set_ylabel('Value')\n",
    "\n",
    "    axes[0].set_title(f'Epoch [{epoch}/{num_epochs}] Predictions and Ground Truth vs. Sample Number')\n",
    "    #plt.legend()\n",
    "    axes[0].grid()\n",
    "    axes[1].grid()\n",
    "    plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left', borderaxespad=0.)\n",
    "    plt.savefig(\"samples.png\")\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Epoch [{epoch}/{num_epochs}], Timestep error: {train_res['time_step_relative_error']:.4e}/{val_res['time_step_relative_error']:.4e}, Energy Loss: {np.log10(train_res['energy_error']):.4e}/{np.log10(train_res['energy_error_fiducial']):.4e}, {np.log10(val_res['energy_error']):.4e}/{np.log10(val_res['energy_error_fiducial']):.4e}, Time step: {train_res['time_step']:.4e}/{train_res['time_step_fiducial']:.4e}, {val_res['time_step']:.4e}/{val_res['time_step_fiducial']:.4e}, {val_res['time_step_std']:.4e}/{val_res['time_step_fiducial_std']:.4e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Gen with magnitude of velocities and acceleration (Suspended)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### second gen is suspended because total energy is a function of each component of velocities and accelerations, unable to be written in a form of magnitudes of velocities and acceleration (it is techinically possible but not preferable neither in most cases nor in general)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from src.trainer import num_samples\n",
    "\n",
    "# Example unsupervised data: 100 samples with 10 features each\n",
    "data = np.load(\"../data/two_body_train_data.npy\")\n",
    "num_samples = data.shape[0]\n",
    "num_samples_start = int(data.shape[0]*0.9)\n",
    "#num_samples_start = 0\n",
    "num_samples_end   = data.shape[0]\n",
    "num_samples = num_samples_end - num_samples_start\n",
    "num_features = data.shape[1]\n",
    "\n",
    "# data should contain [N, pos(2) vel(2) acc(2,4) mass(1) pos(2) vel(2) acc(2,4) mass(1) energy error(1) total energy (1) dt(1)]\n",
    "# new data is rearranged to [N, mag vel(1), mag acc(4), mass(1), pos(2), vel(2), acc(2,4), mass(1), pos(2), vel(2), acc(2,4), energy error(1), total energy(1), dt(1)]\n",
    "data_org = torch.zeros((num_samples,num_features+5), dtype=torch.double).to(device)\n",
    "\n",
    "\n",
    "# Create a tensor of features only\n",
    "data_org = torch.tensor(data[num_samples_start:num_samples_end,:], dtype=torch.double).to(device)\n",
    "data = data_org.clone()\n",
    "\n",
    "\n",
    "# Normalize the data\n",
    "data_min = data_org[:,:26].min(axis=0, keepdim=True).values\n",
    "data_max = data_org[:,:26].max(axis=0, keepdim=True).values\n",
    "data[:,:26] = (data_org[:,:26] - data_min) / (data_max - data_min)\n",
    "\n",
    "# Wrap the feature tensor in a TensorDataset\n",
    "# Each item from the dataset will be a tuple containing one tensor (X[i],)\n",
    "dataset = TensorDataset(data)\n",
    "\n",
    "# Define the proportion for the test set (e.g., 20%)\n",
    "test_ratio = 0.2\n",
    "num_test = int(num_samples * test_ratio)\n",
    "num_train = num_samples - num_test\n",
    "\n",
    "# Use random_split to split the dataset into train and test subsets\n",
    "train_dataset, test_dataset = random_split(dataset, [num_train, num_test])\n",
    "\n",
    "# Create DataLoaders for the training and testing datasets\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import structures\n",
    "importlib.reload(structures)\n",
    "from structures import *\n",
    "import losses\n",
    "importlib.reload(losses)\n",
    "from losses import *\n",
    "import trainer\n",
    "importlib.reload(trainer)\n",
    "from trainer import *\n",
    "\n",
    "\n",
    "input_dim = 13     # Number of input features\n",
    "hidden_dims = [64,64]     # Number of hidden neurons\n",
    "output_dim = 2     # Number of output \n",
    "TargetEnergyError = 1e-5\n",
    "nParticle = 2\n",
    "nAttribute = 13\n",
    "\n",
    "# Instantiate the model\n",
    "try: \n",
    "    del model\n",
    "    print(\"model deleted\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "#model = SimpleNN(input_dim, hidden_size, output_dim).to(device)\n",
    "model = FullyConnectedNN(input_dim=input_dim, output_dim=output_dim, hidden_dims=hidden_dims, activation='relu', dropout=0.0, output_positive=True).to(device)\n",
    "\n",
    "\n",
    "# Define the loss function (CrossEntropyLoss is common for classification tasks)\n",
    "criterion = CustomizableLoss(nParticle=nParticle, nAttribute=nAttribute, nBatch=batch_size,alpha=0.1, beta=0.1, gamma=10.0, TargetEnergyError=TargetEnergyError,\n",
    "                            data_min=data_min, data_max=data_max,device=device)\n",
    "\n",
    "# Define the optimizer (Stochastic Gradient Descent in this example)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Paths to save best and last models\n",
    "base_path = \"/mnt/home/yjo10/projects/AITimeStepper/data/models/two_body_2G/\"\n",
    "best_val_path = base_path + \"best_model_loss.pth\"\n",
    "best_timestep_path = base_path + \"best_model_timestep.pth\"\n",
    "#last_model_path = base_path + f\"last_model_{epoch}.pth\"\n",
    "best_val_loss = float(\"inf\")\n",
    "best_largest_timestep = 0\n",
    "\n",
    "example_input = torch.randn(1, input_dim).to(device)\n",
    "\n",
    "# Training routine\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    train_loss = \\\n",
    "        train_one_epoch(model, optimizer, criterion, train_loader, input_dim, device)\n",
    "    test_loss, energy_error, energy_error_fiducial, time_step, time_step_fiducial = \\\n",
    "        validate(model, criterion, test_loader, input_dim, device)\n",
    "\n",
    "    if epoch > 5:\n",
    "        # Save the best model based on validation loss\n",
    "        if test_loss < best_val_loss:\n",
    "            best_val_loss = test_loss\n",
    "            torch.save(model.state_dict(), best_val_path)\n",
    "            traced_model = torch.jit.trace(model, example_input)\n",
    "            traced_model.save(base_path + f\"c++/best_model_loss.pt\")\n",
    "            print(f\"--> Best model saved at epoch {epoch} with val loss {best_val_loss:.4e}\")\n",
    "        \n",
    "        # Save the best model based on validation largest timestep\n",
    "        if time_step > best_largest_timestep:\n",
    "            best_largest_timestep = time_step\n",
    "            torch.save(model.state_dict(), best_timestep_path)\n",
    "            traced_model = torch.jit.trace(model, example_input)\n",
    "            traced_model.save(base_path + f\"c++/best_model_timestep.pt\")\n",
    "            print(f\"--> Best model saved at epoch {epoch} with largest timestep {best_largest_timestep:.4e}\")\n",
    "\n",
    "    # Save the last model after every epoch (or just once at the end)\n",
    "    torch.save(model.state_dict(), base_path + f\"model_{epoch}.pth\")\n",
    "    traced_model = torch.jit.trace(model, example_input)\n",
    "    traced_model.save(base_path + f\"c++/model_{epoch}.pt\")\n",
    "\n",
    "    print(f\"Epoch [{epoch}/{num_epochs}], Train Loss: {train_loss:.4e}, Test Loss: {test_loss:.4e}, Energy Loss: {energy_error:.4e}/{energy_error_fiducial:.4e}, Time step: {time_step:.4e}/{time_step_fiducial:.4e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Three Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7793, 62])\n"
     ]
    }
   ],
   "source": [
    "#from src.trainer import num_samples\n",
    "\n",
    "# Example unsupervised data: 100 samples with 10 features each\n",
    "data = np.load(\"../data/three_body_train_data.npy\")\n",
    "num_samples = data.shape[0]\n",
    "num_samples_start = int(data.shape[0]*0.9)\n",
    "#num_samples_start = 0\n",
    "num_samples_end   = data.shape[0]\n",
    "num_samples = num_samples_end - num_samples_start\n",
    "num_features = data.shape[1]\n",
    "\n",
    "# Create a tensor of features only\n",
    "data_org = torch.tensor(data[num_samples_start:num_samples_end,:], dtype=torch.double).to(device)\n",
    "data = data_org.clone()\n",
    "\n",
    "\n",
    "\n",
    "# Normalize the data\n",
    "#index = np.r_[:19,20:39,40:59] # this is for three particles\n",
    "#index = np.r_[:19,20:39,40:59] # this is for three particles\n",
    "index = [19,39,59,60,61] # the features that must not be normalized\n",
    "data_min = data_org.min(axis=0, keepdim=True).values\n",
    "data_max = data_org.max(axis=0, keepdim=True).values\n",
    "data_min[0,index] = 0\n",
    "data_max[0,index] = 1\n",
    "data = (data_org - data_min) / (data_max - data_min)\n",
    "\n",
    "# Wrap the feature tensor in a TensorDataset\n",
    "# Each item from the dataset will be a tuple containing one tensor (X[i],)\n",
    "dataset = TensorDataset(data)\n",
    "\n",
    "# Define the proportion for the test set (e.g., 20%)\n",
    "test_ratio = 0.2\n",
    "num_test = int(num_samples * test_ratio)\n",
    "num_train = num_samples - num_test\n",
    "\n",
    "# Use random_split to split the dataset into train and test subsets\n",
    "train_dataset, test_dataset = random_split(dataset, [num_train, num_test])\n",
    "\n",
    "# Create DataLoaders for the training and testing datasets\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kin= tensor([7.3576e+13, 7.3576e+13, 7.3576e+13, 3.9447e+13, 3.9447e+13, 3.9447e+13,\n",
      "        6.7117e+13, 6.7117e+13, 6.7117e+13, 3.4046e+14], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n",
      "pot= tensor([-3.0354e+15, -3.0354e+15, -3.0354e+15, -3.0015e+15, -3.0015e+15,\n",
      "        -3.0015e+15, -3.0289e+15, -3.0289e+15, -3.0289e+15, -3.3026e+15],\n",
      "       device='cuda:0', grad_fn=<SubBackward0>)\n",
      "init0= tensor([-2.9619e+15, -2.9619e+15, -2.9619e+15, -2.9620e+15, -2.9620e+15,\n",
      "        -2.9620e+15, -2.9618e+15, -2.9618e+15, -2.9618e+15, -2.9622e+15],\n",
      "       device='cuda:0') \n",
      "init1= tensor([-2.9619e+15, -2.9619e+15, -2.9619e+15, -2.9620e+15, -2.9620e+15,\n",
      "        -2.9620e+15, -2.9618e+15, -2.9618e+15, -2.9618e+15, -2.9622e+15],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "diff= tensor([-0.5000, -0.5000, -0.5000,  0.5000,  0.5000,  0.5000,  0.5000,  1.0000,\n",
      "         0.5000, -1.5000], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "kin= tensor([ 348016.2793,  348016.2793,  348016.2793,  206479.9556,  206479.9556,\n",
      "         206479.9556,  286812.2205,  286812.2205,  286812.2205, 1399034.8429],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pot= tensor([0.0606, 0.0606, 0.0606, 0.0648, 0.0648, 0.0648, 0.0681, 0.0681, 0.0681,\n",
      "        0.0721], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "pred= tensor([ 348016.3399,  348016.3399,  348016.3399,  206480.0204,  206480.0204,\n",
      "         206480.0204,  286812.2886,  286812.2886,  286812.2886, 1399034.9150],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>) \n",
      "diff= tensor([2.9619e+15, 2.9619e+15, 2.9619e+15, 2.9620e+15, 2.9620e+15, 2.9620e+15,\n",
      "        2.9618e+15, 2.9618e+15, 2.9618e+15, 2.9622e+15], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([6.2572e-05, 6.2572e-05, 6.2572e-05, 9.6054e-05, 9.6054e-05, 9.6054e-05,\n",
       "         1.4517e-04, 1.4517e-04, 1.4517e-04, 4.0750e-05], device='cuda:0'),\n",
       " tensor([-2.9619e+15, -2.9619e+15, -2.9619e+15, -2.9620e+15, -2.9620e+15,\n",
       "         -2.9620e+15, -2.9618e+15, -2.9618e+15, -2.9618e+15, -2.9622e+15],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import structures\n",
    "importlib.reload(structures)\n",
    "from structures import *\n",
    "import losses\n",
    "importlib.reload(losses)\n",
    "from losses import *\n",
    "TargetEnergyError = 1e-5\n",
    "batch_size = 32\n",
    "criterion = CustomizableLoss3D(nParticle=3, nAttribute=20, nBatch=batch_size,alpha=0.1, beta=0.1, gamma=10.0, TargetEnergyError=TargetEnergyError,\n",
    "                            data_min=data_min, data_max=data_max,device=device)\n",
    "X = data[0:10,:]\n",
    "output = torch.zeros((X.shape[0],2)).to(device)\n",
    "loss, loss_terms = criterion(output, X)\n",
    "X[:,-2], X[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model deleted\n",
      "Epoch [0/1000], Train Loss: 2.0895e+120, Test Loss: 7.8070e+77, Energy Loss: 7.0442e+21/1.8740e-01, energy_pred: -1.6958e+38/-3.3775e+16, Time step: 4.2222e-04/5.6198e-08\n",
      "Epoch [1/1000], Train Loss: 8.8817e+78, Test Loss: 3.9814e+79, Energy Loss: 5.1009e+22/1.8740e-01, energy_pred: -1.2275e+39/-3.3775e+16, Time step: 5.6410e-04/5.6198e-08\n",
      "Epoch [2/1000], Train Loss: 3.5948e+80, Test Loss: 1.7811e+81, Energy Loss: 3.4587e+23/1.8740e-01, energy_pred: -8.3154e+39/-3.3775e+16, Time step: 7.4651e-04/5.6198e-08\n",
      "Epoch [3/1000], Train Loss: 1.8261e+82, Test Loss: 6.7488e+82, Energy Loss: 2.1677e+24/1.8740e-01, energy_pred: -5.1995e+40/-3.3775e+16, Time step: 9.7750e-04/5.6198e-08\n",
      "Epoch [4/1000], Train Loss: 5.7342e+83, Test Loss: 2.1832e+84, Energy Loss: 1.2611e+25/1.8740e-01, energy_pred: -3.0146e+41/-3.3775e+16, Time step: 1.2670e-03/5.6198e-08\n",
      "Epoch [5/1000], Train Loss: 1.6567e+85, Test Loss: 6.2409e+85, Energy Loss: 6.8746e+25/1.8740e-01, energy_pred: -1.6372e+42/-3.3775e+16, Time step: 1.6262e-03/5.6198e-08\n",
      "--> Best model saved at epoch 6 with val loss 1.5864e+87\n",
      "--> Best model saved at epoch 6 with largest timestep 2.0678e-03\n",
      "Epoch [6/1000], Train Loss: 5.3251e+86, Test Loss: 1.5864e+87, Energy Loss: 3.5219e+26/1.8740e-01, energy_pred: -8.3560e+42/-3.3775e+16, Time step: 2.0678e-03/5.6198e-08\n",
      "--> Best model saved at epoch 7 with largest timestep 2.6055e-03\n",
      "Epoch [7/1000], Train Loss: 1.2560e+88, Test Loss: 3.5741e+88, Energy Loss: 1.6957e+27/1.8740e-01, energy_pred: -4.0062e+43/-3.3775e+16, Time step: 2.6055e-03/5.6198e-08\n",
      "--> Best model saved at epoch 8 with largest timestep 3.2545e-03\n",
      "Epoch [8/1000], Train Loss: 2.5435e+89, Test Loss: 7.1980e+89, Energy Loss: 7.7027e+27/1.8740e-01, energy_pred: -1.8120e+44/-3.3775e+16, Time step: 3.2545e-03/5.6198e-08\n",
      "--> Best model saved at epoch 9 with largest timestep 4.0311e-03\n",
      "Epoch [9/1000], Train Loss: 5.0112e+90, Test Loss: 1.3027e+91, Energy Loss: 3.3097e+28/1.8740e-01, energy_pred: -7.7523e+44/-3.3775e+16, Time step: 4.0311e-03/5.6198e-08\n",
      "--> Best model saved at epoch 10 with largest timestep 4.9526e-03\n",
      "Epoch [10/1000], Train Loss: 8.5069e+91, Test Loss: 2.1249e+92, Energy Loss: 1.3477e+29/1.8740e-01, energy_pred: -3.1434e+45/-3.3775e+16, Time step: 4.9526e-03/5.6198e-08\n",
      "--> Best model saved at epoch 11 with largest timestep 6.0374e-03\n",
      "Epoch [11/1000], Train Loss: 1.3487e+93, Test Loss: 3.1313e+93, Energy Loss: 5.2099e+29/1.8740e-01, energy_pred: -1.2100e+46/-3.3775e+16, Time step: 6.0374e-03/5.6198e-08\n",
      "--> Best model saved at epoch 12 with largest timestep 7.3037e-03\n",
      "Epoch [12/1000], Train Loss: 1.7662e+94, Test Loss: 4.1736e+94, Energy Loss: 1.9136e+30/1.8740e-01, energy_pred: -4.4253e+46/-3.3775e+16, Time step: 7.3037e-03/5.6198e-08\n",
      "--> Best model saved at epoch 13 with largest timestep 8.7599e-03\n",
      "Epoch [13/1000], Train Loss: 2.2858e+95, Test Loss: 4.9943e+95, Energy Loss: 6.6491e+30/1.8740e-01, energy_pred: -1.5326e+47/-3.3775e+16, Time step: 8.7599e-03/5.6198e-08\n",
      "--> Best model saved at epoch 14 with largest timestep 1.0202e-02\n",
      "Epoch [14/1000], Train Loss: 2.3122e+96, Test Loss: 4.4827e+96, Energy Loss: 1.9505e+31/1.8740e-01, energy_pred: -4.5671e+47/-3.3775e+16, Time step: 1.0202e-02/5.6198e-08\n",
      "Epoch [15/1000], Train Loss: 1.1460e+97, Test Loss: 1.9046e+97, Energy Loss: 2.6398e+31/1.8740e-01, energy_pred: -7.1686e+47/-3.3775e+16, Time step: 9.9979e-03/5.6198e-08\n",
      "--> Best model saved at epoch 16 with val loss 9.7000e+45\n",
      "Epoch [16/1000], Train Loss: 2.5294e+97, Test Loss: 9.7000e+45, Energy Loss: 2.0580e+05/1.8740e-01, energy_pred: -7.2264e+21/-3.3775e+16, Time step: 7.9094e-07/5.6198e-08\n",
      "Epoch [17/1000], Train Loss: 1.1417e+47, Test Loss: 2.2178e+47, Energy Loss: 9.9160e+05/1.8740e-01, energy_pred: -3.4799e+22/-3.3775e+16, Time step: 1.0059e-06/5.6198e-08\n",
      "Epoch [18/1000], Train Loss: 5.1004e+49, Test Loss: 1.4267e+50, Energy Loss: 2.5551e+07/1.8740e-01, energy_pred: -8.9531e+23/-3.3775e+16, Time step: 1.6531e-06/5.6198e-08\n",
      "Epoch [19/1000], Train Loss: 4.4495e+52, Test Loss: 7.2001e+52, Energy Loss: 5.8335e+08/1.8740e-01, energy_pred: -2.0404e+25/-3.3775e+16, Time step: 2.6692e-06/5.6198e-08\n",
      "Epoch [20/1000], Train Loss: 2.4185e+55, Test Loss: 2.8781e+55, Energy Loss: 1.1857e+10/1.8740e-01, energy_pred: -4.1392e+26/-3.3775e+16, Time step: 4.2366e-06/5.6198e-08\n",
      "Epoch [21/1000], Train Loss: 4.3686e+57, Test Loss: 9.1949e+57, Energy Loss: 2.1556e+11/1.8740e-01, energy_pred: -7.5086e+27/-3.3775e+16, Time step: 6.6145e-06/5.6198e-08\n",
      "Epoch [22/1000], Train Loss: 4.3086e+59, Test Loss: 2.3682e+60, Energy Loss: 3.5199e+12/1.8740e-01, energy_pred: -1.2232e+29/-3.3775e+16, Time step: 1.0164e-05/5.6198e-08\n",
      "Epoch [23/1000], Train Loss: 1.4817e+62, Test Loss: 4.9577e+62, Energy Loss: 5.1840e+13/1.8740e-01, energy_pred: -1.7970e+30/-3.3775e+16, Time step: 1.5381e-05/5.6198e-08\n",
      "Epoch [24/1000], Train Loss: 4.7434e+64, Test Loss: 8.5023e+64, Energy Loss: 6.9134e+14/1.8740e-01, energy_pred: -2.3901e+31/-3.3775e+16, Time step: 2.2935e-05/5.6198e-08\n",
      "Epoch [25/1000], Train Loss: 3.2736e+66, Test Loss: 1.2035e+67, Energy Loss: 8.3801e+15/1.8740e-01, energy_pred: -2.8888e+32/-3.3775e+16, Time step: 3.3712e-05/5.6198e-08\n",
      "Epoch [26/1000], Train Loss: 2.9982e+68, Test Loss: 1.4090e+69, Energy Loss: 9.2415e+16/1.8740e-01, energy_pred: -3.1761e+33/-3.3775e+16, Time step: 4.8851e-05/5.6198e-08\n",
      "Epoch [27/1000], Train Loss: 4.5741e+70, Test Loss: 6.0005e+70, Energy Loss: 6.0518e+17/1.8740e-01, energy_pred: -2.0869e+34/-3.3775e+16, Time step: 6.3973e-05/5.6198e-08\n",
      "Epoch [28/1000], Train Loss: 2.1372e+71, Test Loss: 7.1908e+70, Energy Loss: 6.3343e+17/1.8740e-01, energy_pred: -2.2324e+34/-3.3775e+16, Time step: 5.8838e-05/5.6198e-08\n",
      "Epoch [29/1000], Train Loss: 1.8543e+71, Test Loss: 5.1984e+70, Energy Loss: 5.1823e+17/1.8740e-01, energy_pred: -1.8588e+34/-3.3775e+16, Time step: 5.1842e-05/5.6198e-08\n",
      "Epoch [30/1000], Train Loss: 1.4982e+71, Test Loss: 7.6480e+70, Energy Loss: 6.1985e+17/1.8740e-01, energy_pred: -2.2383e+34/-3.3775e+16, Time step: 5.0776e-05/5.6198e-08\n",
      "Epoch [31/1000], Train Loss: 1.9296e+71, Test Loss: 3.1501e+70, Energy Loss: 3.9130e+17/1.8740e-01, energy_pred: -1.4219e+34/-3.3775e+16, Time step: 4.5003e-05/5.6198e-08\n",
      "Epoch [32/1000], Train Loss: 1.0084e+71, Test Loss: 1.3742e+71, Energy Loss: 8.0990e+17/1.8740e-01, energy_pred: -2.9575e+34/-3.3775e+16, Time step: 4.7611e-05/5.6198e-08\n",
      "Epoch [33/1000], Train Loss: 1.6845e+71, Test Loss: 4.1034e+70, Energy Loss: 4.3541e+17/1.8740e-01, energy_pred: -1.5981e+34/-3.3775e+16, Time step: 4.0699e-05/5.6198e-08\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 56\u001b[0m\n\u001b[1;32m     52\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     55\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m---> 56\u001b[0m         \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     test_loss, energy_error, energy_error_std, energy_error_fiducial, energy_error_fiducial_std, energy_pred, energy_init, time_step, time_step_fiducial \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m     58\u001b[0m         validate(model, criterion, test_loader, input_mask, device)\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m5\u001b[39m:\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;66;03m# Save the best model based on validation loss\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/AITimeStepper/jupyter_notebooks/../src/trainer.py:18\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, optimizer, criterion, train_loader, input_mask, device)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#print(output)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m loss, loss_terms \u001b[38;5;241m=\u001b[39m criterion(output, X)  \u001b[38;5;66;03m# Compute loss between output and input\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m               \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#loss.backward()               # Backpropagation\u001b[39;00m\n\u001b[1;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()              \u001b[38;5;66;03m# Update parameters\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import structures\n",
    "importlib.reload(structures)\n",
    "from structures import *\n",
    "import losses\n",
    "importlib.reload(losses)\n",
    "from losses import *\n",
    "import trainer\n",
    "importlib.reload(trainer)\n",
    "from trainer import *\n",
    "\n",
    "\n",
    "input_size = 16     # Number of input features\n",
    "input_mask = np.r_[0,4:19]\n",
    "hidden_dims = [32,64,32]     # Number of hidden neurons\n",
    "output_size = 2     # Number of output \n",
    "TargetEnergyError = 1e-5\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "try: \n",
    "    del model\n",
    "    print(\"model deleted\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "#model = SimpleNN(input_size, hidden_size, output_size).to(device)\n",
    "model = FullyConnectedNN(input_dim=input_size, output_dim=output_size, hidden_dims=hidden_dims, activation='relu', dropout=0.0, output_positive=True).to(device)\n",
    "\n",
    "\n",
    "# Define the loss function (CrossEntropyLoss is common for classification tasks)\n",
    "criterion = CustomizableLoss3D(nParticle=2, nAttribute=20, nBatch=batch_size,alpha=0.1, beta=1.0, gamma=1.0, TargetEnergyError=TargetEnergyError,\n",
    "                            data_min=data_min, data_max=data_max,device=device)\n",
    "\n",
    "# Define the optimizer (Stochastic Gradient Descent in this example)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "\n",
    "# Paths to save best and last models\n",
    "base_path = \"/mnt/home/yjo10/projects/AITimeStepper/data/models/three_body/\"\n",
    "best_val_path = base_path + \"best_model_loss.pth\"\n",
    "best_timestep_path = base_path + \"best_model_timestep.pth\"\n",
    "#last_model_path = base_path + f\"last_model_{epoch}.pth\"\n",
    "best_val_loss = float(\"inf\")\n",
    "best_largest_timestep = 0\n",
    "\n",
    "example_input = torch.randn(1, input_size).to(device)\n",
    "\n",
    "# Training routine\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    train_loss = \\\n",
    "        train_one_epoch(model, optimizer, criterion, train_loader, input_mask, device)\n",
    "    test_loss, energy_error, energy_error_std, energy_error_fiducial, energy_error_fiducial_std, energy_pred, energy_init, time_step, time_step_fiducial = \\\n",
    "        validate(model, criterion, test_loader, input_mask, device)\n",
    "\n",
    "    if epoch > 5:\n",
    "        # Save the best model based on validation loss\n",
    "        if test_loss < best_val_loss:\n",
    "            best_val_loss = test_loss\n",
    "            torch.save(model.state_dict(), best_val_path)\n",
    "            traced_model = torch.jit.trace(model, example_input)\n",
    "            traced_model.save(base_path + f\"c++/best_model_loss.pt\")\n",
    "            print(f\"--> Best model saved at epoch {epoch} with val loss {best_val_loss:.4e}\")\n",
    "        \n",
    "        # Save the best model based on validation largest timestep\n",
    "        if time_step > best_largest_timestep:\n",
    "            best_largest_timestep = time_step\n",
    "            torch.save(model.state_dict(), best_timestep_path)\n",
    "            traced_model = torch.jit.trace(model, example_input)\n",
    "            traced_model.save(base_path + f\"c++/best_model_timestep.pt\")\n",
    "            print(f\"--> Best model saved at epoch {epoch} with largest timestep {best_largest_timestep:.4e}\")\n",
    "\n",
    "    # Save the last model after every epoch (or just once at the end)\n",
    "    torch.save(model.state_dict(), base_path + f\"model_{epoch}.pth\")\n",
    "    traced_model = torch.jit.trace(model, example_input)\n",
    "    traced_model.save(base_path + f\"c++/model_{epoch}.pt\")\n",
    "\n",
    "    #print(f\"Epoch [{epoch}/{num_epochs}], Train Loss: {train_loss:.4e}, Test Loss: {test_loss:.4e}, Energy Loss: {energy_error:.4e}/{energy_error_fiducial:.4e}, std: {energy_error_std:.4e}/{energy_error_fiducial_std:.4e}, Time step: {time_step:.4e}/{time_step_fiducial:.4e}\")\n",
    "    print(f\"Epoch [{epoch}/{num_epochs}], Train Loss: {train_loss:.4e}, Test Loss: {test_loss:.4e}, Energy Loss: {energy_error:.4e}/{energy_error_fiducial:.4e}, energy_pred: {energy_pred:.4e}/{energy_init:.4e}, Time step: {time_step:.4e}/{time_step_fiducial:.4e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training routine\n",
    "num_epochs = 1000\n",
    "epoch0= epoch\n",
    "for epoch in range(epoch0, num_epochs):\n",
    "\n",
    "    train_loss = \\\n",
    "        train_one_epoch(model, optimizer, criterion, train_loader, input_mask, device)\n",
    "    test_loss, energy_error, energy_error_std, energy_error_fiducial, energy_error_fiducial_std, time_step, time_step_fiducial = \\\n",
    "        validate(model, criterion, test_loader, input_mask, device)\n",
    "\n",
    "    if epoch > 5:\n",
    "        # Save the best model based on validation loss\n",
    "        if test_loss < best_val_loss:\n",
    "            best_val_loss = test_loss\n",
    "            torch.save(model.state_dict(), best_val_path)\n",
    "            traced_model = torch.jit.trace(model, example_input)\n",
    "            traced_model.save(base_path + f\"c++/best_model_loss.pt\")\n",
    "            print(f\"--> Best model saved at epoch {epoch} with val loss {best_val_loss:.4e}\")\n",
    "        \n",
    "        # Save the best model based on validation largest timestep\n",
    "        if time_step > best_largest_timestep:\n",
    "            best_largest_timestep = time_step\n",
    "            torch.save(model.state_dict(), best_timestep_path)\n",
    "            traced_model = torch.jit.trace(model, example_input)\n",
    "            traced_model.save(base_path + f\"c++/best_model_timestep.pt\")\n",
    "            print(f\"--> Best model saved at epoch {epoch} with largest timestep {best_largest_timestep:.4e}\")\n",
    "\n",
    "    # Save the last model after every epoch (or just once at the end)\n",
    "    torch.save(model.state_dict(), base_path + f\"model_{epoch}.pth\")\n",
    "    traced_model = torch.jit.trace(model, example_input)\n",
    "    traced_model.save(base_path + f\"c++/model_{epoch}.pt\")\n",
    "\n",
    "    print(f\"Epoch [{epoch}/{num_epochs}], Train Loss: {train_loss:.4e}, Test Loss: {test_loss:.4e}, Energy Loss: {energy_error:.4e}/{energy_error_fiducial:.4e}, std: {energy_error_std:.4e}/{energy_error_fiducial_std:.4e}, Time step: {time_step:.4e}/{time_step_fiducial:.4e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 16     # Number of input features\n",
    "input_mask = np.r_[0,4:19]\n",
    "hidden_dims = [64,64]     # Number of hidden neurons\n",
    "output_size = 2     # Number of output \n",
    "TargetEnergyError = 1e-5\n",
    "\n",
    "base_path = \"/mnt/home/yjo10/projects/AITimeStepper/data/models/three_body/\"\n",
    "best_val_path = base_path + \"best_model_loss.pth\"\n",
    "best_timestep_path = base_path + \"best_model_timestep.pth\"\n",
    "epoch = 73\n",
    "model_path = f\"model_{epoch}.pth\"\n",
    "\n",
    "# Instantiate the model\n",
    "model = FullyConnectedNN(input_dim=input_size, output_dim=output_size, hidden_dims=hidden_dims, activation='relu', dropout=0.1, output_positive=True).to(device)\n",
    "\n",
    "# Load the state dictionary from a file\n",
    "state_dict = torch.load(base_path + model_path, map_location=torch.device('cpu'))\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# Set the model to evaluation mode (important for inference)\n",
    "model.eval()\n",
    "\n",
    "# Define the loss function (CrossEntropyLoss is common for classification tasks)\n",
    "criterion = CustomizableLoss3D(nParticle=2, nAttribute=20, nBatch=batch_size,alpha=0.1, beta=1.0, gamma=1.0, TargetEnergyError=TargetEnergyError,\n",
    "                            data_min=data_min, data_max=data_max,device=device)\n",
    "\n",
    "\n",
    "test_loss, energy_error, energy_error_std, energy_error_fiducial, energy_error_fiducial_std, time_step, time_step_fiducial = \\\n",
    "    validate(model, criterion, test_loader, input_mask, device)\n",
    "print(f\"Epoch [{epoch}], Test Loss: {test_loss:.4e}, Energy Loss: {energy_error:.4e}/{energy_error_fiducial:.4e}, std: {energy_error_std:.4e}/{energy_error_fiducial_std:.4e}, Time step: {time_step:.4e}/{time_step_fiducial:.4e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Three Body Only With Magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([17694, 68])\n"
     ]
    }
   ],
   "source": [
    "def normalizer(_data):\n",
    "    _max = torch.abs(_data.max())\n",
    "    data_max = torch.ones(_data.size(), device=device)*_max\n",
    "    _data = _data/data_max\n",
    "    return _data, _max\n",
    "    \n",
    "def denormalizer(_data, _max):\n",
    "    data_max = torch.ones(_data.size(), device=device)*_max\n",
    "    return _data*data_max\n",
    "\n",
    "# Example unsupervised data: 100 samples with 10 features each\n",
    "data = np.load(\"../data/three_body_train_data.npy\")\n",
    "num_samples = data.shape[0]\n",
    "num_samples_start = int(data.shape[0]*0.8)\n",
    "num_samples_start = 0\n",
    "num_samples_end   = data.shape[0]\n",
    "num_samples = num_samples_end - num_samples_start\n",
    "num_features = data.shape[1]\n",
    "\n",
    "# Placeholder for input (magnitudes of velocities and accelerations)\n",
    "data_org = torch.tensor(data[num_samples_start:num_samples_end,:], dtype=dtype).to(device)\n",
    "data = torch.empty((num_samples,6+num_features), dtype=dtype).to(device)\n",
    "data[:,6:] = data_org\n",
    "\n",
    "\n",
    "# Magnitudes vel, acc, mass\n",
    "temp, tmax = normalizer(data_org[:,4:7])\n",
    "vel = denormalizer(torch.norm(temp, p=2, dim=1),tmax)\n",
    "acc = torch.empty((num_samples,4), dtype=dtype).to(device)\n",
    "\n",
    "temp,tmax = normalizer(data_org[:,7:10])\n",
    "acc[:,0] = denormalizer(torch.norm(temp, p=2, dim=1),tmax)\n",
    "temp,tmax = normalizer(data_org[:,10:13])\n",
    "acc[:,1] = denormalizer(torch.norm(temp, p=2, dim=1),tmax)\n",
    "temp,tmax = normalizer(data_org[:,13:16])\n",
    "acc[:,2] = denormalizer(torch.norm(temp, p=2, dim=1),tmax)\n",
    "temp,tmax = normalizer(data_org[:,16:19])\n",
    "acc[:,3] = denormalizer(torch.norm(temp, p=2, dim=1),tmax)\n",
    "mass = data_org[:,0]\n",
    "\n",
    "data[:,0] = vel\n",
    "data[:,1:5] = acc\n",
    "data[:,5] = mass\n",
    "\n",
    "# Normalize the data\n",
    "eps = 1e-5\n",
    "data_min = data[:,:6].min(axis=0, keepdim=True).values\n",
    "data_max = data[:,:6].max(axis=0, keepdim=True).values\n",
    "data[:,:6] = (data[:,:6] - data_min) / (data_max - data_min)+eps\n",
    "\n",
    "\n",
    "# Wrap the feature tensor in a TensorDataset\n",
    "# Each item from the dataset will be a tuple containing one tensor (X[i],)\n",
    "dataset = TensorDataset(data)\n",
    "\n",
    "# Define the proportion for the test set (e.g., 20%)\n",
    "test_ratio = 0.2\n",
    "num_test = int(num_samples * test_ratio)\n",
    "num_train = num_samples - num_test\n",
    "\n",
    "# Use random_split to split the dataset into train and test subsets\n",
    "# Define generator with a fixed seed\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_dataset, test_dataset = random_split(dataset, [num_train, num_test], generator=generator)\n",
    "\n",
    "# Create DataLoaders for the training and testing datasets\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-05\n",
      "tensor([3.2997e-04, 2.5714e+04, 3.4986e-04, 3.4986e-04, 8.9298e+04, 3.8232e-03,\n",
      "        3.8232e-03, 3.6064e+05, 1.2763e-02, 1.2763e-02, 2.1405e+06, 6.9280e-03,\n",
      "        6.9280e-03, 7.2961e+06, 2.3218e-02, 2.3218e-02, 3.8597e+07, 5.3466e-03,\n",
      "        5.3466e-03, 1.1962e+08], device='cuda:0', grad_fn=<AbsBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import structures\n",
    "importlib.reload(structures)\n",
    "from structures import *\n",
    "import losses\n",
    "importlib.reload(losses)\n",
    "from losses import *\n",
    "TargetEnergyError = 1e-5\n",
    "#batch_size = 32\n",
    "criterion = CustomizableLoss3DM(nParticle=3, nAttribute=20, nBatch=batch_size,alpha=0.1, beta=0.1, gamma=10.0, TargetEnergyError=TargetEnergyError,\n",
    "                            data_min=data_min, data_max=data_max,device=device)\n",
    "X = data[:20,:]\n",
    "output = data[:20,[25,25]] #torch.zeros((X.shape[0],2)).to(device)\n",
    "loss, loss_terms = criterion(output, X)\n",
    "#output[:,0], X[:,-2], X[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.2500e-06, 6.2500e-06, 6.2500e-06,  ..., 1.2500e-05, 2.4410e-08,\n",
       "        2.4410e-08], device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:,25]#.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.return_types.min(\n",
       " values=tensor([0., 0., 0.], device='cuda:0'),\n",
       " indices=tensor([5041,    9,    9], device='cuda:0')),\n",
       " torch.return_types.max(\n",
       " values=tensor([1., 1., 1.], device='cuda:0'),\n",
       " indices=tensor([1649, 1649, 1649], device='cuda:0')),\n",
       " tensor([0.2625, 0.1272, 0.0918], device='cuda:0'))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[train_dataset.indices,:3].min(dim=0), data[train_dataset.indices,:3].max(dim=0), data[train_dataset.indices,:3].mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.return_types.min(\n",
       " values=tensor([0.0003, 0.0000, 0.0000], device='cuda:0'),\n",
       " indices=tensor([368,  18,  18], device='cuda:0')),\n",
       " torch.return_types.max(\n",
       " values=tensor([0.9988, 0.9888, 0.9852], device='cuda:0'),\n",
       " indices=tensor([2865, 2865, 2865], device='cuda:0')),\n",
       " tensor([0.2565, 0.1216, 0.0869], device='cuda:0'))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[test_dataset.indices,:3].min(dim=0), data[test_dataset.indices,:3].max(dim=0), data[test_dataset.indices,:3].mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-06 23:38:28,868] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed info: version=0.16.4, git-hash=unknown, git-branch=unknown\n",
      "[2025-04-06 23:38:28,869] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 1\n",
      "[2025-04-06 23:38:28,873] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2025-04-06 23:38:28,874] [INFO] [logging.py:128:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adam as basic optimizer\n",
      "[2025-04-06 23:38:28,875] [INFO] [logging.py:128:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2025-04-06 23:38:28,875] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam\n",
      "[2025-04-06 23:38:28,876] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>\n",
      "[2025-04-06 23:38:28,877] [INFO] [logging.py:128:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 1 optimizer\n",
      "[2025-04-06 23:38:28,877] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 500000000\n",
      "[2025-04-06 23:38:28,877] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 500000000\n",
      "[2025-04-06 23:38:28,878] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2025-04-06 23:38:28,878] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2025-04-06 23:38:29,189] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states\n",
      "[2025-04-06 23:38:29,191] [INFO] [utils.py:782:see_memory_usage] MA 0.06 GB         Max_MA 3.79 GB         CA 7.52 GB         Max_CA 8 GB \n",
      "[2025-04-06 23:38:29,192] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 60.49 GB, percent = 8.0%\n",
      "[2025-04-06 23:38:29,399] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states\n",
      "[2025-04-06 23:38:29,401] [INFO] [utils.py:782:see_memory_usage] MA 0.06 GB         Max_MA 0.06 GB         CA 7.52 GB         Max_CA 8 GB \n",
      "[2025-04-06 23:38:29,402] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 60.49 GB, percent = 8.0%\n",
      "[2025-04-06 23:38:29,402] [INFO] [stage_1_and_2.py:550:__init__] optimizer state initialized\n",
      "[2025-04-06 23:38:29,608] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2025-04-06 23:38:29,609] [INFO] [utils.py:782:see_memory_usage] MA 0.06 GB         Max_MA 0.06 GB         CA 7.52 GB         Max_CA 8 GB \n",
      "[2025-04-06 23:38:29,610] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 60.49 GB, percent = 8.0%\n",
      "[2025-04-06 23:38:29,625] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer\n",
      "[2025-04-06 23:38:29,625] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = None\n",
      "[2025-04-06 23:38:29,626] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2025-04-06 23:38:29,626] [INFO] [logging.py:128:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001], mom=[[0.9, 0.999]]\n",
      "[2025-04-06 23:38:29,627] [INFO] [config.py:1001:print] DeepSpeedEngine configuration:\n",
      "[2025-04-06 23:38:29,627] [INFO] [config.py:1005:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2025-04-06 23:38:29,627] [INFO] [config.py:1005:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'intra_op_parallelism': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}\n",
      "[2025-04-06 23:38:29,628] [INFO] [config.py:1005:print]   amp_enabled .................. False\n",
      "[2025-04-06 23:38:29,628] [INFO] [config.py:1005:print]   amp_params ................... False\n",
      "[2025-04-06 23:38:29,628] [INFO] [config.py:1005:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2025-04-06 23:38:29,629] [INFO] [config.py:1005:print]   bfloat16_enabled ............. False\n",
      "[2025-04-06 23:38:29,629] [INFO] [config.py:1005:print]   bfloat16_immediate_grad_update  False\n",
      "[2025-04-06 23:38:29,630] [INFO] [config.py:1005:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2025-04-06 23:38:29,630] [INFO] [config.py:1005:print]   checkpoint_tag_validation_enabled  True\n",
      "[2025-04-06 23:38:29,630] [INFO] [config.py:1005:print]   checkpoint_tag_validation_fail  False\n",
      "[2025-04-06 23:38:29,631] [INFO] [config.py:1005:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1551d114f6d0>\n",
      "[2025-04-06 23:38:29,631] [INFO] [config.py:1005:print]   communication_data_type ...... None\n",
      "[2025-04-06 23:38:29,631] [INFO] [config.py:1005:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2025-04-06 23:38:29,632] [INFO] [config.py:1005:print]   curriculum_enabled_legacy .... False\n",
      "[2025-04-06 23:38:29,632] [INFO] [config.py:1005:print]   curriculum_params_legacy ..... False\n",
      "[2025-04-06 23:38:29,632] [INFO] [config.py:1005:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2025-04-06 23:38:29,633] [INFO] [config.py:1005:print]   data_efficiency_enabled ...... False\n",
      "[2025-04-06 23:38:29,633] [INFO] [config.py:1005:print]   dataloader_drop_last ......... False\n",
      "[2025-04-06 23:38:29,633] [INFO] [config.py:1005:print]   disable_allgather ............ False\n",
      "[2025-04-06 23:38:29,636] [INFO] [config.py:1005:print]   dump_state ................... False\n",
      "[2025-04-06 23:38:29,636] [INFO] [config.py:1005:print]   dynamic_loss_scale_args ...... None\n",
      "[2025-04-06 23:38:29,636] [INFO] [config.py:1005:print]   eigenvalue_enabled ........... False\n",
      "[2025-04-06 23:38:29,637] [INFO] [config.py:1005:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2025-04-06 23:38:29,637] [INFO] [config.py:1005:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2025-04-06 23:38:29,637] [INFO] [config.py:1005:print]   eigenvalue_layer_num ......... 0\n",
      "[2025-04-06 23:38:29,638] [INFO] [config.py:1005:print]   eigenvalue_max_iter .......... 100\n",
      "[2025-04-06 23:38:29,638] [INFO] [config.py:1005:print]   eigenvalue_stability ......... 1e-06\n",
      "[2025-04-06 23:38:29,638] [INFO] [config.py:1005:print]   eigenvalue_tol ............... 0.01\n",
      "[2025-04-06 23:38:29,639] [INFO] [config.py:1005:print]   eigenvalue_verbose ........... False\n",
      "[2025-04-06 23:38:29,639] [INFO] [config.py:1005:print]   elasticity_enabled ........... False\n",
      "[2025-04-06 23:38:29,639] [INFO] [config.py:1005:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2025-04-06 23:38:29,640] [INFO] [config.py:1005:print]   fp16_auto_cast ............... None\n",
      "[2025-04-06 23:38:29,640] [INFO] [config.py:1005:print]   fp16_enabled ................. False\n",
      "[2025-04-06 23:38:29,640] [INFO] [config.py:1005:print]   fp16_master_weights_and_gradients  False\n",
      "[2025-04-06 23:38:29,641] [INFO] [config.py:1005:print]   global_rank .................. 0\n",
      "[2025-04-06 23:38:29,641] [INFO] [config.py:1005:print]   grad_accum_dtype ............. None\n",
      "[2025-04-06 23:38:29,641] [INFO] [config.py:1005:print]   gradient_accumulation_steps .. 1\n",
      "[2025-04-06 23:38:29,642] [INFO] [config.py:1005:print]   gradient_clipping ............ 0.0\n",
      "[2025-04-06 23:38:29,642] [INFO] [config.py:1005:print]   gradient_predivide_factor .... 1.0\n",
      "[2025-04-06 23:38:29,642] [INFO] [config.py:1005:print]   graph_harvesting ............. False\n",
      "[2025-04-06 23:38:29,643] [INFO] [config.py:1005:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2025-04-06 23:38:29,643] [INFO] [config.py:1005:print]   initial_dynamic_scale ........ 65536\n",
      "[2025-04-06 23:38:29,643] [INFO] [config.py:1005:print]   load_universal_checkpoint .... False\n",
      "[2025-04-06 23:38:29,644] [INFO] [config.py:1005:print]   loss_scale ................... 0\n",
      "[2025-04-06 23:38:29,644] [INFO] [config.py:1005:print]   memory_breakdown ............. False\n",
      "[2025-04-06 23:38:29,644] [INFO] [config.py:1005:print]   mics_hierarchial_params_gather  False\n",
      "[2025-04-06 23:38:29,645] [INFO] [config.py:1005:print]   mics_shard_size .............. -1\n",
      "[2025-04-06 23:38:29,645] [INFO] [config.py:1005:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')\n",
      "[2025-04-06 23:38:29,646] [INFO] [config.py:1005:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2025-04-06 23:38:29,646] [INFO] [config.py:1005:print]   optimizer_legacy_fusion ...... False\n",
      "[2025-04-06 23:38:29,646] [INFO] [config.py:1005:print]   optimizer_name ............... adam\n",
      "[2025-04-06 23:38:29,647] [INFO] [config.py:1005:print]   optimizer_params ............. {'lr': 0.0001, 'betas': [0.9, 0.999], 'eps': 1e-08}\n",
      "[2025-04-06 23:38:29,647] [INFO] [config.py:1005:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2025-04-06 23:38:29,647] [INFO] [config.py:1005:print]   pld_enabled .................. False\n",
      "[2025-04-06 23:38:29,648] [INFO] [config.py:1005:print]   pld_params ................... False\n",
      "[2025-04-06 23:38:29,648] [INFO] [config.py:1005:print]   prescale_gradients ........... False\n",
      "[2025-04-06 23:38:29,648] [INFO] [config.py:1005:print]   scheduler_name ............... None\n",
      "[2025-04-06 23:38:29,649] [INFO] [config.py:1005:print]   scheduler_params ............. None\n",
      "[2025-04-06 23:38:29,649] [INFO] [config.py:1005:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2025-04-06 23:38:29,649] [INFO] [config.py:1005:print]   sparse_attention ............. None\n",
      "[2025-04-06 23:38:29,650] [INFO] [config.py:1005:print]   sparse_gradients_enabled ..... False\n",
      "[2025-04-06 23:38:29,650] [INFO] [config.py:1005:print]   steps_per_print .............. None\n",
      "[2025-04-06 23:38:29,650] [INFO] [config.py:1005:print]   tensor_parallel_config ....... dtype=torch.float16 autotp_size=0 tensor_parallel=TPConfig(tp_size=1, tp_grain_size=1, mpu=None, tp_group=None) injection_policy_tuple=None keep_module_on_host=False replace_with_kernel_inject=False\n",
      "[2025-04-06 23:38:29,651] [INFO] [config.py:1005:print]   timers_config ................ enabled=True synchronized=True\n",
      "[2025-04-06 23:38:29,651] [INFO] [config.py:1005:print]   train_batch_size ............. 64\n",
      "[2025-04-06 23:38:29,651] [INFO] [config.py:1005:print]   train_micro_batch_size_per_gpu  64\n",
      "[2025-04-06 23:38:29,652] [INFO] [config.py:1005:print]   use_data_before_expert_parallel_  False\n",
      "[2025-04-06 23:38:29,652] [INFO] [config.py:1005:print]   use_node_local_storage ....... False\n",
      "[2025-04-06 23:38:29,652] [INFO] [config.py:1005:print]   wall_clock_breakdown ......... False\n",
      "[2025-04-06 23:38:29,653] [INFO] [config.py:1005:print]   weight_quantization_config ... None\n",
      "[2025-04-06 23:38:29,653] [INFO] [config.py:1005:print]   world_size ................... 1\n",
      "[2025-04-06 23:38:29,653] [INFO] [config.py:1005:print]   zero_allow_untested_optimizer  False\n",
      "[2025-04-06 23:38:29,654] [INFO] [config.py:1005:print]   zero_config .................. stage=1 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False zeropp_loco_param=None mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True log_trace_cache_warnings=False\n",
      "[2025-04-06 23:38:29,654] [INFO] [config.py:1005:print]   zero_enabled ................. True\n",
      "[2025-04-06 23:38:29,654] [INFO] [config.py:1005:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2025-04-06 23:38:29,655] [INFO] [config.py:1005:print]   zero_optimization_stage ...... 1\n",
      "[2025-04-06 23:38:29,655] [INFO] [config.py:991:print_user_config]   json = {\n",
      "    \"train_batch_size\": 64, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"optimizer\": {\n",
      "        \"type\": \"Adam\", \n",
      "        \"params\": {\n",
      "            \"lr\": 0.0001, \n",
      "            \"betas\": [0.9, 0.999], \n",
      "            \"eps\": 1e-08\n",
      "        }\n",
      "    }, \n",
      "    \"fp32\": {\n",
      "        \"enabled\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 1\n",
      "    }\n",
      "}\n",
      "Epoch [0/1000], Timestep error: 4.4348e+11/4.5533e+11, Energy Loss: 5.1086e+01/nan, 5.1002e+01/nan, Time step: 6.8003e-01/3.6641e-06, 5.6490e-01/3.6910e-06, 4.4239e-03/4.7258e-06\n",
      "Epoch [1/1000], Timestep error: 1.6137e+11/3.1702e+09, Energy Loss: 5.0318e+01/nan, 4.1668e+01/nan, Time step: 2.2916e-01/3.6641e-06, 2.7531e-03/3.6910e-06, 8.7262e-04/4.7258e-06\n",
      "Epoch [2/1000], Timestep error: 1.3127e+08/1.2295e+05, Energy Loss: 3.8473e+01/nan, 2.2874e+01/nan, Time step: 2.2322e-04/3.6641e-06, 8.7881e-08/3.6910e-06, 8.0635e-08/4.7258e-06\n",
      "Epoch [3/1000], Timestep error: 1.9540e+04/6.7015e+03, Energy Loss: 2.2378e+01/nan, 1.7633e+01/nan, Time step: 1.3072e-08/3.6641e-06, 5.9835e-09/3.6910e-06, 6.3142e-09/4.7258e-06\n",
      "Epoch [4/1000], Timestep error: 4.5352e+03/4.3749e+03, Energy Loss: 2.0076e+01/nan, 1.6901e+01/nan, Time step: 5.7567e-09/3.6641e-06, 5.1016e-09/3.6910e-06, 5.3347e-09/4.7258e-06\n",
      "Epoch [5/1000], Timestep error: 2.7254e+03/2.2181e+03, Energy Loss: 1.9762e+01/nan, 1.5842e+01/nan, Time step: 4.6259e-09/3.6641e-06, 3.2995e-09/3.6910e-06, 3.4569e-09/4.7258e-06\n",
      "--> Best model saved at epoch 6 with val loss 2.9222e+02\n",
      "--> Best model saved at epoch 6 with largest timestep 2.4345e-09\n",
      "Epoch [6/1000], Timestep error: 1.7425e+03/1.4009e+03, Energy Loss: 1.8152e+01/nan, 1.5126e+01/nan, Time step: 3.6601e-09/3.6641e-06, 2.4345e-09/3.6910e-06, 2.5591e-09/4.7258e-06\n",
      "--> Best model saved at epoch 7 with val loss 2.8709e+02\n",
      "--> Best model saved at epoch 7 with largest timestep 3.9601e-09\n",
      "Epoch [7/1000], Timestep error: 1.7174e+03/2.0195e+03, Energy Loss: 1.7014e+01/nan, 1.5936e+01/nan, Time step: 4.1148e-09/3.6641e-06, 3.9601e-09/3.6910e-06, 4.0221e-09/4.7258e-06\n",
      "--> Best model saved at epoch 8 with val loss 2.8376e+02\n",
      "--> Best model saved at epoch 8 with largest timestep 5.1841e-09\n",
      "Epoch [8/1000], Timestep error: 1.7612e+03/2.3274e+03, Energy Loss: 1.6753e+01/nan, 1.6397e+01/nan, Time step: 4.3293e-09/3.6641e-06, 5.1841e-09/3.6910e-06, 5.0548e-09/4.7258e-06\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 90\u001b[0m\n\u001b[1;32m     84\u001b[0m lists \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m:[], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m:[], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_energy\u001b[39m\u001b[38;5;124m\"\u001b[39m:[], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_energy\u001b[39m\u001b[38;5;124m\"\u001b[39m:[], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_time_step\u001b[39m\u001b[38;5;124m\"\u001b[39m:[], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_time_step\u001b[39m\u001b[38;5;124m\"\u001b[39m:[]}\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     87\u001b[0m \n\u001b[1;32m     88\u001b[0m     \u001b[38;5;66;03m#train_loss, train_energy = \\\u001b[39;00m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;66;03m#    train_one_epoch(model, optimizer, criterion, train_loader, input_mask, weights, device)\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m     train_res \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch_deepspeed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_engine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;66;03m#test_loss, energy_error, energy_error_std, energy_error_fiducial, energy_error_fiducial_std, energy_pred, energy_init, time_step, time_step_fiducial = \\\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;66;03m#    validate(model, criterion, test_loader, input_mask, weights, device)\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     val_res \u001b[38;5;241m=\u001b[39m validate_deepspeed(model_engine, criterion, test_loader, input_mask, weights, device)\n",
      "File \u001b[0;32m~/projects/AITimeStepper/jupyter_notebooks/../src/trainer.py:18\u001b[0m, in \u001b[0;36mtrain_one_epoch_deepspeed\u001b[0;34m(model_engine, optimizer, criterion, train_loader, input_mask, weights, device)\u001b[0m\n\u001b[1;32m     13\u001b[0m N \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (X,) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m#optimizer.zero_grad()       # Clear gradients\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m#print(X.shape)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m#print(X[:,:12].shape)\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43minput_mask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m          \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m#print(output)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     loss, loss_terms \u001b[38;5;241m=\u001b[39m criterion(model_engine, output, X, weights)  \u001b[38;5;66;03m# Compute loss between output and input\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/pyenv/torch/lib/python3.10/site-packages/deepspeed/utils/nvtx.py:18\u001b[0m, in \u001b[0;36minstrument_w_nvtx.<locals>.wrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m enable_nvtx:\n\u001b[1;32m     17\u001b[0m     get_accelerator()\u001b[38;5;241m.\u001b[39mrange_push(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m ret_val \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m enable_nvtx:\n\u001b[1;32m     20\u001b[0m     get_accelerator()\u001b[38;5;241m.\u001b[39mrange_pop()\n",
      "File \u001b[0;32m~/pyenv/torch/lib/python3.10/site-packages/deepspeed/runtime/engine.py:1987\u001b[0m, in \u001b[0;36mDeepSpeedEngine.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp16_auto_cast():\n\u001b[1;32m   1985\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cast_inputs_half(inputs)\n\u001b[0;32m-> 1987\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1989\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzero_optimization_partition_weights():\n\u001b[1;32m   1990\u001b[0m     \u001b[38;5;66;03m# Disable automated discovery of external parameters\u001b[39;00m\n\u001b[1;32m   1991\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39mmodules():\n",
      "File \u001b[0;32m/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/AITimeStepper/jupyter_notebooks/../src/structures.py:78\u001b[0m, in \u001b[0;36mFullyConnectedNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/torch/nn/modules/activation.py:101\u001b[0m, in \u001b[0;36mReLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/torch/nn/functional.py:1473\u001b[0m, in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1471\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m   1472\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1473\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1474\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/torch/fx/traceback.py:68\u001b[0m, in \u001b[0;36mformat_stack\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [current_meta\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack_trace\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# fallback to traceback.format_stack()\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m traceback\u001b[38;5;241m.\u001b[39mformat_list(\u001b[43mtraceback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/traceback.py:227\u001b[0m, in \u001b[0;36mextract_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[0;32m--> 227\u001b[0m stack \u001b[38;5;241m=\u001b[39m \u001b[43mStackSummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwalk_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m stack\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stack\n",
      "File \u001b[0;32m/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/traceback.py:379\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[0;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[1;32m    376\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(FrameSummary(\n\u001b[1;32m    377\u001b[0m         filename, lineno, name, lookup_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39mf_locals))\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m fnames:\n\u001b[0;32m--> 379\u001b[0m     \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckcache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# If immediate lookup was desired, trigger lookups now.\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lookup_lines:\n",
      "File \u001b[0;32m/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/linecache.py:72\u001b[0m, in \u001b[0;36mcheckcache\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m   \u001b[38;5;66;03m# no-op for files loaded via a __loader__\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m     stat \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     cache\u001b[38;5;241m.\u001b[39mpop(filename, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import structures\n",
    "importlib.reload(structures)\n",
    "from structures import *\n",
    "import losses\n",
    "importlib.reload(losses)\n",
    "from losses import *\n",
    "import trainer\n",
    "importlib.reload(trainer)\n",
    "from trainer import *\n",
    "\n",
    "input_mask = np.r_[0:6]\n",
    "input_size = len(input_mask)\n",
    "hidden_dims = [32,64,64,32]     # Number of hidden neurons\n",
    "#hidden_dims = [8,16,16,4]     # Number of hidden neurons\n",
    "#hidden_dims = [16,128,32,8]     # Number of hidden neurons\n",
    "#hidden_dims = [8,8]     # Number of hidden neurons\n",
    "output_size = 2     # Number of output \n",
    "TargetEnergyError = 1e-2\n",
    "weights = {\"time_step\":1, \"energy_loss\":1}\n",
    "\n",
    "# Instantiate the model\n",
    "try: \n",
    "    del mode\n",
    "    l\n",
    "    print(\"model deleted\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "ds_config = {\n",
    "    \"train_batch_size\": batch_size,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"Adam\",\n",
    "        \"params\": {\"lr\": 1e-4, \"betas\": [0.9, 0.999], \"eps\": 1e-8}\n",
    "    },\n",
    "    \"fp32\": {\n",
    "        \"enabled\": True  # Enables mixed precision training\n",
    "    },\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 1  # Enable ZeRO Stage 1 for memory optimization\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "#model = SimpleNN(input_size, hidden_size, output_size).to(device)\n",
    "model = FullyConnectedNN(input_dim=input_size, output_dim=output_size, hidden_dims=hidden_dims, activation='relu', dropout=0.0, output_positive=True).to(device)\n",
    "\n",
    "\n",
    "model_engine, optimizer, _, _ = deepspeed.initialize(\n",
    "    model=model,\n",
    "    model_parameters=model.parameters(),\n",
    "    config=ds_config\n",
    ")\n",
    "\n",
    "# Define the loss function (CrossEntropyLoss is common for classification tasks)\n",
    "criterion = CustomizableLoss3DM(nParticle=3, nAttribute=20, nBatch=batch_size,alpha=weights['time_step'], beta=weights['energy_loss'], gamma=weights['energy_loss'], TargetEnergyError=TargetEnergyError,\n",
    "                            data_min=data_min, data_max=data_max,device=device)\n",
    "\n",
    "# Define the optimizer (Stochastic Gradient Descent in this example)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "#optimizer = optim.AdamW(model.parameters(), lr=0.00001)\n",
    "#optimizer = optim.AdamW(model.parameters(), lr=0.00001)\n",
    "\n",
    "\n",
    "\n",
    "# Paths to save best and last models\n",
    "base_path = \"/mnt/home/yjo10/projects/AITimeStepper/data/models/three_body/\"\n",
    "best_val_path = base_path + \"best_model_loss.pth\"\n",
    "best_timestep_path = base_path + \"best_model_timestep.pth\"\n",
    "#last_model_path = base_path + f\"last_model_{epoch}.pth\"\n",
    "best_val_loss = float(\"inf\")\n",
    "best_largest_timestep = 0\n",
    "with open(base_path+\"c++/normalization_factors.txt\", \"w\") as f:\n",
    "    f.write(f\"{data_min[0][0]} {data_min[0][1]} {data_min[0][2]} {data_min[0][3]} {data_min[0][4]} {data_min[0][5]}\\n\")    \n",
    "    f.write(f\"{data_max[0][0]} {data_max[0][1]} {data_max[0][2]} {data_max[0][3]} {data_max[0][4]} {data_max[0][5]}\\n\")    \n",
    "\n",
    "example_input = torch.randn(1, input_size).to(device)\n",
    "exp_time_step = 1\n",
    "exp_energy_loss = 1\n",
    "# Training routine\n",
    "num_epochs = 1000\n",
    "lists = {\"training_loss\":[], \"val_loss\":[], \"training_energy\":[], \"val_energy\":[], \"training_time_step\":[], \"val_time_step\":[]}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    #train_loss, train_energy = \\\n",
    "    #    train_one_epoch(model, optimizer, criterion, train_loader, input_mask, weights, device)\n",
    "    train_res = train_one_epoch_deepspeed(model_engine, optimizer, criterion, train_loader, input_mask, weights, device)\n",
    "        \n",
    "    #test_loss, energy_error, energy_error_std, energy_error_fiducial, energy_error_fiducial_std, energy_pred, energy_init, time_step, time_step_fiducial = \\\n",
    "    #    validate(model, criterion, test_loader, input_mask, weights, device)\n",
    "    val_res = validate_deepspeed(model_engine, criterion, test_loader, input_mask, weights, device)\n",
    "\n",
    "    lists[\"training_loss\"].append(train_res[\"train_loss\"])\n",
    "    lists[\"training_energy\"].append(train_res[\"energy_error\"])\n",
    "    lists[\"training_time_step\"].append(train_res[\"time_step\"])\n",
    "\n",
    "    lists[\"val_loss\"].append(val_res[\"val_loss\"])\n",
    "    lists[\"val_energy\"].append(val_res[\"energy_error\"])\n",
    "    lists[\"val_time_step\"].append(val_res[\"time_step\"])\n",
    "\n",
    "    if epoch > 5:\n",
    "        # Save the best model based on validation loss\n",
    "        if val_res['val_loss'] < best_val_loss:\n",
    "            best_val_loss = val_res['val_loss']\n",
    "            torch.save(model.state_dict(), best_val_path)\n",
    "            #traced_model = torch.jit.trace(model, example_input)\n",
    "            traced_model = torch.jit.script(model)\n",
    "            traced_model.save(base_path + f\"c++/best_model_loss.pt\")\n",
    "            print(f\"--> Best model saved at epoch {epoch} with val loss {best_val_loss:.4e}\")\n",
    "        \n",
    "        # Save the best model based on validation largest timestep\n",
    "        if val_res['time_step'] > best_largest_timestep:\n",
    "            best_largest_timestep = val_res['time_step']\n",
    "            torch.save(model.state_dict(), best_timestep_path)\n",
    "            #traced_model = torch.jit.trace(model, example_input)\n",
    "            traced_model = torch.jit.script(model)\n",
    "            traced_model.save(base_path + f\"c++/best_model_timestep.pt\")\n",
    "            print(f\"--> Best model saved at epoch {epoch} with largest timestep {best_largest_timestep:.4e}\")\n",
    "\n",
    "    # Save the last model after every epoch (or just once at the end)\n",
    "    torch.save(model.state_dict(), base_path + f\"model_{epoch}.pth\")\n",
    "    #traced_model = torch.jit.trace(model, example_input)\n",
    "    traced_model = torch.jit.script(model)\n",
    "    traced_model.save(base_path + f\"c++/model_{epoch}.pt\")\n",
    "\n",
    "\n",
    "\n",
    "    fig, axes = pu.generateAxesForMultiplePlots(shape=(1,3),figsize=(10,10),hspace=0.1,wspace=0.1,\n",
    "                                    gridspec=None)\n",
    "    for i, (key, value) in enumerate(lists.items()):\n",
    "        y = i//2\n",
    "        axes[y].plot(range(epoch+1), value, label=key)\n",
    "        axes[y].scatter(range(epoch+1), value)\n",
    "        axes[y].set_yscale(\"log\")\n",
    "\n",
    "\n",
    "    axes[2].axhline(y=val_res['time_step_fiducial'], c='r',alpha=0.5,zorder=-1,label=\"Timestep Fiducial\")\n",
    "    axes[1].axhline(y=TargetEnergyError, c='r',alpha=0.5,zorder=-1,label=\"Target energy\")\n",
    "    #plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left', borderaxespad=0.)\n",
    "    axes[0].legend()\n",
    "    axes[1].legend()\n",
    "    axes[2].legend()\n",
    "    #plt.tight_layout()\n",
    "    plt.savefig(\"learning_curve.png\",dpi=100)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    fig, axes = pu.generateAxesForMultiplePlots(shape=(1,2),figsize=(10,15),hspace=0.1,wspace=0.1,\n",
    "                                    gridspec=None)\n",
    "    # Get one batch from the validation loader\n",
    "    dataiter = iter(train_loader)\n",
    "    inputs, = next(dataiter)\n",
    "\n",
    "    # Determine how many samples to take (if batch size < 50, take the whole batch)\n",
    "    num_samples = min(50, batch_size)\n",
    "\n",
    "    # Randomly select indices from the batch\n",
    "    indices = random.sample(range(batch_size), num_samples)\n",
    "    sampled_inputs = inputs[:,input_mask][indices]\n",
    "    sampled_targets = inputs[indices,25]\n",
    "\n",
    "    # Compute model predictions with no gradient computation\n",
    "    with torch.no_grad():\n",
    "        sampled_predictions = model(sampled_inputs)\n",
    "\n",
    "    # Convert tensors to numpy arrays for plotting\n",
    "    sampled_predictions = sampled_predictions[:,0].cpu().numpy().flatten()\n",
    "    sampled_targets = sampled_targets.cpu().numpy().flatten()\n",
    "\n",
    "    # Create sample indices for the x-axis (1st sample, 2nd sample, etc.)\n",
    "    sample_indices = list(range(1, num_samples + 1))\n",
    "\n",
    "    # Plot predictions and ground truth vs sample number\n",
    "    # plt.figure(figsize=(8, 6))\n",
    "    # Add vertical lines for each data point\n",
    "    for x in sample_indices:\n",
    "        axes[0].axvline(x=x, color='grey', linestyle='-', alpha=0.2,zorder=0)\n",
    "    axes[0].scatter(sample_indices, sampled_targets, marker='o', label='Ground Truth', fc=\"none\", ec=\"k\",zorder=10)\n",
    "    axes[0].scatter(sample_indices, sampled_predictions, marker='s', label='Predictions', fc=\"none\",ec=\"r\" ,zorder=10)\n",
    "    axes[0].set_yscale(\"log\")\n",
    "    axes[0].set_xlabel('Sample Number')\n",
    "    axes[0].set_ylabel('Value')\n",
    "\n",
    "    # Get one batch from the validation loader\n",
    "    dataiter = iter(test_loader)\n",
    "    inputs, = next(dataiter)\n",
    "\n",
    "    # Determine how many samples to take (if batch size < 50, take the whole batch)\n",
    "    num_samples = min(50, batch_size)\n",
    "\n",
    "    # Randomly select indices from the batch\n",
    "    indices = random.sample(range(batch_size), num_samples)\n",
    "    sampled_inputs = inputs[:,input_mask][indices]\n",
    "    sampled_targets = inputs[indices,25]\n",
    "\n",
    "    # Compute model predictions with no gradient computation\n",
    "    with torch.no_grad():\n",
    "        sampled_predictions = model(sampled_inputs)\n",
    "\n",
    "    # Convert tensors to numpy arrays for plotting\n",
    "    sampled_predictions = sampled_predictions[:,0].cpu().numpy().flatten()\n",
    "    sampled_targets = sampled_targets.cpu().numpy().flatten()\n",
    "\n",
    "    # Create sample indices for the x-axis (1st sample, 2nd sample, etc.)\n",
    "    sample_indices = list(range(1, num_samples + 1))\n",
    "\n",
    "    # Plot predictions and ground truth vs sample number\n",
    "    # plt.figure(figsize=(8, 6))\n",
    "    # Add vertical lines for each data point\n",
    "    for x in sample_indices:\n",
    "        axes[1].axvline(x=x, color='grey', linestyle='-', alpha=0.2,zorder=0)\n",
    "    axes[1].scatter(sample_indices, sampled_targets, marker='o', label='Ground Truth', fc=\"none\", ec=\"k\",zorder=10)\n",
    "    axes[1].scatter(sample_indices, sampled_predictions, marker='s', label='Predictions', fc=\"none\",ec=\"r\" ,zorder=10)\n",
    "    axes[1].set_yscale(\"log\")\n",
    "    axes[1].set_xlabel('Sample Number')\n",
    "    axes[1].set_ylabel('Value')\n",
    "\n",
    "    axes[0].set_title(f'Epoch [{epoch}/{num_epochs}] Predictions and Ground Truth vs. Sample Number')\n",
    "    #plt.legend()\n",
    "    plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left', borderaxespad=0.)\n",
    "    plt.savefig(\"samples.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    if time_step < time_step_fiducial:\n",
    "        weights['time_step'] += 0.1*exp_time_step\n",
    "        exp_time_step += 1\n",
    "    else:\n",
    "        weights['time_step'] += 0\n",
    "        exp_time_step = 1\n",
    "\n",
    "    if energy_error > energy_error_fiducial:\n",
    "        weights['energy_loss'] += 0.1*exp_energy_loss\n",
    "        exp_energy_loss += 1\n",
    "    else:\n",
    "        weights['energy_loss'] += 0\n",
    "        exp_energy_loss = 1\n",
    "        \"\"\"\n",
    "\n",
    "    #print(f\"Epoch [{epoch}/{num_epochs}], Train Loss: {train_loss:.4e}, Test Loss: {test_loss:.4e}, Energy Loss: {energy_error:.4e}/{energy_error_fiducial:.4e}, std: {energy_error_std:.4e}/{energy_error_fiducial_std:.4e}, Time step: {time_step:.4e}/{time_step_fiducial:.4e}\")\n",
    "    #print(f\"Epoch [{epoch}/{num_epochs}], Train Loss: {train_res['train_loss']:.4e}, Val Loss: {val_res['val_loss']:.4e}, Energy Loss: {np.log10(train_res['energy_error']):.4e}/{np.log10(train_res['energy_error_fiducial']):.4e}, {np.log10(val_res['energy_error']):.4e}/{np.log10(val_res['energy_error_fiducial']):.4e}, Time step: {train_res['time_step']:.4e}/{train_res['time_step_fiducial']:.4e}, {val_res['time_step']:.4e}/{val_res['time_step_fiducial']:.4e}, {val_res['time_step_std']:.4e}/{val_res['time_step_fiducial_std']:.4e}\")\n",
    "    print(f\"Epoch [{epoch}/{num_epochs}], Timestep error: {train_res['time_step_relative_error']:.4e}/{val_res['time_step_relative_error']:.4e}, Energy Loss: {np.log10(train_res['energy_error']):.4e}/{np.log10(train_res['energy_error_fiducial']):.4e}, {np.log10(val_res['energy_error']):.4e}/{np.log10(val_res['energy_error_fiducial']):.4e}, Time step: {train_res['time_step']:.4e}/{train_res['time_step_fiducial']:.4e}, {val_res['time_step']:.4e}/{val_res['time_step_fiducial']:.4e}, {val_res['time_step_std']:.4e}/{val_res['time_step_fiducial_std']:.4e}\")\n",
    "    #print(f\"Epoch [{epoch}/{num_epochs}], Train Loss: {train_res['train_loss']:.4e}, Val Loss: {val_res['val_loss']:.4e}, Energy Loss: {np.log10(train_res['energy_error']):.4e}/{np.log10(train_res['energy_error_fiducial']):.4e}, {np.log10(val_res['energy_error']):.4e}/{np.log10(val_res['energy_error_fiducial']):.4e}, energy_pred: {energy_pred:.4e}/{energy_init:.4e}, Time step: {time_step:.4e}/{time_step_fiducial:.4e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training routine\n",
    "num_epochs = 1000\n",
    "epoch0= epoch\n",
    "for epoch in range(epoch0, num_epochs):\n",
    "\n",
    "    train_loss = \\\n",
    "        train_one_epoch(model, optimizer, criterion, train_loader, input_mask, weights, device)\n",
    "    test_loss, energy_error, energy_error_std, energy_error_fiducial, energy_error_fiducial_std, energy_pred, energy_init, time_step, time_step_fiducial = \\\n",
    "        validate(model, criterion, test_loader, input_mask, weights, device)\n",
    "\n",
    "    if epoch > 5:\n",
    "        # Save the best model based on validation loss\n",
    "        if test_loss < best_val_loss:\n",
    "            best_val_loss = test_loss\n",
    "            torch.save(model.state_dict(), best_val_path)\n",
    "            traced_model = torch.jit.trace(model, example_input)\n",
    "            traced_model.save(base_path + f\"c++/best_model_loss.pt\")\n",
    "            print(f\"--> Best model saved at epoch {epoch} with val loss {best_val_loss:.4e}\")\n",
    "        \n",
    "        # Save the best model based on validation largest timestep\n",
    "        if time_step > best_largest_timestep:\n",
    "            best_largest_timestep = time_step\n",
    "            torch.save(model.state_dict(), best_timestep_path)\n",
    "            traced_model = torch.jit.trace(model, example_input)\n",
    "            traced_model.save(base_path + f\"c++/best_model_timestep.pt\")\n",
    "            print(f\"--> Best model saved at epoch {epoch} with largest timestep {best_largest_timestep:.4e}\")\n",
    "\n",
    "    # Save the last model after every epoch (or just once at the end)\n",
    "    torch.save(model.state_dict(), base_path + f\"model_{epoch}.pth\")\n",
    "    traced_model = torch.jit.trace(model, example_input)\n",
    "    traced_model.save(base_path + f\"c++/model_{epoch}.pt\")\n",
    "\n",
    "    #print(f\"Epoch [{epoch}/{num_epochs}], Train Loss: {train_loss:.4e}, Test Loss: {test_loss:.4e}, Energy Loss: {energy_error:.4e}/{energy_error_fiducial:.4e}, std: {energy_error_std:.4e}/{energy_error_fiducial_std:.4e}, Time step: {time_step:.4e}/{time_step_fiducial:.4e}\")\n",
    "    print(f\"Epoch [{epoch}/{num_epochs}], Train Loss: {train_loss:.4e}, Test Loss: {test_loss:.4e}, Energy Loss: {np.log10(energy_error):.4e}/{np.log10(energy_error_fiducial):.4e}, energy_pred: {energy_pred:.4e}/{energy_init:.4e}, Time step: {time_step:.4e}/{time_step_fiducial:.4e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], Test Loss: 4.4118e+01, Energy Loss: 1.3661e-03/2.7618e-01, std: 1.0723e-03/1.8289e-01, Time step: 7.1532e-11/2.0075e-08\n"
     ]
    }
   ],
   "source": [
    "input_size = 6     # Number of input features\n",
    "input_mask = np.r_[0:6]\n",
    "hidden_dims = [64,64]     # Number of hidden neurons\n",
    "hidden_dims = [16,32,16]     # Number of hidden neurons\n",
    "output_size = 2     # Number of output \n",
    "TargetEnergyError = 1e-5\n",
    "\n",
    "base_path = \"/mnt/home/yjo10/projects/AITimeStepper/data/models/three_body/\"\n",
    "best_val_path = base_path + \"best_model_loss.pth\"\n",
    "best_timestep_path = base_path + \"best_model_timestep.pth\"\n",
    "epoch = 13\n",
    "epoch = 20\n",
    "\n",
    "\n",
    "model_path = f\"model_{epoch}.pth\"\n",
    "\n",
    "weights = {\"time_step\":5, \"energy_loss\":1e-1}\n",
    "\n",
    "# Instantiate the model\n",
    "model = FullyConnectedNN(input_dim=input_size, output_dim=output_size, hidden_dims=hidden_dims, activation='relu', dropout=0.1, output_positive=True).to(device)\n",
    "\n",
    "# Load the state dictionary from a file\n",
    "state_dict = torch.load(base_path + model_path, map_location=torch.device('cpu'))\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# Set the model to evaluation mode (important for inference)\n",
    "model.eval()\n",
    "\n",
    "# Define the loss function (CrossEntropyLoss is common for classification tasks)\n",
    "criterion = CustomizableLoss3DM(nParticle=3, nAttribute=20, nBatch=batch_size,alpha=0.1, beta=1.0, gamma=1.0, TargetEnergyError=TargetEnergyError,\n",
    "                            data_min=data_min, data_max=data_max,device=device)\n",
    "\n",
    "\n",
    "test_loss, energy_error, energy_error_std, energy_error_fiducial, energy_error_fiducial_std, energy_pred, energy_init, time_step, time_step_fiducial = \\\n",
    "    validate(model, criterion, test_loader, input_mask, weights, device)\n",
    "print(f\"Epoch [{epoch}], Test Loss: {test_loss:.4e}, Energy Loss: {energy_error:.4e}/{energy_error_fiducial:.4e}, std: {energy_error_std:.4e}/{energy_error_fiducial_std:.4e}, Time step: {time_step:.4e}/{time_step_fiducial:.4e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Three Body from Canonical Timestepper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18708, 68])\n"
     ]
    }
   ],
   "source": [
    "def normalizer(_data):\n",
    "    _max = torch.abs(_data.max())\n",
    "    data_max = torch.ones(_data.size(), device=device)*_max\n",
    "    _data = _data/data_max\n",
    "    return _data, _max\n",
    "    \n",
    "def denormalizer(_data, _max):\n",
    "    data_max = torch.ones(_data.size(), device=device)*_max\n",
    "    return _data*data_max\n",
    "\n",
    "# Example unsupervised data: 100 samples with 10 features each\n",
    "data = np.load(\"../data/three_body_train_data.npy\")\n",
    "num_samples = data.shape[0]\n",
    "num_samples_start = int(data.shape[0]*0.95)\n",
    "num_samples_start = 0\n",
    "num_samples_end   = data.shape[0]\n",
    "num_samples = num_samples_end - num_samples_start\n",
    "num_features = data.shape[1]\n",
    "\n",
    "# Placeholder for input (magnitudes of velocities and accelerations)\n",
    "data_org = torch.tensor(data[num_samples_start:num_samples_end,:], dtype=dtype).to(device)\n",
    "data = torch.empty((num_samples,6+num_features), dtype=dtype).to(device)\n",
    "data[:,6:] = data_org\n",
    "\n",
    "\n",
    "# Magnitudes vel, acc, mass\n",
    "temp, tmax = normalizer(data_org[:,4:7])\n",
    "vel = denormalizer(torch.norm(temp, p=2, dim=1),tmax)\n",
    "acc = torch.empty((num_samples,4), dtype=dtype).to(device)\n",
    "\n",
    "temp,tmax = normalizer(data_org[:,7:10])\n",
    "acc[:,0] = denormalizer(torch.norm(temp, p=2, dim=1),tmax)\n",
    "temp,tmax = normalizer(data_org[:,10:13])\n",
    "acc[:,1] = denormalizer(torch.norm(temp, p=2, dim=1),tmax)\n",
    "temp,tmax = normalizer(data_org[:,13:16])\n",
    "acc[:,2] = denormalizer(torch.norm(temp, p=2, dim=1),tmax)\n",
    "temp,tmax = normalizer(data_org[:,16:19])\n",
    "acc[:,3] = denormalizer(torch.norm(temp, p=2, dim=1),tmax)\n",
    "mass = data_org[:,0]\n",
    "\n",
    "data[:,0] = vel\n",
    "data[:,1:5] = acc\n",
    "data[:,5] = mass\n",
    "\n",
    "# Normalize the data\n",
    "eps = torch.finfo(torch.double).tiny\n",
    "data_min = data[:,:6].min(axis=0, keepdim=True).values\n",
    "data_max = data[:,:6].max(axis=0, keepdim=True).values\n",
    "data[:,:6] = (data[:,:6] - data_min) / (data_max - data_min) +eps\n",
    "\n",
    "\n",
    "# Wrap the feature tensor in a TensorDataset\n",
    "# Each item from the dataset will be a tuple containing one tensor (X[i],)\n",
    "dataset = TensorDataset(data)\n",
    "\n",
    "# Define the proportion for the test set (e.g., 20%)\n",
    "test_ratio = 0.2\n",
    "num_test = int(num_samples * test_ratio)\n",
    "num_train = num_samples - num_test\n",
    "\n",
    "# Use random_split to split the dataset into train and test subsets\n",
    "# Define generator with a fixed seed\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_dataset, test_dataset = random_split(dataset, [num_train, num_test], generator=generator)\n",
    "\n",
    "# Create DataLoaders for the training and testing datasets\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3230e+43, device='cuda:0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_org[:,7:19].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.1760e+07,  6.9440e+07,  1.9930e+08,  ...,  7.5800e+20,\n",
       "          9.4280e+21,  2.6730e+22],\n",
       "        [ 7.3060e+07, -9.5400e+07,  2.7010e+06,  ...,  3.9260e+21,\n",
       "         -7.9120e+21, -2.3390e+21],\n",
       "        [-6.8400e+07,  8.8380e+07, -1.0550e+08,  ..., -5.4870e+21,\n",
       "          5.4520e+21, -1.0640e+22],\n",
       "        ...,\n",
       "        [-8.2630e+07, -2.7490e+08,  3.7450e+07,  ..., -1.1680e+22,\n",
       "          1.3660e+22,  6.4800e+22],\n",
       "        [ 1.0930e+08,  4.2830e+08, -2.7110e+08,  ..., -2.3880e+24,\n",
       "         -1.5960e+25,  2.5750e+25],\n",
       "        [-3.7300e+08, -1.4680e+09,  9.4750e+08,  ...,  8.5130e+24,\n",
       "          5.3420e+25, -8.9590e+25]], device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_org[:,7:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.9347e-03,  3.0354e-07,  2.8002e-12,  1.7239e-16,  7.9151e-22,\n",
       "          2.1084e-01],\n",
       "        [ 1.9106e-03,  1.7634e-08,  1.1221e-12,  3.9385e-17,  2.2971e-22,\n",
       "          5.9583e-01],\n",
       "        [ 6.5133e-04,  1.1625e-07,  1.3016e-12,  8.3355e-17,  3.4716e-22,\n",
       "          4.4962e-01],\n",
       "        ...,\n",
       "        [ 8.8039e-03,  5.1604e-07,  1.0358e-11,  4.4025e-16,  1.9285e-21,\n",
       "         2.2251e-308],\n",
       "        [ 1.1908e-02,  1.1904e-06,  1.6754e-10,  1.8762e-14,  8.8836e-19,\n",
       "          1.0000e+00],\n",
       "        [ 4.5579e-02,  4.9237e-06,  5.9044e-10,  6.5928e-14,  3.0595e-18,\n",
       "          2.5644e-01]], device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:,:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.9347e-03,  3.0354e-07,  2.8002e-12,  1.7239e-16,  7.9151e-22,\n",
       "          2.1084e-01],\n",
       "        [ 1.9106e-03,  1.7634e-08,  1.1221e-12,  3.9385e-17,  2.2971e-22,\n",
       "          5.9583e-01],\n",
       "        [ 6.5133e-04,  1.1625e-07,  1.3016e-12,  8.3355e-17,  3.4716e-22,\n",
       "          4.4962e-01],\n",
       "        ...,\n",
       "        [ 8.8039e-03,  5.1604e-07,  1.0358e-11,  4.4025e-16,  1.9285e-21,\n",
       "         2.2251e-308],\n",
       "        [ 1.1908e-02,  1.1904e-06,  1.6754e-10,  1.8762e-14,  8.8836e-19,\n",
       "          1.0000e+00],\n",
       "        [ 4.5579e-02,  4.9237e-06,  5.9044e-10,  6.5928e-14,  3.0595e-18,\n",
       "          2.5644e-01]], device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:,:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-05\n",
      "tensor([3.2997e-04, 2.5714e+04, 3.4986e-04, 3.4986e-04, 8.9298e+04, 3.8232e-03,\n",
      "        3.8232e-03, 3.6064e+05, 1.2763e-02, 1.2763e-02, 2.1405e+06, 6.9280e-03,\n",
      "        6.9280e-03, 7.2961e+06, 2.3218e-02, 2.3218e-02, 3.8597e+07, 5.3466e-03,\n",
      "        5.3466e-03, 1.1962e+08], device='cuda:0', grad_fn=<AbsBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import structures\n",
    "importlib.reload(structures)\n",
    "from structures import *\n",
    "import losses\n",
    "importlib.reload(losses)\n",
    "from losses import *\n",
    "TargetEnergyError = 1e-5\n",
    "#batch_size = 32\n",
    "criterion = CustomizableLoss3DM(nParticle=3, nAttribute=20, nBatch=batch_size,alpha=0.1, beta=0.1, gamma=10.0, TargetEnergyError=TargetEnergyError,\n",
    "                            data_min=data_min, data_max=data_max,device=device)\n",
    "X = data[:20,:]\n",
    "output = data[:20,[25,25]] #torch.zeros((X.shape[0],2)).to(device)\n",
    "loss, loss_terms = criterion(output, X)\n",
    "#output[:,0], X[:,-2], X[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.2500e-06, 6.2500e-06, 6.2500e-06,  ..., 1.2500e-05, 2.4410e-08,\n",
       "        2.4410e-08], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[:,25]#.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.return_types.min(\n",
       " values=tensor([0., 0., 0.], device='cuda:0'),\n",
       " indices=tensor([5041,    9,    9], device='cuda:0')),\n",
       " torch.return_types.max(\n",
       " values=tensor([1., 1., 1.], device='cuda:0'),\n",
       " indices=tensor([1649, 1649, 1649], device='cuda:0')),\n",
       " tensor([0.2625, 0.1272, 0.0918], device='cuda:0'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[train_dataset.indices,:3].min(dim=0), data[train_dataset.indices,:3].max(dim=0), data[train_dataset.indices,:3].mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.return_types.min(\n",
       " values=tensor([0.0003, 0.0000, 0.0000], device='cuda:0'),\n",
       " indices=tensor([368,  18,  18], device='cuda:0')),\n",
       " torch.return_types.max(\n",
       " values=tensor([0.9988, 0.9888, 0.9852], device='cuda:0'),\n",
       " indices=tensor([2865, 2865, 2865], device='cuda:0')),\n",
       " tensor([0.2565, 0.1216, 0.0869], device='cuda:0'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[test_dataset.indices,:3].min(dim=0), data[test_dataset.indices,:3].max(dim=0), data[test_dataset.indices,:3].mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-07 14:55:38,715] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed info: version=0.16.4, git-hash=unknown, git-branch=unknown\n",
      "[2025-04-07 14:55:38,715] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 1\n",
      "[2025-04-07 14:55:38,718] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2025-04-07 14:55:38,719] [INFO] [logging.py:128:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adam as basic optimizer\n",
      "[2025-04-07 14:55:38,719] [INFO] [logging.py:128:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2025-04-07 14:55:38,720] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam\n",
      "[2025-04-07 14:55:38,720] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>\n",
      "[2025-04-07 14:55:38,720] [INFO] [logging.py:128:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 1 optimizer\n",
      "[2025-04-07 14:55:38,721] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 500000000\n",
      "[2025-04-07 14:55:38,721] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 500000000\n",
      "[2025-04-07 14:55:38,721] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2025-04-07 14:55:38,722] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-07 14:55:39,729] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states\n",
      "[2025-04-07 14:55:39,732] [INFO] [utils.py:782:see_memory_usage] MA 3.76 GB         Max_MA 7.49 GB         CA 7.5 GB         Max_CA 7 GB \n",
      "[2025-04-07 14:55:39,734] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 69.74 GB, percent = 6.9%\n",
      "[2025-04-07 14:55:40,009] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states\n",
      "[2025-04-07 14:55:40,011] [INFO] [utils.py:782:see_memory_usage] MA 3.76 GB         Max_MA 3.76 GB         CA 7.5 GB         Max_CA 7 GB \n",
      "[2025-04-07 14:55:40,011] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 69.74 GB, percent = 6.9%\n",
      "[2025-04-07 14:55:40,012] [INFO] [stage_1_and_2.py:550:__init__] optimizer state initialized\n",
      "[2025-04-07 14:55:40,280] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2025-04-07 14:55:40,281] [INFO] [utils.py:782:see_memory_usage] MA 3.76 GB         Max_MA 3.76 GB         CA 7.5 GB         Max_CA 7 GB \n",
      "[2025-04-07 14:55:40,282] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 69.74 GB, percent = 6.9%\n",
      "[2025-04-07 14:55:40,294] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer\n",
      "[2025-04-07 14:55:40,295] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = None\n",
      "[2025-04-07 14:55:40,295] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2025-04-07 14:55:40,295] [INFO] [logging.py:128:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001], mom=[[0.9, 0.999]]\n",
      "[2025-04-07 14:55:40,296] [INFO] [config.py:1001:print] DeepSpeedEngine configuration:\n",
      "[2025-04-07 14:55:40,296] [INFO] [config.py:1005:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2025-04-07 14:55:40,296] [INFO] [config.py:1005:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'intra_op_parallelism': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}\n",
      "[2025-04-07 14:55:40,297] [INFO] [config.py:1005:print]   amp_enabled .................. False\n",
      "[2025-04-07 14:55:40,297] [INFO] [config.py:1005:print]   amp_params ................... False\n",
      "[2025-04-07 14:55:40,297] [INFO] [config.py:1005:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2025-04-07 14:55:40,298] [INFO] [config.py:1005:print]   bfloat16_enabled ............. False\n",
      "[2025-04-07 14:55:40,298] [INFO] [config.py:1005:print]   bfloat16_immediate_grad_update  False\n",
      "[2025-04-07 14:55:40,298] [INFO] [config.py:1005:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2025-04-07 14:55:40,299] [INFO] [config.py:1005:print]   checkpoint_tag_validation_enabled  True\n",
      "[2025-04-07 14:55:40,299] [INFO] [config.py:1005:print]   checkpoint_tag_validation_fail  False\n",
      "[2025-04-07 14:55:40,299] [INFO] [config.py:1005:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1552d1c37400>\n",
      "[2025-04-07 14:55:40,299] [INFO] [config.py:1005:print]   communication_data_type ...... None\n",
      "[2025-04-07 14:55:40,300] [INFO] [config.py:1005:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2025-04-07 14:55:40,300] [INFO] [config.py:1005:print]   curriculum_enabled_legacy .... False\n",
      "[2025-04-07 14:55:40,300] [INFO] [config.py:1005:print]   curriculum_params_legacy ..... False\n",
      "[2025-04-07 14:55:40,301] [INFO] [config.py:1005:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2025-04-07 14:55:40,301] [INFO] [config.py:1005:print]   data_efficiency_enabled ...... False\n",
      "[2025-04-07 14:55:40,301] [INFO] [config.py:1005:print]   dataloader_drop_last ......... False\n",
      "[2025-04-07 14:55:40,302] [INFO] [config.py:1005:print]   disable_allgather ............ False\n",
      "[2025-04-07 14:55:40,302] [INFO] [config.py:1005:print]   dump_state ................... False\n",
      "[2025-04-07 14:55:40,302] [INFO] [config.py:1005:print]   dynamic_loss_scale_args ...... None\n",
      "[2025-04-07 14:55:40,302] [INFO] [config.py:1005:print]   eigenvalue_enabled ........... False\n",
      "[2025-04-07 14:55:40,303] [INFO] [config.py:1005:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2025-04-07 14:55:40,303] [INFO] [config.py:1005:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2025-04-07 14:55:40,303] [INFO] [config.py:1005:print]   eigenvalue_layer_num ......... 0\n",
      "[2025-04-07 14:55:40,303] [INFO] [config.py:1005:print]   eigenvalue_max_iter .......... 100\n",
      "[2025-04-07 14:55:40,304] [INFO] [config.py:1005:print]   eigenvalue_stability ......... 1e-06\n",
      "[2025-04-07 14:55:40,304] [INFO] [config.py:1005:print]   eigenvalue_tol ............... 0.01\n",
      "[2025-04-07 14:55:40,304] [INFO] [config.py:1005:print]   eigenvalue_verbose ........... False\n",
      "[2025-04-07 14:55:40,305] [INFO] [config.py:1005:print]   elasticity_enabled ........... False\n",
      "[2025-04-07 14:55:40,305] [INFO] [config.py:1005:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2025-04-07 14:55:40,305] [INFO] [config.py:1005:print]   fp16_auto_cast ............... None\n",
      "[2025-04-07 14:55:40,305] [INFO] [config.py:1005:print]   fp16_enabled ................. False\n",
      "[2025-04-07 14:55:40,306] [INFO] [config.py:1005:print]   fp16_master_weights_and_gradients  False\n",
      "[2025-04-07 14:55:40,306] [INFO] [config.py:1005:print]   global_rank .................. 0\n",
      "[2025-04-07 14:55:40,306] [INFO] [config.py:1005:print]   grad_accum_dtype ............. None\n",
      "[2025-04-07 14:55:40,307] [INFO] [config.py:1005:print]   gradient_accumulation_steps .. 1\n",
      "[2025-04-07 14:55:40,307] [INFO] [config.py:1005:print]   gradient_clipping ............ 0.0\n",
      "[2025-04-07 14:55:40,307] [INFO] [config.py:1005:print]   gradient_predivide_factor .... 1.0\n",
      "[2025-04-07 14:55:40,307] [INFO] [config.py:1005:print]   graph_harvesting ............. False\n",
      "[2025-04-07 14:55:40,308] [INFO] [config.py:1005:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2025-04-07 14:55:40,308] [INFO] [config.py:1005:print]   initial_dynamic_scale ........ 65536\n",
      "[2025-04-07 14:55:40,308] [INFO] [config.py:1005:print]   load_universal_checkpoint .... False\n",
      "[2025-04-07 14:55:40,309] [INFO] [config.py:1005:print]   loss_scale ................... 0\n",
      "[2025-04-07 14:55:40,309] [INFO] [config.py:1005:print]   memory_breakdown ............. False\n",
      "[2025-04-07 14:55:40,309] [INFO] [config.py:1005:print]   mics_hierarchial_params_gather  False\n",
      "[2025-04-07 14:55:40,309] [INFO] [config.py:1005:print]   mics_shard_size .............. -1\n",
      "[2025-04-07 14:55:40,310] [INFO] [config.py:1005:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')\n",
      "[2025-04-07 14:55:40,310] [INFO] [config.py:1005:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2025-04-07 14:55:40,310] [INFO] [config.py:1005:print]   optimizer_legacy_fusion ...... False\n",
      "[2025-04-07 14:55:40,311] [INFO] [config.py:1005:print]   optimizer_name ............... adam\n",
      "[2025-04-07 14:55:40,311] [INFO] [config.py:1005:print]   optimizer_params ............. {'lr': 0.0001, 'betas': [0.9, 0.999], 'eps': 1e-08}\n",
      "[2025-04-07 14:55:40,311] [INFO] [config.py:1005:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2025-04-07 14:55:40,311] [INFO] [config.py:1005:print]   pld_enabled .................. False\n",
      "[2025-04-07 14:55:40,312] [INFO] [config.py:1005:print]   pld_params ................... False\n",
      "[2025-04-07 14:55:40,312] [INFO] [config.py:1005:print]   prescale_gradients ........... False\n",
      "[2025-04-07 14:55:40,312] [INFO] [config.py:1005:print]   scheduler_name ............... None\n",
      "[2025-04-07 14:55:40,313] [INFO] [config.py:1005:print]   scheduler_params ............. None\n",
      "[2025-04-07 14:55:40,313] [INFO] [config.py:1005:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2025-04-07 14:55:40,313] [INFO] [config.py:1005:print]   sparse_attention ............. None\n",
      "[2025-04-07 14:55:40,313] [INFO] [config.py:1005:print]   sparse_gradients_enabled ..... False\n",
      "[2025-04-07 14:55:40,314] [INFO] [config.py:1005:print]   steps_per_print .............. None\n",
      "[2025-04-07 14:55:40,314] [INFO] [config.py:1005:print]   tensor_parallel_config ....... dtype=torch.float16 autotp_size=0 tensor_parallel=TPConfig(tp_size=1, tp_grain_size=1, mpu=None, tp_group=None) injection_policy_tuple=None keep_module_on_host=False replace_with_kernel_inject=False\n",
      "[2025-04-07 14:55:40,314] [INFO] [config.py:1005:print]   timers_config ................ enabled=True synchronized=True\n",
      "[2025-04-07 14:55:40,314] [INFO] [config.py:1005:print]   train_batch_size ............. 64\n",
      "[2025-04-07 14:55:40,315] [INFO] [config.py:1005:print]   train_micro_batch_size_per_gpu  64\n",
      "[2025-04-07 14:55:40,315] [INFO] [config.py:1005:print]   use_data_before_expert_parallel_  False\n",
      "[2025-04-07 14:55:40,315] [INFO] [config.py:1005:print]   use_node_local_storage ....... False\n",
      "[2025-04-07 14:55:40,316] [INFO] [config.py:1005:print]   wall_clock_breakdown ......... False\n",
      "[2025-04-07 14:55:40,316] [INFO] [config.py:1005:print]   weight_quantization_config ... None\n",
      "[2025-04-07 14:55:40,316] [INFO] [config.py:1005:print]   world_size ................... 1\n",
      "[2025-04-07 14:55:40,316] [INFO] [config.py:1005:print]   zero_allow_untested_optimizer  False\n",
      "[2025-04-07 14:55:40,317] [INFO] [config.py:1005:print]   zero_config .................. stage=1 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False zeropp_loco_param=None mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True log_trace_cache_warnings=False\n",
      "[2025-04-07 14:55:40,317] [INFO] [config.py:1005:print]   zero_enabled ................. True\n",
      "[2025-04-07 14:55:40,317] [INFO] [config.py:1005:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2025-04-07 14:55:40,318] [INFO] [config.py:1005:print]   zero_optimization_stage ...... 1\n",
      "[2025-04-07 14:55:40,318] [INFO] [config.py:991:print_user_config]   json = {\n",
      "    \"train_batch_size\": 64, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"optimizer\": {\n",
      "        \"type\": \"Adam\", \n",
      "        \"params\": {\n",
      "            \"lr\": 0.0001, \n",
      "            \"betas\": [0.9, 0.999], \n",
      "            \"eps\": 1e-08\n",
      "        }\n",
      "    }, \n",
      "    \"fp32\": {\n",
      "        \"enabled\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 1\n",
      "    }\n",
      "}\n",
      "Epoch [0/1000], Timestep error: 9.7936e+08/1.1066e+09, Energy Loss: 9.3083e+00/-1.2078e+00, 8.7722e+00/-1.0583e+00, Time step: 8.8735e-01/1.0072e-07, 8.6065e-01/1.0129e-07, 2.7149e-03/1.7170e-07\n",
      "Epoch [1/1000], Timestep error: 9.3038e+08/1.0543e+09, Energy Loss: 9.2389e+00/-1.2078e+00, 8.7012e+00/-1.0583e+00, Time step: 8.4451e-01/1.0072e-07, 8.2417e-01/1.0129e-07, 5.0025e-03/1.7170e-07\n",
      "Epoch [2/1000], Timestep error: 8.6748e+08/9.7811e+08, Energy Loss: 9.1448e+00/-1.2078e+00, 8.5947e+00/-1.0583e+00, Time step: 7.9478e-01/1.0072e-07, 7.7211e-01/1.0129e-07, 8.3177e-03/1.7170e-07\n",
      "Epoch [3/1000], Timestep error: 8.3726e+08/9.7029e+08, Energy Loss: 9.0798e+00/-1.2078e+00, 8.5909e+00/-1.0583e+00, Time step: 7.7107e-01/1.0072e-07, 7.7025e-01/1.0129e-07, 8.6152e-03/1.7170e-07\n",
      "Epoch [4/1000], Timestep error: 8.2370e+08/9.4439e+08, Energy Loss: 9.0692e+00/-1.2078e+00, 8.5718e+00/-1.0583e+00, Time step: 7.6560e-01/1.0072e-07, 7.6026e-01/1.0129e-07, 1.0328e-02/1.7170e-07\n",
      "Epoch [5/1000], Timestep error: 8.0006e+08/9.1374e+08, Energy Loss: 9.0523e+00/-1.2078e+00, 8.5468e+00/-1.0583e+00, Time step: 7.5423e-01/1.0072e-07, 7.4805e-01/1.0129e-07, 1.2098e-02/1.7170e-07\n",
      "--> Best model saved at epoch 6 with val loss 5.7580e+01\n",
      "--> Best model saved at epoch 6 with largest timestep 7.3280e-01\n",
      "Epoch [6/1000], Timestep error: 7.7128e+08/8.7469e+08, Energy Loss: 9.0206e+00/-1.2078e+00, 8.5151e+00/-1.0583e+00, Time step: 7.4065e-01/1.0072e-07, 7.3280e-01/1.0129e-07, 1.4476e-02/1.7170e-07\n",
      "--> Best model saved at epoch 7 with val loss 5.6573e+01\n",
      "Epoch [7/1000], Timestep error: 7.3568e+08/8.2690e+08, Energy Loss: 8.9814e+00/-1.2078e+00, 8.4746e+00/-1.0583e+00, Time step: 7.2365e-01/1.0072e-07, 7.1397e-01/1.0129e-07, 1.7302e-02/1.7170e-07\n",
      "--> Best model saved at epoch 8 with val loss 5.5210e+01\n",
      "Epoch [8/1000], Timestep error: 6.9378e+08/7.7442e+08, Energy Loss: 8.9319e+00/-1.2078e+00, 8.4187e+00/-1.0583e+00, Time step: 7.0209e-01/1.0072e-07, 6.8912e-01/1.0129e-07, 2.0095e-02/1.7170e-07\n",
      "--> Best model saved at epoch 9 with val loss 5.3510e+01\n",
      "Epoch [9/1000], Timestep error: 6.4792e+08/7.1161e+08, Energy Loss: 8.8825e+00/-1.2078e+00, 8.3467e+00/-1.0583e+00, Time step: 6.7408e-01/1.0072e-07, 6.5821e-01/1.0129e-07, 2.3374e-02/1.7170e-07\n",
      "--> Best model saved at epoch 10 with val loss 5.1525e+01\n",
      "Epoch [10/1000], Timestep error: 5.9198e+08/6.4052e+08, Energy Loss: 8.8116e+00/-1.2078e+00, 8.2605e+00/-1.0583e+00, Time step: 6.4130e-01/1.0072e-07, 6.2271e-01/1.0129e-07, 2.7147e-02/1.7170e-07\n",
      "--> Best model saved at epoch 11 with val loss 4.8996e+01\n",
      "Epoch [11/1000], Timestep error: 5.2868e+08/5.6124e+08, Energy Loss: 8.6865e+00/-1.2078e+00, 8.1472e+00/-1.0583e+00, Time step: 6.0163e-01/1.0072e-07, 5.7875e-01/1.0129e-07, 3.0911e-02/1.7170e-07\n",
      "--> Best model saved at epoch 12 with val loss 4.6521e+01\n",
      "Epoch [12/1000], Timestep error: 4.6343e+08/4.9198e+08, Energy Loss: 8.5720e+00/-1.2078e+00, 8.0267e+00/-1.0583e+00, Time step: 5.5779e-01/1.0072e-07, 5.3687e-01/1.0129e-07, 3.2944e-02/1.7170e-07\n",
      "--> Best model saved at epoch 13 with val loss 4.4366e+01\n",
      "Epoch [13/1000], Timestep error: 4.1051e+08/4.3091e+08, Energy Loss: 8.4757e+00/-1.2078e+00, 7.9153e+00/-1.0583e+00, Time step: 5.1954e-01/1.0072e-07, 5.0008e-01/1.0129e-07, 3.5146e-02/1.7170e-07\n",
      "--> Best model saved at epoch 14 with val loss 4.0248e+01\n",
      "Epoch [14/1000], Timestep error: 3.4430e+08/3.2345e+08, Energy Loss: 8.3386e+00/-1.2078e+00, 7.7033e+00/-1.0583e+00, Time step: 4.7342e-01/1.0072e-07, 4.3364e-01/1.0129e-07, 4.0358e-02/1.7170e-07\n",
      "--> Best model saved at epoch 15 with val loss 3.6164e+01\n",
      "Epoch [15/1000], Timestep error: 2.5874e+08/2.4842e+08, Energy Loss: 8.0735e+00/-1.2078e+00, 7.4574e+00/-1.0583e+00, Time step: 4.0003e-01/1.0072e-07, 3.6955e-01/1.0129e-07, 4.1330e-02/1.7170e-07\n",
      "--> Best model saved at epoch 16 with val loss 3.2605e+01\n",
      "Epoch [16/1000], Timestep error: 2.0410e+08/1.8991e+08, Energy Loss: 7.8387e+00/-1.2078e+00, 7.1946e+00/-1.0583e+00, Time step: 3.4203e-01/1.0072e-07, 3.1185e-01/1.0129e-07, 4.0600e-02/1.7170e-07\n",
      "--> Best model saved at epoch 17 with val loss 2.9241e+01\n",
      "Epoch [17/1000], Timestep error: 1.5391e+08/1.4123e+08, Energy Loss: 7.5686e+00/-1.2078e+00, 6.8954e+00/-1.0583e+00, Time step: 2.8450e-01/1.0072e-07, 2.5694e-01/1.0129e-07, 3.8917e-02/1.7170e-07\n",
      "--> Best model saved at epoch 18 with val loss 2.7443e+01\n",
      "Epoch [18/1000], Timestep error: 1.1658e+08/1.1576e+08, Energy Loss: 7.2782e+00/-1.2078e+00, 6.6944e+00/-1.0583e+00, Time step: 2.3541e-01/1.0072e-07, 2.2568e-01/1.0129e-07, 3.7278e-02/1.7170e-07\n",
      "--> Best model saved at epoch 19 with val loss 2.6033e+01\n",
      "Epoch [19/1000], Timestep error: 9.8614e+07/9.8053e+07, Energy Loss: 7.0400e+00/-1.2078e+00, 6.5076e+00/-1.0583e+00, Time step: 2.0817e-01/1.0072e-07, 2.0030e-01/1.0129e-07, 3.5348e-02/1.7170e-07\n",
      "--> Best model saved at epoch 20 with val loss 2.5262e+01\n",
      "Epoch [20/1000], Timestep error: 8.7043e+07/8.5160e+07, Energy Loss: 6.9576e+00/-1.2078e+00, 6.3578e+00/-1.0583e+00, Time step: 1.9058e-01/1.0072e-07, 1.8180e-01/1.0129e-07, 3.4036e-02/1.7170e-07\n",
      "--> Best model saved at epoch 21 with val loss 2.4405e+01\n",
      "Epoch [21/1000], Timestep error: 7.4583e+07/6.8743e+07, Energy Loss: 6.7510e+00/-1.2078e+00, 6.1280e+00/-1.0583e+00, Time step: 1.7061e-01/1.0072e-07, 1.5683e-01/1.0129e-07, 3.1853e-02/1.7170e-07\n",
      "Epoch [22/1000], Timestep error: 6.7644e+07/7.3080e+07, Energy Loss: 6.6624e+00/-1.2078e+00, 6.1998e+00/-1.0583e+00, Time step: 1.5924e-01/1.0072e-07, 1.6432e-01/1.0129e-07, 3.2491e-02/1.7170e-07\n",
      "Epoch [23/1000], Timestep error: 6.9713e+07/7.1709e+07, Energy Loss: 6.6811e+00/-1.2078e+00, 6.1813e+00/-1.0583e+00, Time step: 1.6314e-01/1.0072e-07, 1.6244e-01/1.0129e-07, 3.2282e-02/1.7170e-07\n",
      "Epoch [24/1000], Timestep error: 6.8185e+07/6.9583e+07, Energy Loss: 6.6532e+00/-1.2078e+00, 6.1518e+00/-1.0583e+00, Time step: 1.6083e-01/1.0072e-07, 1.5945e-01/1.0129e-07, 3.1964e-02/1.7170e-07\n",
      "--> Best model saved at epoch 25 with val loss 2.4396e+01\n",
      "Epoch [25/1000], Timestep error: 6.6713e+07/6.8872e+07, Energy Loss: 6.6359e+00/-1.2078e+00, 6.1446e+00/-1.0583e+00, Time step: 1.5869e-01/1.0072e-07, 1.5876e-01/1.0129e-07, 3.1870e-02/1.7170e-07\n",
      "--> Best model saved at epoch 26 with val loss 2.4224e+01\n",
      "Epoch [26/1000], Timestep error: 6.4474e+07/6.4767e+07, Energy Loss: 6.6189e+00/-1.2078e+00, 6.0746e+00/-1.0583e+00, Time step: 1.5490e-01/1.0072e-07, 1.5203e-01/1.0129e-07, 3.0993e-02/1.7170e-07\n",
      "Epoch [27/1000], Timestep error: 6.3092e+07/6.5870e+07, Energy Loss: 6.5678e+00/-1.2078e+00, 6.1002e+00/-1.0583e+00, Time step: 1.5271e-01/1.0072e-07, 1.5454e-01/1.0129e-07, 3.1274e-02/1.7170e-07\n",
      "--> Best model saved at epoch 28 with val loss 2.4210e+01\n",
      "Epoch [28/1000], Timestep error: 6.2682e+07/6.3784e+07, Energy Loss: 6.5698e+00/-1.2078e+00, 6.0695e+00/-1.0583e+00, Time step: 1.5257e-01/1.0072e-07, 1.5159e-01/1.0129e-07, 3.0954e-02/1.7170e-07\n",
      "--> Best model saved at epoch 29 with val loss 2.4155e+01\n",
      "Epoch [29/1000], Timestep error: 6.1861e+07/6.2918e+07, Energy Loss: 6.5630e+00/-1.2078e+00, 6.0575e+00/-1.0583e+00, Time step: 1.5142e-01/1.0072e-07, 1.5053e-01/1.0129e-07, 3.0782e-02/1.7170e-07\n",
      "--> Best model saved at epoch 30 with val loss 2.4051e+01\n",
      "Epoch [30/1000], Timestep error: 5.9523e+07/6.0665e+07, Energy Loss: 6.5081e+00/-1.2078e+00, 6.0171e+00/-1.0583e+00, Time step: 1.4748e-01/1.0072e-07, 1.4684e-01/1.0129e-07, 3.0287e-02/1.7170e-07\n",
      "--> Best model saved at epoch 31 with val loss 2.4000e+01\n",
      "Epoch [31/1000], Timestep error: 5.9192e+07/5.9537e+07, Energy Loss: 6.5200e+00/-1.2078e+00, 6.0007e+00/-1.0583e+00, Time step: 1.4723e-01/1.0072e-07, 1.4542e-01/1.0129e-07, 3.0054e-02/1.7170e-07\n",
      "--> Best model saved at epoch 32 with val loss 2.3580e+01\n",
      "Epoch [32/1000], Timestep error: 5.5937e+07/5.1384e+07, Energy Loss: 6.4626e+00/-1.2078e+00, 5.8251e+00/-1.0583e+00, Time step: 1.4152e-01/1.0072e-07, 1.3042e-01/1.0129e-07, 2.8009e-02/1.7170e-07\n",
      "--> Best model saved at epoch 33 with val loss 2.3511e+01\n",
      "Epoch [33/1000], Timestep error: 4.9749e+07/5.0219e+07, Energy Loss: 6.3026e+00/-1.2078e+00, 5.8031e+00/-1.0583e+00, Time step: 1.2921e-01/1.0072e-07, 1.2866e-01/1.0129e-07, 2.7793e-02/1.7170e-07\n",
      "--> Best model saved at epoch 34 with val loss 2.3507e+01\n",
      "Epoch [34/1000], Timestep error: 4.8878e+07/4.8969e+07, Energy Loss: 6.2737e+00/-1.2078e+00, 5.7737e+00/-1.0583e+00, Time step: 1.2762e-01/1.0072e-07, 1.2638e-01/1.0129e-07, 2.7439e-02/1.7170e-07\n",
      "--> Best model saved at epoch 35 with val loss 2.3488e+01\n",
      "Epoch [35/1000], Timestep error: 4.7374e+07/4.7901e+07, Energy Loss: 6.2492e+00/-1.2078e+00, 5.7541e+00/-1.0583e+00, Time step: 1.2507e-01/1.0072e-07, 1.2487e-01/1.0129e-07, 2.7233e-02/1.7170e-07\n",
      "Epoch [36/1000], Timestep error: 4.7275e+07/4.7920e+07, Energy Loss: 6.2508e+00/-1.2078e+00, 5.7584e+00/-1.0583e+00, Time step: 1.2509e-01/1.0072e-07, 1.2527e-01/1.0129e-07, 2.7254e-02/1.7170e-07\n",
      "Epoch [37/1000], Timestep error: 5.4944e+07/5.8063e+07, Energy Loss: 6.4327e+00/-1.2078e+00, 5.9832e+00/-1.0583e+00, Time step: 1.4063e-01/1.0072e-07, 1.4488e-01/1.0129e-07, 2.9226e-02/1.7170e-07\n",
      "Epoch [38/1000], Timestep error: 5.6774e+07/5.7748e+07, Energy Loss: 6.4727e+00/-1.2078e+00, 5.9807e+00/-1.0583e+00, Time step: 1.4459e-01/1.0072e-07, 1.4472e-01/1.0129e-07, 2.9191e-02/1.7170e-07\n",
      "--> Best model saved at epoch 39 with val loss 2.3434e+01\n",
      "Epoch [39/1000], Timestep error: 5.4932e+07/4.9233e+07, Energy Loss: 6.4324e+00/-1.2078e+00, 5.8013e+00/-1.0583e+00, Time step: 1.4131e-01/1.0072e-07, 1.2928e-01/1.0129e-07, 2.7335e-02/1.7170e-07\n",
      "Epoch [40/1000], Timestep error: 5.0002e+07/5.0699e+07, Energy Loss: 6.3216e+00/-1.2078e+00, 5.8282e+00/-1.0583e+00, Time step: 1.3138e-01/1.0072e-07, 1.3160e-01/1.0129e-07, 2.7556e-02/1.7170e-07\n",
      "Epoch [41/1000], Timestep error: 5.2263e+07/5.5415e+07, Energy Loss: 6.3330e+00/-1.2078e+00, 5.9339e+00/-1.0583e+00, Time step: 1.3584e-01/1.0072e-07, 1.4073e-01/1.0129e-07, 2.8629e-02/1.7170e-07\n",
      "Epoch [42/1000], Timestep error: 5.4341e+07/5.4922e+07, Energy Loss: 6.4193e+00/-1.2078e+00, 5.9263e+00/-1.0583e+00, Time step: 1.4024e-01/1.0072e-07, 1.4010e-01/1.0129e-07, 2.8531e-02/1.7170e-07\n",
      "Epoch [43/1000], Timestep error: 5.3762e+07/5.3676e+07, Energy Loss: 6.4051e+00/-1.2078e+00, 5.9018e+00/-1.0583e+00, Time step: 1.3933e-01/1.0072e-07, 1.3794e-01/1.0129e-07, 2.8294e-02/1.7170e-07\n",
      "Epoch [44/1000], Timestep error: 5.2717e+07/5.3161e+07, Energy Loss: 6.3854e+00/-1.2078e+00, 5.8921e+00/-1.0583e+00, Time step: 1.3739e-01/1.0072e-07, 1.3714e-01/1.0129e-07, 2.8179e-02/1.7170e-07\n"
     ]
    }
   ],
   "source": [
    "import structures\n",
    "importlib.reload(structures)\n",
    "from structures import *\n",
    "import losses\n",
    "importlib.reload(losses)\n",
    "from losses import *\n",
    "import trainer\n",
    "importlib.reload(trainer)\n",
    "from trainer import *\n",
    "\n",
    "input_mask = np.r_[0:6]\n",
    "input_size = len(input_mask)\n",
    "#hidden_dims = [32,64,64,32]     # Number of hidden neurons\n",
    "hidden_dims = [8,16,16,4]     # Number of hidden neurons\n",
    "#hidden_dims = [16,128,32,8]     # Number of hidden neurons\n",
    "#hidden_dims = [8,8]     # Number of hidden neurons\n",
    "output_size = 2     # Number of output \n",
    "TargetEnergyError = 1e-2\n",
    "weights = {\"time_step\":0.1, \"energy_loss\":1}\n",
    "\n",
    "# Instantiate the model\n",
    "try: \n",
    "    del mode\n",
    "    l\n",
    "    print(\"model deleted\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "ds_config = {\n",
    "    \"train_batch_size\": batch_size,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"Adam\",\n",
    "        \"params\": {\"lr\": 1e-4, \"betas\": [0.9, 0.999], \"eps\": 1e-8}\n",
    "    },\n",
    "    \"fp32\": {\n",
    "        \"enabled\": True  # Enables mixed precision training\n",
    "    },\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 1  # Enable ZeRO Stage 1 for memory optimization\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "#model = SimpleNN(input_size, hidden_size, output_size).to(device)\n",
    "model = FullyConnectedNN(input_dim=input_size, output_dim=output_size, hidden_dims=hidden_dims, activation='relu', dropout=0.0, output_positive=True).to(device)\n",
    "#model = FullyConnectedNN(input_dim=input_size, output_dim=output_size, hidden_dims=hidden_dims, activation='relu', dropout=0.0, output_positive=False).to(device)\n",
    "\n",
    "\n",
    "model_engine, optimizer, _, _ = deepspeed.initialize(\n",
    "    model=model,\n",
    "    model_parameters=model.parameters(),\n",
    "    config=ds_config\n",
    ")\n",
    "\n",
    "# Define the loss function (CrossEntropyLoss is common for classification tasks)\n",
    "criterion = CustomizableLoss3DMAdjusted(nParticle=3, nAttribute=20, nBatch=batch_size,alpha=weights['time_step'], beta=weights['energy_loss'], gamma=weights['energy_loss'], TargetEnergyError=TargetEnergyError,\n",
    "                            data_min=data_min, data_max=data_max,device=device)\n",
    "\n",
    "# Define the optimizer (Stochastic Gradient Descent in this example)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "#optimizer = optim.AdamW(model.parameters(), lr=0.00001)\n",
    "#optimizer = optim.AdamW(model.parameters(), lr=0.00001)\n",
    "\n",
    "\n",
    "\n",
    "# Paths to save best and last models\n",
    "base_path = \"/mnt/home/yjo10/projects/AITimeStepper/data/models/three_body/\"\n",
    "best_val_path = base_path + \"best_model_loss_adjusted.pth\"\n",
    "best_timestep_path = base_path + \"best_model_timestep_adjusted.pth\"\n",
    "#last_model_path = base_path + f\"last_model_{epoch}.pth\"\n",
    "best_val_loss = float(\"inf\")\n",
    "best_largest_timestep = 0\n",
    "with open(base_path+\"c++/normalization_factors_adjusted.txt\", \"w\") as f:\n",
    "    f.write(f\"{data_min[0][0]} {data_min[0][1]} {data_min[0][2]} {data_min[0][3]} {data_min[0][4]} {data_min[0][5]}\\n\")    \n",
    "    f.write(f\"{data_max[0][0]} {data_max[0][1]} {data_max[0][2]} {data_max[0][3]} {data_max[0][4]} {data_max[0][5]}\\n\")    \n",
    "\n",
    "example_input = torch.randn(1, input_size).to(device)\n",
    "exp_time_step = 1\n",
    "exp_energy_loss = 1\n",
    "# Training routine\n",
    "num_epochs = 1000\n",
    "lists = {\"training_loss\":[], \"val_loss\":[], \"training_energy\":[], \"val_energy\":[], \"training_time_step\":[], \"val_time_step\":[]}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    #train_loss, train_energy = \\\n",
    "    #    train_one_epoch(model, optimizer, criterion, train_loader, input_mask, weights, device)\n",
    "    train_res = train_one_epoch_deepspeed(model_engine, optimizer, criterion, train_loader, input_mask, weights, device)\n",
    "        \n",
    "    #test_loss, energy_error, energy_error_std, energy_error_fiducial, energy_error_fiducial_std, energy_pred, energy_init, time_step, time_step_fiducial = \\\n",
    "    #    validate(model, criterion, test_loader, input_mask, weights, device)\n",
    "    val_res = validate_deepspeed(model_engine, criterion, test_loader, input_mask, weights, device)\n",
    "\n",
    "    lists[\"training_loss\"].append(train_res[\"train_loss\"])\n",
    "    lists[\"training_energy\"].append(train_res[\"energy_error\"])\n",
    "    lists[\"training_time_step\"].append(train_res[\"time_step\"])\n",
    "\n",
    "    lists[\"val_loss\"].append(val_res[\"val_loss\"])\n",
    "    lists[\"val_energy\"].append(val_res[\"energy_error\"])\n",
    "    lists[\"val_time_step\"].append(val_res[\"time_step\"])\n",
    "\n",
    "    if epoch > 5:\n",
    "        # Save the best model based on validation loss\n",
    "        if val_res['val_loss'] < best_val_loss:\n",
    "            best_val_loss = val_res['val_loss']\n",
    "            torch.save(model.state_dict(), best_val_path)\n",
    "            #traced_model = torch.jit.trace(model, example_input)\n",
    "            traced_model = torch.jit.script(model)\n",
    "            traced_model.save(base_path + f\"c++/best_model_loss_adjusted.pt\")\n",
    "            print(f\"--> Best model saved at epoch {epoch} with val loss {best_val_loss:.4e}\")\n",
    "        \n",
    "        # Save the best model based on validation largest timestep\n",
    "        if val_res['time_step'] > best_largest_timestep:\n",
    "            best_largest_timestep = val_res['time_step']\n",
    "            torch.save(model.state_dict(), best_timestep_path)\n",
    "            #traced_model = torch.jit.trace(model, example_input)\n",
    "            traced_model = torch.jit.script(model)\n",
    "            traced_model.save(base_path + f\"c++/best_model_timestep_adjusted.pt\")\n",
    "            print(f\"--> Best model saved at epoch {epoch} with largest timestep {best_largest_timestep:.4e}\")\n",
    "\n",
    "    # Save the last model after every epoch (or just once at the end)\n",
    "    torch.save(model.state_dict(), base_path + f\"model_{epoch}_adjusted.pth\")\n",
    "    #traced_model = torch.jit.trace(model, example_input)\n",
    "    traced_model = torch.jit.script(model)\n",
    "    traced_model.save(base_path + f\"c++/model_{epoch}_adjusted.pt\")\n",
    "\n",
    "\n",
    "\n",
    "    fig, axes = pu.generateAxesForMultiplePlots(shape=(1,3),figsize=(10,10),hspace=0.1,wspace=0.1,\n",
    "                                    gridspec=None)\n",
    "    for i, (key, value) in enumerate(lists.items()):\n",
    "        y = i//2\n",
    "        axes[y].plot(range(epoch+1), value, label=key)\n",
    "        axes[y].scatter(range(epoch+1), value)\n",
    "        axes[y].set_yscale(\"log\")\n",
    "\n",
    "\n",
    "    axes[2].axhline(y=val_res['time_step_fiducial'], c='r',alpha=0.5,zorder=-1,label=\"Timestep Fiducial\")\n",
    "    axes[1].axhline(y=TargetEnergyError, c='r',alpha=0.5,zorder=-1,label=\"Target energy\")\n",
    "    #plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left', borderaxespad=0.)\n",
    "    axes[0].legend()\n",
    "    axes[1].legend()\n",
    "    axes[2].legend()\n",
    "    #plt.tight_layout()\n",
    "    plt.savefig(\"learning_curve_adjusted.png\",dpi=100)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    fig, axes = pu.generateAxesForMultiplePlots(shape=(1,2),figsize=(10,15),hspace=0.1,wspace=0.1,\n",
    "                                    gridspec=None)\n",
    "    # Get one batch from the validation loader\n",
    "    dataiter = iter(train_loader)\n",
    "    inputs, = next(dataiter)\n",
    "\n",
    "    # Determine how many samples to take (if batch size < 50, take the whole batch)\n",
    "    num_samples = min(50, batch_size)\n",
    "\n",
    "    # Randomly select indices from the batch\n",
    "    indices = random.sample(range(batch_size), num_samples)\n",
    "    sampled_inputs = inputs[:,input_mask][indices]\n",
    "    sampled_targets = inputs[indices,25]\n",
    "\n",
    "    # Compute model predictions with no gradient computation\n",
    "    with torch.no_grad():\n",
    "        sampled_predictions = model(sampled_inputs)\n",
    "\n",
    "    # Convert tensors to numpy arrays for plotting\n",
    "    sampled_predictions = sampled_predictions[:,0].cpu().numpy().flatten()\n",
    "    sampled_targets = sampled_targets.cpu().numpy().flatten()\n",
    "\n",
    "    acc = inputs[:,1:5][indices]*(data_max[:,1:5]-data_min[:,1:5]) + data_min[:,1:5]\n",
    "    dt_fid = torch.sqrt((acc[:,0]*acc[:,2]+acc[:,1]**2)/(acc[:,1]*acc[:,3]+acc[:,2]**2)).cpu().numpy().flatten()\n",
    "    dt = sampled_predictions*dt_fid\n",
    "\n",
    "    # Create sample indices for the x-axis (1st sample, 2nd sample, etc.)\n",
    "    sample_indices = list(range(1, num_samples + 1))\n",
    "\n",
    "    # Plot predictions and ground truth vs sample number\n",
    "    # plt.figure(figsize=(8, 6))\n",
    "    # Add vertical lines for each data point\n",
    "    for x in sample_indices:\n",
    "        axes[0].axvline(x=x, color='grey', linestyle='-', alpha=0.2,zorder=0)\n",
    "    axes[0].scatter(sample_indices, sampled_targets, marker='o', label='Ground Truth', fc=\"none\", ec=\"k\",zorder=10)\n",
    "    axes[0].scatter(sample_indices, dt, marker='s', label='Predictions', fc=\"none\",ec=\"r\" ,zorder=10)\n",
    "    axes[0].scatter(sample_indices, dt_fid, marker='s', label='Fiducial', fc=\"none\",ec=\"b\" ,zorder=10)\n",
    "    axes[0].set_yscale(\"log\")\n",
    "    axes[0].set_xlabel('Sample Number')\n",
    "    axes[0].set_ylabel('Value')\n",
    "\n",
    "    # Get one batch from the validation loader\n",
    "    dataiter = iter(test_loader)\n",
    "    inputs, = next(dataiter)\n",
    "\n",
    "    # Determine how many samples to take (if batch size < 50, take the whole batch)\n",
    "    num_samples = min(50, batch_size)\n",
    "\n",
    "    # Randomly select indices from the batch\n",
    "    indices = random.sample(range(batch_size), num_samples)\n",
    "    sampled_inputs = inputs[:,input_mask][indices]\n",
    "    sampled_targets = inputs[indices,25]\n",
    "\n",
    "    # Compute model predictions with no gradient computation\n",
    "    with torch.no_grad():\n",
    "        sampled_predictions = model(sampled_inputs)\n",
    "\n",
    "    # Convert tensors to numpy arrays for plotting\n",
    "    sampled_predictions = sampled_predictions[:,0].cpu().numpy().flatten()\n",
    "    sampled_targets = sampled_targets.cpu().numpy().flatten()\n",
    "\n",
    "    acc = inputs[:,1:5][indices]*(data_max[:,1:5]-data_min[:,1:5]) + data_min[:,1:5]\n",
    "    dt = torch.sqrt((acc[:,0]*acc[:,2]+acc[:,1]**2)/(acc[:,1]*acc[:,3]+acc[:,2]**2))\n",
    "    dt = sampled_predictions*dt.cpu().numpy().flatten()\n",
    "\n",
    "    # Create sample indices for the x-axis (1st sample, 2nd sample, etc.)\n",
    "    sample_indices = list(range(1, num_samples + 1))\n",
    "\n",
    "    # Plot predictions and ground truth vs sample number\n",
    "    # plt.figure(figsize=(8, 6))\n",
    "    # Add vertical lines for each data point\n",
    "    for x in sample_indices:\n",
    "        axes[1].axvline(x=x, color='grey', linestyle='-', alpha=0.2,zorder=0)\n",
    "    axes[1].scatter(sample_indices, sampled_targets, marker='o', label='Ground Truth', fc=\"none\", ec=\"k\",zorder=10)\n",
    "    axes[1].scatter(sample_indices, dt, marker='s', label='Predictions', fc=\"none\",ec=\"r\" ,zorder=10)\n",
    "    axes[1].set_yscale(\"log\")\n",
    "    axes[1].set_xlabel('Sample Number')\n",
    "    axes[1].set_ylabel('Value')\n",
    "\n",
    "    axes[0].set_title(f'Epoch [{epoch}/{num_epochs}] Predictions and Ground Truth vs. Sample Number')\n",
    "    #plt.legend()\n",
    "    plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left', borderaxespad=0.)\n",
    "    plt.savefig(\"samples_adjusted.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    if time_step < time_step_fiducial:\n",
    "        weights['time_step'] += 0.1*exp_time_step\n",
    "        exp_time_step += 1\n",
    "    else:\n",
    "        weights['time_step'] += 0\n",
    "        exp_time_step = 1\n",
    "\n",
    "    if energy_error > energy_error_fiducial:\n",
    "        weights['energy_loss'] += 0.1*exp_energy_loss\n",
    "        exp_energy_loss += 1\n",
    "    else:\n",
    "        weights['energy_loss'] += 0\n",
    "        exp_energy_loss = 1\n",
    "        \"\"\"\n",
    "\n",
    "    #print(f\"Epoch [{epoch}/{num_epochs}], Train Loss: {train_loss:.4e}, Test Loss: {test_loss:.4e}, Energy Loss: {energy_error:.4e}/{energy_error_fiducial:.4e}, std: {energy_error_std:.4e}/{energy_error_fiducial_std:.4e}, Time step: {time_step:.4e}/{time_step_fiducial:.4e}\")\n",
    "    #print(f\"Epoch [{epoch}/{num_epochs}], Train Loss: {train_res['train_loss']:.4e}, Val Loss: {val_res['val_loss']:.4e}, Energy Loss: {np.log10(train_res['energy_error']):.4e}/{np.log10(train_res['energy_error_fiducial']):.4e}, {np.log10(val_res['energy_error']):.4e}/{np.log10(val_res['energy_error_fiducial']):.4e}, Time step: {train_res['time_step']:.4e}/{train_res['time_step_fiducial']:.4e}, {val_res['time_step']:.4e}/{val_res['time_step_fiducial']:.4e}, {val_res['time_step_std']:.4e}/{val_res['time_step_fiducial_std']:.4e}\")\n",
    "    print(f\"Epoch [{epoch}/{num_epochs}], Timestep error: {train_res['time_step_relative_error']:.4e}/{val_res['time_step_relative_error']:.4e}, Energy Loss: {np.log10(train_res['energy_error']):.4e}/{np.log10(train_res['energy_error_fiducial']):.4e}, {np.log10(val_res['energy_error']):.4e}/{np.log10(val_res['energy_error_fiducial']):.4e}, Time step: {train_res['time_step']:.4e}/{train_res['time_step_fiducial']:.4e}, {val_res['time_step']:.4e}/{val_res['time_step_fiducial']:.4e}, {val_res['time_step_std']:.4e}/{val_res['time_step_fiducial_std']:.4e}\")\n",
    "    #print(f\"Epoch [{epoch}/{num_epochs}], Train Loss: {train_res['train_loss']:.4e}, Val Loss: {val_res['val_loss']:.4e}, Energy Loss: {np.log10(train_res['energy_error']):.4e}/{np.log10(train_res['energy_error_fiducial']):.4e}, {np.log10(val_res['energy_error']):.4e}/{np.log10(val_res['energy_error_fiducial']):.4e}, energy_pred: {energy_pred:.4e}/{energy_init:.4e}, Time step: {time_step:.4e}/{time_step_fiducial:.4e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Body With Tidal Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.2'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch (3.10.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
