---
phase: 02-history-buffer-zero-padding
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/history_buffer.py
autonomous: true

must_haves:
  truths:
    - "Zero-state factory exists and creates zero-valued _HistoryState"
    - "features_for() returns zero features for missing history slots"
    - "Zero-padding preserves device, dtype, and softening from reference"
  artifacts:
    - path: "src/history_buffer.py"
      provides: "_zero_state() static method"
      contains: "_zero_state"
    - path: "src/history_buffer.py"
      provides: "Zero-padding in features_for()"
      pattern: "_zero_state.*past_list"
  key_links:
    - from: "_zero_state()"
      to: "features_for()"
      via: "called when len(past_list) < history_len"
      pattern: "_zero_state\\(past_list\\[0\\]\\)"
---

<objective>
Add zero-state factory method and implement zero-padding in features_for()

Purpose: Replace oldest-state padding with zero-padding for incomplete history during bootstrap. This provides cleaner signal to the model - zeros indicate "no data" rather than false repetition of oldest state.

Output: Modified src/history_buffer.py with _zero_state() method and updated features_for() using zero-padding.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-history-buffer-zero-padding/02-RESEARCH.md
@src/history_buffer.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add _zero_state() static method to HistoryBuffer</name>
  <files>src/history_buffer.py</files>
  <action>
Add a new static method `_zero_state()` to the `HistoryBuffer` class, placed after the existing `_expand_state_to_batch()` method (around line 252).

The method signature:
```python
@staticmethod
def _zero_state(reference: _HistoryState) -> _HistoryState:
```

Implementation:
1. Extract position tensor from reference to get device and dtype
2. Create zero tensors using `torch.zeros_like()` for position, velocity, mass, dt
3. Return new `_HistoryState` with zero tensors but same softening as reference

Key details:
- Use `torch.zeros_like(reference.position)` for both position and velocity (same shape)
- Use `torch.zeros_like(reference.mass)` for mass
- Use `torch.zeros_like(reference.dt)` for dt
- Copy `reference.softening` directly (physics parameter, must be consistent)

Do NOT create zero tensors manually with shape/device/dtype - use zeros_like to preserve all tensor properties automatically.
  </action>
  <verify>
Run Python to verify method exists and creates correct zero state:
```bash
cd /u/gkerex/projects/AITimeStepper && python -c "
from src.history_buffer import HistoryBuffer, _HistoryState
import torch

# Create reference state
ref = _HistoryState(
    position=torch.randn(4, 3),
    velocity=torch.randn(4, 3),
    mass=torch.ones(4),
    dt=torch.tensor(0.01),
    softening=0.1
)

# Create zero state
zero = HistoryBuffer._zero_state(ref)

# Verify zeros
assert torch.allclose(zero.position, torch.zeros(4, 3))
assert torch.allclose(zero.velocity, torch.zeros(4, 3))
assert torch.allclose(zero.mass, torch.zeros(4))
assert torch.allclose(zero.dt, torch.zeros(1))
assert zero.softening == 0.1
print('_zero_state() works correctly')
"
```
  </verify>
  <done>_zero_state() method exists and creates zero-valued _HistoryState with correct shapes and softening preserved</done>
</task>

<task type="auto">
  <name>Task 2: Modify features_for() to use zero-padding</name>
  <files>src/history_buffer.py</files>
  <action>
Modify the `features_for()` method (lines 254-292) to use `_zero_state()` for padding instead of repeating the oldest state.

Current code (lines 260-267):
```python
past_list: List[_HistoryState] = list(self._buf)
if len(past_list) < self.history_len:
    pad_count = self.history_len - len(past_list)
    if past_list:
        past_list = [past_list[0]] * pad_count + past_list
    else:
        past_list = [self._state_from_particle(current, detach=False)] * pad_count
```

Replace with:
```python
past_list: List[_HistoryState] = list(self._buf)
if len(past_list) < self.history_len:
    pad_count = self.history_len - len(past_list)
    if past_list:
        # Use oldest state as reference for shape/device/dtype
        zero_state = self._zero_state(past_list[0])
    else:
        # Use current state as reference
        current_state = self._state_from_particle(current, detach=False)
        zero_state = self._zero_state(current_state)

    past_list = [zero_state] * pad_count + past_list
```

Key change: Instead of repeating `past_list[0]` or current state, create a zero-valued state with matching tensor properties and use that for padding.

The rest of the method (seq assembly, feature computation) remains unchanged.
  </action>
  <verify>
Run Python to verify zero-padding behavior:
```bash
cd /u/gkerex/projects/AITimeStepper && python -c "
from src.history_buffer import HistoryBuffer
from src.particle import ParticleTorch
import torch

# Create history buffer with history_len=3
hb = HistoryBuffer(history_len=3, feature_type='basic')

# Create a particle (don't push anything to buffer)
p = ParticleTorch(
    position=torch.randn(4, 3),
    velocity=torch.randn(4, 3),
    mass=torch.ones(4),
    dt=0.01,
    softening=0.1
)

# Get features with empty history (should have zero-padded history)
feats = hb.features_for(p)
print(f'Feature shape: {feats.shape}')
print(f'Features computed successfully with zero-padding')

# Verify: for basic features, first 3 slots (33 features) should be mostly zeros
# except for n_val, d_val, soft_val which are metadata
# Key test: with zero pos/vel, r_mean, v_mean, a_mean should be 0
print('Zero-padding test passed')
"
```
  </verify>
  <done>features_for() uses zero-padding when history is incomplete; returns features without errors for empty buffer</done>
</task>

<task type="auto">
  <name>Task 3: Add unit test for zero-padding behavior</name>
  <files>src/history_buffer.py</files>
  <action>
Add a test function at the end of src/history_buffer.py (before any `if __name__ == "__main__":` block if present, or at the very end).

```python
def _test_zero_padding():
    """
    Test that zero-padding is used for incomplete history.
    Run with: python -c "from src.history_buffer import _test_zero_padding; _test_zero_padding()"
    """
    import torch
    from src.particle import ParticleTorch

    # Test 1: Empty buffer -> all padding should be zeros
    hb = HistoryBuffer(history_len=3, feature_type='basic')
    p = ParticleTorch(
        position=torch.randn(4, 3),
        velocity=torch.randn(4, 3),
        mass=torch.ones(4),
        dt=0.01,
        softening=0.1
    )

    feats_empty = hb.features_for(p)
    assert feats_empty.shape[-1] == 44, f"Expected 44 features for basic, got {feats_empty.shape[-1]}"

    # Test 2: Partially filled buffer
    hb.push(p)  # Now has 1 state, needs 2 more for history_len=3
    feats_partial = hb.features_for(p)
    assert feats_partial.shape[-1] == 44

    # Test 3: Full buffer -> no padding needed
    hb.push(p)
    hb.push(p)  # Now has 3 states
    feats_full = hb.features_for(p)
    assert feats_full.shape[-1] == 44

    # Test 4: Verify _zero_state preserves softening
    from src.history_buffer import _HistoryState
    ref = _HistoryState(
        position=torch.randn(4, 3),
        velocity=torch.randn(4, 3),
        mass=torch.ones(4),
        dt=torch.tensor(0.01),
        softening=0.5
    )
    zero = HistoryBuffer._zero_state(ref)
    assert zero.softening == 0.5, f"Softening mismatch: {zero.softening} != 0.5"
    assert torch.allclose(zero.position, torch.zeros(4, 3))
    assert torch.allclose(zero.velocity, torch.zeros(4, 3))

    print("All zero-padding tests passed!")
```

This provides a quick sanity check that can be run to verify the zero-padding implementation.
  </action>
  <verify>
Run the test function:
```bash
cd /u/gkerex/projects/AITimeStepper && python -c "from src.history_buffer import _test_zero_padding; _test_zero_padding()"
```
  </verify>
  <done>Test function exists and passes, confirming zero-padding works for empty, partial, and full buffer cases</done>
</task>

</tasks>

<verification>
Run all verification commands in sequence:
```bash
cd /u/gkerex/projects/AITimeStepper
python -c "from src.history_buffer import HistoryBuffer, _HistoryState; print('Import OK')"
python -c "from src.history_buffer import _test_zero_padding; _test_zero_padding()"
```

Both should complete without errors.
</verification>

<success_criteria>
1. `_zero_state()` static method exists in HistoryBuffer class
2. `features_for()` uses `_zero_state()` for padding instead of repeating oldest state
3. Test function `_test_zero_padding()` passes all assertions
4. No regressions - existing functionality still works
</success_criteria>

<output>
After completion, create `.planning/phases/02-history-buffer-zero-padding/02-01-SUMMARY.md`
</output>
