---
phase: 03-trajectory-collection-loop
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/trajectory_collection.py
autonomous: true

must_haves:
  truths:
    - "Single step predicts dt, integrates particle, returns new state"
    - "Energy threshold check correctly identifies pass/fail"
    - "Clone is created at start to avoid graph accumulation"
  artifacts:
    - path: "src/trajectory_collection.py"
      provides: "Core trajectory collection functions"
      exports: ["attempt_single_step", "check_energy_threshold"]
      min_lines: 50
  key_links:
    - from: "src/trajectory_collection.py"
      to: "src/model_adapter.py"
      via: "build_feature_tensor call"
      pattern: "adapter\\.build_feature_tensor"
    - from: "src/trajectory_collection.py"
      to: "src/particle.py"
      via: "clone_detached and evolve_batch"
      pattern: "clone_detached|evolve_batch"
---

<objective>
Create the core single-step prediction and energy threshold check functions.

Purpose: Establish the foundational primitives for accept/reject trajectory collection. These functions will be used by the retrain loop (Plan 02) and the trajectory collector (Plan 03).

Output: New `src/trajectory_collection.py` module with `attempt_single_step()` and `check_energy_threshold()` functions.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-trajectory-collection-loop/03-RESEARCH.md

# Core source files
@src/particle.py
@src/model_adapter.py
@src/config.py
@src/losses.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create trajectory_collection.py with attempt_single_step</name>
  <files>src/trajectory_collection.py</files>
  <action>
Create a new module `src/trajectory_collection.py` with:

1. Imports for torch, typing, Config, ParticleTorch, ModelAdapter, HistoryBuffer

2. `attempt_single_step()` function:
```python
def attempt_single_step(
    model: torch.nn.Module,
    particle: ParticleTorch,
    config: Config,
    adapter: ModelAdapter,
    history_buffer: Optional[HistoryBuffer] = None,
) -> Tuple[ParticleTorch, torch.Tensor, torch.Tensor, torch.Tensor]:
    """
    Predict dt, integrate one step, return new state and energy info.

    IMPORTANT: Creates clone_detached() at start to prevent graph accumulation.

    Args:
        model: Neural network that predicts dt
        particle: Current particle state (will NOT be modified)
        config: Configuration with energy_threshold
        adapter: ModelAdapter for feature construction
        history_buffer: Optional history for temporal features

    Returns:
        (advanced_particle, dt, E0, E1) where:
        - advanced_particle: ParticleTorch after integration (in computation graph)
        - dt: predicted timestep tensor
        - E0: initial energy (before integration)
        - E1: final energy (after integration)
    """
```

Implementation details:
- Clone particle with `p = particle.clone_detached()` at START
- Build features with `adapter.build_feature_tensor(p, history_buffer=history_buffer)`
- Handle feature dimension: `if feats.dim() == 1: feats = feats.unsqueeze(0)`
- Get model prediction: `params = model(feats)`, extract `dt_raw = params[:, 0]`
- Add epsilon: `dt = dt_raw + 1e-12` (ensure positive)
- Compute E0 with `p.total_energy_batch(G=1.0)`, normalize to 1D if scalar
- Update particle dt with `p.update_dt(dt)`
- Integrate with `p.evolve_batch(G=1.0)`
- Compute E1 after integration
- Return (p, dt, E0, E1)

3. `check_energy_threshold()` function:
```python
def check_energy_threshold(
    E0: torch.Tensor,
    E1: torch.Tensor,
    threshold: float,
) -> Tuple[bool, torch.Tensor]:
    """
    Check if relative energy error is within threshold.

    Args:
        E0: Initial energy (tensor, possibly batched)
        E1: Final energy (tensor, same shape as E0)
        threshold: Relative energy error threshold (e.g., 2e-4)

    Returns:
        (passed, rel_dE) where:
        - passed: True if rel_dE < threshold
        - rel_dE: Relative energy error tensor
    """
```

Implementation details:
- Safe division: `E0_safe = E0 + 1e-12 * E0.detach().abs() + 1e-12`
- Compute relative error: `rel_dE = torch.abs((E1 - E0) / E0_safe)`
- Handle batched case by taking max or checking all pass
- For single-step collection, use `.item()` for comparison: `passed = rel_dE.item() < threshold`
- Return (passed, rel_dE)

4. Add module to `src/__init__.py` exports:
   - Add `from .trajectory_collection import attempt_single_step, check_energy_threshold`
  </action>
  <verify>
Run: `python -c "from src.trajectory_collection import attempt_single_step, check_energy_threshold; print('Import OK')"`
  </verify>
  <done>Functions `attempt_single_step` and `check_energy_threshold` are importable from src module</done>
</task>

<task type="auto">
  <name>Task 2: Add compute_single_step_loss helper</name>
  <files>src/trajectory_collection.py</files>
  <action>
Add a helper function for computing loss during the retrain loop:

```python
def compute_single_step_loss(
    E0: torch.Tensor,
    E1: torch.Tensor,
    config: Config,
) -> torch.Tensor:
    """
    Compute loss for a single integration step.
    Uses band loss pattern from existing losses.py.

    Args:
        E0: Initial energy
        E1: Final energy
        config: Config with E_lower, E_upper bounds

    Returns:
        Scalar loss tensor (mean over batch if batched)
    """
```

Implementation:
- Import `band_loss_zero_inside_where` from `src.losses`
- Compute safe relative error as in check_energy_threshold
- Replace inf/nan with 1.0 penalty: `rel_dE = torch.where(torch.isfinite(rel_dE), rel_dE, torch.full_like(rel_dE, 1.0))`
- Add epsilon before log: `rel_dE_safe = rel_dE + 1e-12`
- Compute band loss: `loss = band_loss_zero_inside_where(torch.log(rel_dE_safe), math.log(config.E_lower), math.log(config.E_upper))`
- Return `loss.mean()` for batched case

Add to `src/__init__.py` exports.
  </action>
  <verify>
Run: `python -c "from src.trajectory_collection import compute_single_step_loss; print('Loss helper OK')"`
  </verify>
  <done>Function `compute_single_step_loss` computes band loss for single-step energy error</done>
</task>

<task type="auto">
  <name>Task 3: Add typing and docstrings</name>
  <files>src/trajectory_collection.py</files>
  <action>
Ensure the module has:

1. Module-level docstring explaining purpose:
```python
"""
Trajectory collection primitives for two-phase training.

This module provides the core accept/reject loop components:
- attempt_single_step: Predict dt, integrate, return state and energies
- check_energy_threshold: Verify energy conservation
- compute_single_step_loss: Loss for retrain loop

Phase 3 of AITimeStepper training refactor.
"""
```

2. Type hints for all function signatures using:
   - `from typing import Optional, Tuple`
   - `import torch`
   - Forward references where needed

3. Comprehensive docstrings with Args, Returns, and usage examples

4. Constants at module level:
   - `EPS = 1e-12` for numerical stability
  </action>
  <verify>
Run: `python -c "from src import trajectory_collection; help(trajectory_collection.attempt_single_step)"`
  </verify>
  <done>Module has complete type hints and docstrings</done>
</task>

</tasks>

<verification>
1. Import test: `python -c "from src import attempt_single_step, check_energy_threshold, compute_single_step_loss"`
2. Type check: `python -c "import src.trajectory_collection; print('Types OK')"`
3. Verify functions exist with correct signatures by inspecting help output
</verification>

<success_criteria>
1. `src/trajectory_collection.py` exists with all three functions
2. All functions are exported from `src/__init__.py`
3. Functions have complete type hints and docstrings
4. `attempt_single_step` creates clone_detached at start (graph isolation)
5. `check_energy_threshold` uses safe division pattern
6. `compute_single_step_loss` uses existing band_loss_zero_inside_where
</success_criteria>

<output>
After completion, create `.planning/phases/03-trajectory-collection-loop/03-01-SUMMARY.md`
</output>
