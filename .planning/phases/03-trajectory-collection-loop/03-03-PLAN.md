---
phase: 03-trajectory-collection-loop
plan: 03
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - src/trajectory_collection.py
autonomous: true

must_haves:
  truths:
    - "Collects N steps per epoch using steps_per_epoch config"
    - "Warmup steps (first history_len) discarded from trajectory list"
    - "History buffer always updated (even during warmup)"
    - "Returns list of accepted (state, dt) tuples"
  artifacts:
    - path: "src/trajectory_collection.py"
      provides: "Trajectory collection orchestrator"
      exports: ["collect_trajectory"]
      min_lines: 150
  key_links:
    - from: "src/trajectory_collection.py:collect_trajectory"
      to: "src/trajectory_collection.py:collect_trajectory_step"
      via: "function call in loop"
      pattern: "collect_trajectory_step"
    - from: "src/trajectory_collection.py:collect_trajectory"
      to: "src/history_buffer.py"
      via: "history_buffer.push()"
      pattern: "history_buffer\\.push"
---

<objective>
Implement the trajectory collection orchestrator that collects N validated steps per epoch.

Purpose: This function implements TRAIN-04 (N steps per epoch) and HIST-02 (warmup discard). It orchestrates multiple calls to `collect_trajectory_step` and manages the history buffer.

Output: `collect_trajectory()` function that returns a list of accepted trajectory steps, with warmup steps discarded.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-trajectory-collection-loop/03-RESEARCH.md
@.planning/phases/03-trajectory-collection-loop/03-01-SUMMARY.md

# Source files
@src/trajectory_collection.py
@src/history_buffer.py
@src/config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement collect_trajectory function</name>
  <files>src/trajectory_collection.py</files>
  <action>
Add the trajectory collection orchestrator to `src/trajectory_collection.py`:

```python
from typing import List

def collect_trajectory(
    model: torch.nn.Module,
    particle: ParticleTorch,
    optimizer: torch.optim.Optimizer,
    config: Config,
    adapter: ModelAdapter,
    history_buffer: Optional[HistoryBuffer] = None,
) -> Tuple[List[Tuple[ParticleTorch, float]], Dict[str, Any]]:
    """
    Collect a trajectory of N validated steps for one epoch.

    Implements TRAIN-04 (steps_per_epoch) and HIST-02 (warmup discard):
    - Collects config.steps_per_epoch accepted steps
    - Always pushes to history buffer (for feature computation)
    - Discards first history_len steps from returned trajectory (warmup)

    Args:
        model: Neural network for dt prediction
        particle: Starting particle state
        optimizer: PyTorch optimizer for model
        config: Config with steps_per_epoch, history_len, energy_threshold
        adapter: ModelAdapter for feature construction
        history_buffer: Optional history buffer (required if history_enabled)

    Returns:
        (trajectory, epoch_metrics) where:
        - trajectory: List of (ParticleTorch, dt) tuples (warmup excluded)
        - epoch_metrics: dict with 'total_steps', 'warmup_discarded',
                         'mean_retrain_iterations', 'mean_energy_error'
    """
```

Implementation:
```python
trajectory: List[Tuple[ParticleTorch, float]] = []
all_metrics: List[Dict[str, Any]] = []

# Determine warmup length
warmup_len = config.history_len if history_buffer is not None else 0

# Current particle state (will be updated each step)
current_particle = particle

for step_idx in range(config.steps_per_epoch):
    # Collect one accepted step
    accepted_particle, accepted_dt, step_metrics = collect_trajectory_step(
        model=model,
        particle=current_particle,
        optimizer=optimizer,
        config=config,
        adapter=adapter,
        history_buffer=history_buffer,
    )

    # Always push to history buffer (needed for next step's features)
    if history_buffer is not None:
        # Push detached copy to avoid graph accumulation
        history_buffer.push(accepted_particle.clone_detached())

    # Update current particle for next iteration
    current_particle = accepted_particle.clone_detached()

    # Track metrics
    all_metrics.append(step_metrics)

    # HIST-02: Discard warmup steps (first history_len)
    if step_idx >= warmup_len:
        # Real trajectory: add detached copy
        trajectory.append((accepted_particle.clone_detached(), accepted_dt))

# Aggregate epoch metrics
epoch_metrics = {
    'total_steps': config.steps_per_epoch,
    'warmup_discarded': warmup_len,
    'trajectory_length': len(trajectory),
    'mean_retrain_iterations': sum(m['retrain_iterations'] for m in all_metrics) / len(all_metrics) if all_metrics else 0,
    'mean_energy_error': sum(m['final_energy_error'] for m in all_metrics) / len(all_metrics) if all_metrics else 0,
    'max_retrain_iterations': max((m['retrain_iterations'] for m in all_metrics), default=0),
}

return trajectory, epoch_metrics
```

Key points:
- Uses `clone_detached()` when storing to trajectory to prevent graph accumulation
- Updates `current_particle` each step so trajectory is connected
- History buffer push is BEFORE warmup check (always push)
- Warmup check is AFTER history push (skip adding to trajectory list)
  </action>
  <verify>
Run: `python -c "from src.trajectory_collection import collect_trajectory; print('collect_trajectory OK')"`
  </verify>
  <done>Function `collect_trajectory` collects N steps with warmup discard</done>
</task>

<task type="auto">
  <name>Task 2: Handle edge cases</name>
  <files>src/trajectory_collection.py</files>
  <action>
Add validation and edge case handling to `collect_trajectory`:

1. Validate config.steps_per_epoch:
```python
if config.steps_per_epoch < 1:
    raise ValueError("steps_per_epoch must be >= 1")
```

2. Handle case where steps_per_epoch <= history_len (all warmup):
```python
if warmup_len >= config.steps_per_epoch:
    import warnings
    warnings.warn(
        f"steps_per_epoch ({config.steps_per_epoch}) <= history_len ({warmup_len}): "
        f"trajectory will be empty (all steps are warmup)",
        UserWarning,
    )
```

3. Handle history_buffer None for analytic mode:
```python
# Warmup only applies when history is enabled
warmup_len = config.history_len if (history_buffer is not None and config.history_len > 0) else 0
```

4. Add type annotation for return value:
```python
from typing import List, Tuple, Dict, Any
```
  </action>
  <verify>
Run: `python -c "from src.trajectory_collection import collect_trajectory; import inspect; print(inspect.signature(collect_trajectory))"`
  </verify>
  <done>Edge cases handled for steps_per_epoch and history_len combinations</done>
</task>

<task type="auto">
  <name>Task 3: Export and update __init__.py</name>
  <files>src/__init__.py</files>
  <action>
Ensure `collect_trajectory` is exported from the src package:

1. Add to imports in `src/__init__.py`:
```python
from .trajectory_collection import (
    attempt_single_step,
    check_energy_threshold,
    compute_single_step_loss,
    collect_trajectory_step,
    collect_trajectory,
)
```

2. Verify the import chain from project root.
  </action>
  <verify>
Run: `cd /u/gkerex/projects/AITimeStepper && python -c "from src import collect_trajectory; print('Export OK')"`
  </verify>
  <done>collect_trajectory exported from src package</done>
</task>

</tasks>

<verification>
1. Import: `python -c "from src import collect_trajectory"`
2. Signature: `python -c "from src import collect_trajectory; import inspect; print(inspect.signature(collect_trajectory))"`
3. Return type annotation check
</verification>

<success_criteria>
1. `collect_trajectory` exists with correct signature
2. Loops for `config.steps_per_epoch` iterations
3. Always pushes to history buffer (every step)
4. Discards first `history_len` steps from trajectory list
5. Returns (trajectory_list, epoch_metrics)
6. Handles edge case: steps_per_epoch <= history_len
7. Handles analytic mode (no history buffer)
</success_criteria>

<output>
After completion, create `.planning/phases/03-trajectory-collection-loop/03-03-SUMMARY.md`
</output>
